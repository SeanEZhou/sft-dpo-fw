{"vuln_id": "GHSA-2v5j-q74q-r53f", "cwe_id": "{'CWE-79'}", "score": 8.8, "chain": "{'https://github.com/django-helpdesk/django-helpdesk/commit/a22eb0673fe0b7784f99c6b5fd343b64a6700f06'}", "dataset": "osv", "summary": "django-helpdesk is vulnerable to Cross-site Scripting django-helpdesk is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting').", "published_date": "2021-12-03", "chain_len": 1, "project": "https://github.com/django-helpdesk/django-helpdesk", "commit_href": "https://github.com/django-helpdesk/django-helpdesk/commit/a22eb0673fe0b7784f99c6b5fd343b64a6700f06", "commit_sha": "a22eb0673fe0b7784f99c6b5fd343b64a6700f06", "patch": "SINGLE", "chain_ord": "['a22eb0673fe0b7784f99c6b5fd343b64a6700f06']", "before_first_fix_commit": "{'7097c9c4c0b255ec1f10f3ea14fa2b9c47f6c706'}", "last_fix_commit": "a22eb0673fe0b7784f99c6b5fd343b64a6700f06", "chain_ord_pos": 1, "commit_datetime": "11/19/2021, 16:11:33", "message": "Update pattern", "author": "noobpk", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"helpdesk/models.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/django-helpdesk/django-helpdesk/raw/a22eb0673fe0b7784f99c6b5fd343b64a6700f06/helpdesk%2Fmodels.py", "patch": "@@ -56,7 +56,7 @@ def get_markdown(text):\n     if not text:\n         return \"\"\n \n-    pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\[\\s\\S\\]]*?)\\)'\n+    pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\s\\S]*?)\\)'\n     # Regex check\n     if re.match(pattern, text):\n         # get get value of group regex"}}, "prior_version": " def get_markdown(text):     if not text:         return \"\"      pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\[\\s\\S\\]]*?)\\)'     # Regex check     if re.match(pattern, text):         # get get value of group regex", "after_version": " def get_markdown(text):     if not text:         return \"\"      pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\s\\S]*?)\\)'     # Regex check     if re.match(pattern, text):         # get get value of group regex", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "GHSA-3q6g-vf58-7m4g", "cwe_id": "{'CWE-400'}", "score": 7.5, "chain": "{'https://github.com/python-restx/flask-restx/commit/bab31e085f355dd73858fd3715f7ed71849656da'}", "dataset": "osv", "summary": "Regular Expression Denial of Service in flask-restx Flask RESTX contains a regular expression that is vulnerable to [ReDoS](https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS) (Regular Expression Denial of Service) in `email_regex`.", "published_date": "2021-09-08", "chain_len": 1, "project": "https://github.com/python-restx/flask-restx", "commit_href": "https://github.com/python-restx/flask-restx/commit/bab31e085f355dd73858fd3715f7ed71849656da", "commit_sha": "bab31e085f355dd73858fd3715f7ed71849656da", "patch": "SINGLE", "chain_ord": "['bab31e085f355dd73858fd3715f7ed71849656da']", "before_first_fix_commit": "{'e1ab7e34a47fa8c2fd025402b9c65afbe24d5e98'}", "last_fix_commit": "bab31e085f355dd73858fd3715f7ed71849656da", "chain_ord_pos": 1, "commit_datetime": "09/01/2021, 19:53:02", "message": "optimize email regex (credits: @kevinbackhouse, fix: #372)", "author": "ziirish", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"flask_restx/inputs.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/python-restx/flask-restx/raw/bab31e085f355dd73858fd3715f7ed71849656da/flask_restx%2Finputs.py", "patch": "@@ -48,7 +48,7 @@ def my_type(value):\n \n \n email_regex = re.compile(\n-    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@]+(?:\\.[^@]+)*)\" r\"$\",\n+    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@\\.]+(?:\\.[^@\\.]+)*)\" r\"$\",\n     re.IGNORECASE,\n )"}}, "prior_version": " def my_type(value):   email_regex = re.compile(     r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@]+(?:\\.[^@]+)*)\" r\"$\",     re.IGNORECASE, ) ", "after_version": " def my_type(value):   email_regex = re.compile(     r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@\\.]+(?:\\.[^@\\.]+)*)\" r\"$\",     re.IGNORECASE, ) ", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-49qr-xh3w-h436", "cwe_id": "{'CWE-79'}", "score": 6.1, "chain": "{'https://github.com/jupyter/notebook/commit/107a89fce5f413fb5728c1c5d2c7788e1fb17491'}", "dataset": "osv", "summary": "Moderate severity vulnerability that affects notebook Jupyter Notebook before 5.7.1 allows XSS via an untrusted notebook because nbconvert responses are considered to have the same origin as the notebook server. In other words, nbconvert endpoints can execute JavaScript with access to the server API. In notebook/nbconvert/handlers.py, NbconvertFileHandler and NbconvertPostHandler do not set a Content Security Policy to prevent this.", "published_date": "2018-11-21", "chain_len": 1, "project": "https://github.com/jupyter/notebook", "commit_href": "https://github.com/jupyter/notebook/commit/107a89fce5f413fb5728c1c5d2c7788e1fb17491", "commit_sha": "107a89fce5f413fb5728c1c5d2c7788e1fb17491", "patch": "SINGLE", "chain_ord": "['107a89fce5f413fb5728c1c5d2c7788e1fb17491']", "before_first_fix_commit": "{'04a686dbaf9dfe553324a03cb9e6f778cf1e3da1'}", "last_fix_commit": "107a89fce5f413fb5728c1c5d2c7788e1fb17491", "chain_ord_pos": 1, "commit_datetime": "10/22/2018, 13:52:36", "message": "Apply CSP sandboxing for nbconvert responses\n\nThese may contain untrusted content, so they should be treated as being\nfrom a different domain to the notebook server.", "author": "Thomas Kluyver", "comments": null, "stats": "{'additions': 14, 'deletions': 0, 'total': 14}", "files": {"notebook/nbconvert/handlers.py": {"additions": 14, "deletions": 0, "changes": 14, "status": "modified", "raw_url": "https://github.com/jupyter/notebook/raw/107a89fce5f413fb5728c1c5d2c7788e1fb17491/notebook%2Fnbconvert%2Fhandlers.py", "patch": "@@ -78,6 +78,13 @@ class NbconvertFileHandler(IPythonHandler):\n \n     SUPPORTED_METHODS = ('GET',)\n \n+    @property\n+    def content_security_policy(self):\n+        # In case we're serving HTML/SVG, confine any Javascript to a unique\n+        # origin so it can't interact with the notebook server.\n+        return super(NbconvertFileHandler, self).content_security_policy + \\\n+               \"; sandbox allow-scripts\"\n+\n     @web.authenticated\n     def get(self, format, path):\n \n@@ -145,6 +152,13 @@ def get(self, format, path):\n class NbconvertPostHandler(IPythonHandler):\n     SUPPORTED_METHODS = ('POST',)\n \n+    @property\n+    def content_security_policy(self):\n+        # In case we're serving HTML/SVG, confine any Javascript to a unique\n+        # origin so it can't interact with the notebook server.\n+        return super(NbconvertPostHandler, self).content_security_policy + \\\n+               \"; sandbox allow-scripts\"\n+\n     @web.authenticated\n     def post(self, format):\n         exporter = get_exporter(format, config=self.config)"}}, "prior_version": " class NbconvertFileHandler(IPythonHandler):      SUPPORTED_METHODS = ('GET',)      @web.authenticated     def get(self, format, path):  def get(self, format, path): class NbconvertPostHandler(IPythonHandler):     SUPPORTED_METHODS = ('POST',)      @web.authenticated     def post(self, format):         exporter = get_exporter(format, config=self.config)", "after_version": " class NbconvertFileHandler(IPythonHandler):      SUPPORTED_METHODS = ('GET',)      @property     def content_security_policy(self):         # In case we're serving HTML/SVG, confine any Javascript to a unique         # origin so it can't interact with the notebook server.         return super(NbconvertFileHandler, self).content_security_policy + \\                \"; sandbox allow-scripts\"      @web.authenticated     def get(self, format, path):  def get(self, format, path): class NbconvertPostHandler(IPythonHandler):     SUPPORTED_METHODS = ('POST',)      @property     def content_security_policy(self):         # In case we're serving HTML/SVG, confine any Javascript to a unique         # origin so it can't interact with the notebook server.         return super(NbconvertPostHandler, self).content_security_policy + \\                \"; sandbox allow-scripts\"      @web.authenticated     def post(self, format):         exporter = get_exporter(format, config=self.config)", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "GHSA-52q8-877j-gghq", "cwe_id": "{'CWE-22'}", "score": 0.0, "chain": "{'https://github.com/moinwiki/moin-1.9/commit/6b96a9060069302996b5af47fd4a388fc80172b7'}", "dataset": "osv", "summary": "remote code execution via cache action in MoinMoin ### Impact\nThe cache action in action/cache.py allows directory traversal through a crafted HTTP request. An attacker who can upload attachments to\nthe wiki can use this to achieve remote code execution.\n\n### Patches\nUsers are strongly advised to upgrade to a patched version.\n\nMoinMoin Wiki 1.9.11 has the necessary fixes and also contains other important fixes.\n\n### Workarounds\nIt is not advised to work around this, but to upgrade MoinMoin to a patched version.\n\nThat said, a work around via disabling the `cache` or the `AttachFile` action might be possible.\n\nAlso, it is of course helpful if you give `write` permissions (which include uploading attachments) only to trusted users.\n\n### Credits\n\nThis vulnerability was discovered by Michael Chapman.\n\n### For more information\nIf you have any questions or comments about this advisory, email me at [twaldmann@thinkmo.de](mailto:twaldmann@thinkmo.de).", "published_date": "2020-11-11", "chain_len": 1, "project": "https://github.com/moinwiki/moin-1.9", "commit_href": "https://github.com/moinwiki/moin-1.9/commit/6b96a9060069302996b5af47fd4a388fc80172b7", "commit_sha": "6b96a9060069302996b5af47fd4a388fc80172b7", "patch": "SINGLE", "chain_ord": "['6b96a9060069302996b5af47fd4a388fc80172b7']", "before_first_fix_commit": "{'d1e5fc7d3708d877353ca64dd4aa7cfd1cde4cb4', '31de9139d0aabc171e94032168399b4a0b2a88a2'}", "last_fix_commit": "6b96a9060069302996b5af47fd4a388fc80172b7", "chain_ord_pos": 1, "commit_datetime": "11/08/2020, 16:21:56", "message": "Merge pull request from GHSA-52q8-877j-gghq\n\nsecurity: fix remote code execution via cache action, CVE-2020-25074", "author": "TW", "comments": null, "stats": "{'additions': 20, 'deletions': 7, 'total': 27}", "files": {"MoinMoin/action/cache.py": {"additions": 20, "deletions": 7, "changes": 27, "status": "modified", "raw_url": "https://github.com/moinwiki/moin-1.9/raw/6b96a9060069302996b5af47fd4a388fc80172b7/MoinMoin%2Faction%2Fcache.py", "patch": "@@ -103,6 +103,19 @@ def key(request, wikiname=None, itemname=None, attachname=None, content=None, se\n     return key\n \n \n+def valid_key(key):\n+    # make sure the key looks like keys generated by key()\n+    if not isinstance(key, unicode):\n+        # key is None (not given in url args) or something unexpected\n+        return False\n+    try:\n+        int(key, 16)  # try to evaluate as hex number\n+    except ValueError:\n+        # was not a hex number\n+        return False\n+    return len(key) == 40  # hmac-sha1 hexdigest == 40 hex chars\n+\n+\n def put(request, key, data,\n         filename=None,\n         content_type=None,\n@@ -234,14 +247,14 @@ def _do_remove(request, key):\n     remove(request, key)\n \n \n-def _do(request, do, key):\n-    if do == 'get':\n-        _do_get(request, key)\n-    elif do == 'remove':\n-        _do_remove(request, key)\n-\n def execute(pagename, request):\n     do = request.values.get('do')\n     key = request.values.get('key')\n-    _do(request, do, key)\n+    valid = valid_key(key)  # validate untrusted input\n+    if valid and do == 'get':\n+        _do_get(request, key)\n+    elif valid and do == 'remove':\n+        _do_remove(request, key)\n+    else:\n+        request.status_code = 404"}}, "prior_version": " def key(request, wikiname=None, itemname=None, attachname=None, content=None, se     return key   def put(request, key, data,         filename=None,         content_type=None, def _do_remove(request, key):     remove(request, key)   def _do(request, do, key):     if do == 'get':         _do_get(request, key)     elif do == 'remove':         _do_remove(request, key)  def execute(pagename, request):     do = request.values.get('do')     key = request.values.get('key')     _do(request, do, key) ", "after_version": " def key(request, wikiname=None, itemname=None, attachname=None, content=None, se     return key   def valid_key(key):     # make sure the key looks like keys generated by key()     if not isinstance(key, unicode):         # key is None (not given in url args) or something unexpected         return False     try:         int(key, 16)  # try to evaluate as hex number     except ValueError:         # was not a hex number         return False     return len(key) == 40  # hmac-sha1 hexdigest == 40 hex chars   def put(request, key, data,         filename=None,         content_type=None, def _do_remove(request, key):     remove(request, key)   def execute(pagename, request):     do = request.values.get('do')     key = request.values.get('key')     valid = valid_key(key)  # validate untrusted input     if valid and do == 'get':         _do_get(request, key)     elif valid and do == 'remove':         _do_remove(request, key)     else:         request.status_code = 404 ", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-7257-96vg-qf6x", "cwe_id": "{'CWE-74', 'CWE-94'}", "score": 8.5, "chain": "{'https://github.com/Cog-Creators/Red-DiscordBot/pull/4183/commits/e269ea0d3bc88417163c18431b1df38a9be92bfc'}", "dataset": "osv", "summary": "Remote Code Execution in Red Discord Bot ### Impact\nA RCE exploit has been discovered in the Streams module: this exploit allows Discord users with specifically crafted \"going live\" messages to inject code into the Streams module's going live message. By abusing this exploit, it's possible to perform destructive actions and/or access sensitive information.\n\n### Patches\nThis critical exploit has been fixed on version ``3.3.12`` & ``3.4``.\n\n### Workarounds\nUnloading the Streams module with ``unload streams`` can render this exploit not accessible. We still highly recommend updating to ``3.3.12`` or ``3.4`` to completely patch this issue.\n\n### References\n* https://github.com/Cog-Creators/Red-DiscordBot/pull/4183\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Cog-Creators/Red-DiscordBot](https://github.com/Cog-Creators/Red-DiscordBot)\n* Over on our [Discord server](https://discord.gg/red)", "published_date": "2020-08-21", "chain_len": 1, "project": "https://github.com/Cog-Creators/Red-DiscordBot", "commit_href": "https://github.com/Cog-Creators/Red-DiscordBot/pull/4183/commits/e269ea0d3bc88417163c18431b1df38a9be92bfc", "commit_sha": "e269ea0d3bc88417163c18431b1df38a9be92bfc", "patch": "SINGLE", "chain_ord": "['e269ea0d3bc88417163c18431b1df38a9be92bfc']", "before_first_fix_commit": "{'9798538438ceb37c0592aa358f6f0c5784878d71'}", "last_fix_commit": "e269ea0d3bc88417163c18431b1df38a9be92bfc", "chain_ord_pos": 1, "commit_datetime": "08/11/2020, 22:40:06", "message": "Added consume all to streams.", "author": "Kowlin", "comments": null, "stats": "{'additions': 13, 'deletions': 9, 'total': 22}", "files": {"redbot/cogs/streams/streams.py": {"additions": 13, "deletions": 9, "changes": 22, "status": "modified", "raw_url": "https://github.com/Cog-Creators/Red-DiscordBot/raw/e269ea0d3bc88417163c18431b1df38a9be92bfc/redbot%2Fcogs%2Fstreams%2Fstreams.py", "patch": "@@ -497,14 +497,13 @@ async def message(self, ctx: commands.Context):\n \n     @message.command(name=\"mention\")\n     @commands.guild_only()\n-    async def with_mention(self, ctx: commands.Context, message: str = None):\n+    async def with_mention(self, ctx: commands.Context, *, message: str = None):\n         \"\"\"Set stream alert message when mentions are enabled.\n \n         Use `{mention}` in the message to insert the selected mentions.\n+        Use `{stream}` in the message to insert the channel or user name.\n \n-        Use `{stream.name}` in the message to insert the channel or user name.\n-\n-        For example: `[p]streamset message mention \"{mention}, {stream.name} is live!\"`\n+        For example: `[p]streamset message mention \"{mention}, {stream} is live!\"`\n         \"\"\"\n         if message is not None:\n             guild = ctx.guild\n@@ -515,12 +514,12 @@ async def with_mention(self, ctx: commands.Context, message: str = None):\n \n     @message.command(name=\"nomention\")\n     @commands.guild_only()\n-    async def without_mention(self, ctx: commands.Context, message: str = None):\n+    async def without_mention(self, ctx: commands.Context, *, message: str = None):\n         \"\"\"Set stream alert message when mentions are disabled.\n \n-        Use `{stream.name}` in the message to insert the channel or user name.\n+        Use `{stream}` in the message to insert the channel or user name.\n \n-        For example: `[p]streamset message nomention \"{stream.name} is live!\"`\n+        For example: `[p]streamset message nomention \"{stream} is live!\"`\n         \"\"\"\n         if message is not None:\n             guild = ctx.guild\n@@ -720,7 +719,10 @@ async def check_streams(self):\n                                 channel.guild\n                             ).live_message_mention()\n                             if alert_msg:\n-                                content = alert_msg.format(mention=mention_str, stream=stream)\n+                                content = alert_msg  # Stop bad things from happening here...\n+                                content = content.replace(\"{stream.name}\", str(stream.name))  # Backwards compatability\n+                                content = content.replace(\"{stream}\", str(stream.name))\n+                                content = content.replace(\"{mention}\", mention_str)\n                             else:\n                                 content = _(\"{mention}, {stream} is live!\").format(\n                                     mention=mention_str,\n@@ -733,7 +735,9 @@ async def check_streams(self):\n                                 channel.guild\n                             ).live_message_nomention()\n                             if alert_msg:\n-                                content = alert_msg.format(stream=stream)\n+                                content = alert_msg  # Stop bad things from happening here...\n+                                content = content.replace(\"{stream.name}\", str(stream.name))  # Backwards compatability\n+                                content = content.replace(\"{stream}\", str(stream.name))\n                             else:\n                                 content = _(\"{stream} is live!\").format(\n                                     stream=escape("}}, "prior_version": " async def message(self, ctx: commands.Context):      @message.command(name=\"mention\")     @commands.guild_only()     async def with_mention(self, ctx: commands.Context, message: str = None):         \"\"\"Set stream alert message when mentions are enabled.          Use `{mention}` in the message to insert the selected mentions.          Use `{stream.name}` in the message to insert the channel or user name.          For example: `[p]streamset message mention \"{mention}, {stream.name} is live!\"`         \"\"\"         if message is not None:             guild = ctx.guild async def with_mention(self, ctx: commands.Context, message: str = None):      @message.command(name=\"nomention\")     @commands.guild_only()     async def without_mention(self, ctx: commands.Context, message: str = None):         \"\"\"Set stream alert message when mentions are disabled.          Use `{stream.name}` in the message to insert the channel or user name.          For example: `[p]streamset message nomention \"{stream.name} is live!\"`         \"\"\"         if message is not None:             guild = ctx.guild async def check_streams(self):                                 channel.guild                             ).live_message_mention()                             if alert_msg:                                 content = alert_msg.format(mention=mention_str, stream=stream)                             else:                                 content = _(\"{mention}, {stream} is live!\").format(                                     mention=mention_str, async def check_streams(self):                                 channel.guild                             ).live_message_nomention()                             if alert_msg:                                 content = alert_msg.format(stream=stream)                             else:                                 content = _(\"{stream} is live!\").format(                                     stream=escape(", "after_version": " async def message(self, ctx: commands.Context):      @message.command(name=\"mention\")     @commands.guild_only()     async def with_mention(self, ctx: commands.Context, *, message: str = None):         \"\"\"Set stream alert message when mentions are enabled.          Use `{mention}` in the message to insert the selected mentions.         Use `{stream}` in the message to insert the channel or user name.          For example: `[p]streamset message mention \"{mention}, {stream} is live!\"`         \"\"\"         if message is not None:             guild = ctx.guild async def with_mention(self, ctx: commands.Context, message: str = None):      @message.command(name=\"nomention\")     @commands.guild_only()     async def without_mention(self, ctx: commands.Context, *, message: str = None):         \"\"\"Set stream alert message when mentions are disabled.          Use `{stream}` in the message to insert the channel or user name.          For example: `[p]streamset message nomention \"{stream} is live!\"`         \"\"\"         if message is not None:             guild = ctx.guild async def check_streams(self):                                 channel.guild                             ).live_message_mention()                             if alert_msg:                                 content = alert_msg  # Stop bad things from happening here...                                 content = content.replace(\"{stream.name}\", str(stream.name))  # Backwards compatability                                 content = content.replace(\"{stream}\", str(stream.name))                                 content = content.replace(\"{mention}\", mention_str)                             else:                                 content = _(\"{mention}, {stream} is live!\").format(                                     mention=mention_str, async def check_streams(self):                                 channel.guild                             ).live_message_nomention()                             if alert_msg:                                 content = alert_msg  # Stop bad things from happening here...                                 content = content.replace(\"{stream.name}\", str(stream.name))  # Backwards compatability                                 content = content.replace(\"{stream}\", str(stream.name))                             else:                                 content = _(\"{stream} is live!\").format(                                     stream=escape(", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "GHSA-7488-6x3r-23w5", "cwe_id": "{'CWE-22'}", "score": 9.3, "chain": "{'https://github.com/ganga-devs/ganga/commit/730e7aba192407d35eb37dd7938d49071124be8c'}", "dataset": "osv", "summary": "ganga before 8.5.10 allows absolute path traversal because the Flask send_file function is used unsafely The ganga-devs/ganga repository before 8.5.10 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-13", "chain_len": 1, "project": "https://github.com/ganga-devs/ganga", "commit_href": "https://github.com/ganga-devs/ganga/commit/730e7aba192407d35eb37dd7938d49071124be8c", "commit_sha": "730e7aba192407d35eb37dd7938d49071124be8c", "patch": "SINGLE", "chain_ord": "['730e7aba192407d35eb37dd7938d49071124be8c']", "before_first_fix_commit": "{'0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc'}", "last_fix_commit": "730e7aba192407d35eb37dd7938d49071124be8c", "chain_ord_pos": 1, "commit_datetime": "05/09/2022, 23:19:28", "message": "# Absolute Path Traversal due to incorrect use of `send_file` call (#2025)\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\r\n\r\n## Common Weakness Enumeration category\r\nCWE - 36\r\n\r\n## Root Cause Analysis\r\n\r\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\r\n```\r\n>>> import os.path\r\n>>> static = \"path/to/mySafeStaticDir\"\r\n>>> malicious = \"/../../../../../etc/passwd\"\r\n>>> os.path.join(t,malicious)\r\n'/../../../../../etc/passwd'\r\n```\r\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\r\n\r\nIn this case, the problems occurs due to the following code :\r\nhttps://github.com/ganga-devs/ganga/blob/0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc/ganga/GangaGUI/gui/routes.py#L671\r\n\r\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\r\n\r\n## Proof of Concept\r\n\r\nThe bug can be verified using a proof of concept similar to the one shown below.\r\n\r\n```\r\ncurl --path-as-is 'http://<domain>/job/<int:job_id>/browse///../../../../etc/passwd\"'\r\n```\r\n## Remediation\r\n\r\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\r\n\r\n## Common Vulnerability Scoring System Vector\r\n\r\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\r\n\r\n(AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L)[https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L&version=3.1]\r\n\r\nThis gives it a base score of 9.3/10 and a severity rating of critical.\r\n\r\n## References\r\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\r\n* github/securitylab#669\r\n\r\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*\r\n\r\nCo-authored-by: Porcupiney Hairs <porucpiney.hairs@protonmail.com>", "author": "porcupineyhairs", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"ganga/GangaGUI/gui/routes.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/ganga-devs/ganga/raw/730e7aba192407d35eb37dd7938d49071124be8c/ganga%2FGangaGUI%2Fgui%2Froutes.py", "patch": "@@ -12,7 +12,7 @@\n import sys\n import datetime\n from functools import wraps\n-from werkzeug.utils import secure_filename\n+from werkzeug.utils import secure_filename, safe_join\n from werkzeug.security import generate_password_hash, check_password_hash\n from flask import Flask, request, jsonify, render_template, flash, redirect, url_for, session, send_file, make_response\n from flask_login import login_user, login_required, logout_user, current_user, UserMixin\n@@ -656,7 +656,7 @@ def job_browse(job_id: int, path):\n         return redirect(url_for(\"job_page\", job_id=job_id))\n \n     # Join the base and the requested path\n-    abs_path = os.path.join(job_base_dir, path)\n+    abs_path = safe_join(job_base_dir, path)\n \n     # URL path variable for going back\n     back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")"}}, "prior_version": " import sys import datetime from functools import wraps from werkzeug.utils import secure_filename from werkzeug.security import generate_password_hash, check_password_hash from flask import Flask, request, jsonify, render_template, flash, redirect, url_for, session, send_file, make_response from flask_login import login_user, login_required, logout_user, current_user, UserMixin def job_browse(job_id: int, path):         return redirect(url_for(\"job_page\", job_id=job_id))      # Join the base and the requested path     abs_path = os.path.join(job_base_dir, path)      # URL path variable for going back     back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")", "after_version": " import sys import datetime from functools import wraps from werkzeug.utils import secure_filename, safe_join from werkzeug.security import generate_password_hash, check_password_hash from flask import Flask, request, jsonify, render_template, flash, redirect, url_for, session, send_file, make_response from flask_login import login_user, login_required, logout_user, current_user, UserMixin def job_browse(job_id: int, path):         return redirect(url_for(\"job_page\", job_id=job_id))      # Join the base and the requested path     abs_path = safe_join(job_base_dir, path)      # URL path variable for going back     back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-8434-v7xw-8m9x", "cwe_id": "{'CWE-88', 'CWE-78'}", "score": 9.3, "chain": "{'https://github.com/dwisiswant0/apkleaks/commit/a966e781499ff6fd4eea66876d7532301b13a382'}", "dataset": "osv", "summary": "Improper Neutralization of Argument Delimiters in a Decompiling Package Process in APKLeaks APKLeaks prior to v2.0.4 allows remote authenticated attackers to execute arbitrary OS commands via package name inside the application manifest.\n\n### Impact\n\nAn authenticated attacker could include arguments that allow unintended commands or code to be executed, allow sensitive data to be read or modified, or could cause other unintended behavior through malicious package names.\n\n\n### References\n\n- a966e781499ff6fd4eea66876d7532301b13a382\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Email me at [me@dw1.io](mailto:me@dw1.io)", "published_date": "2022-01-21", "chain_len": 1, "project": "https://github.com/dwisiswant0/apkleaks", "commit_href": "https://github.com/dwisiswant0/apkleaks/commit/a966e781499ff6fd4eea66876d7532301b13a382", "commit_sha": "a966e781499ff6fd4eea66876d7532301b13a382", "patch": "SINGLE", "chain_ord": "['a966e781499ff6fd4eea66876d7532301b13a382']", "before_first_fix_commit": "{'8577b7af6224bf0a5455b552963c46721308d2ff'}", "last_fix_commit": "a966e781499ff6fd4eea66876d7532301b13a382", "chain_ord_pos": 1, "commit_datetime": "03/14/2021, 15:25:42", "message": "Escapes decompiling arguments", "author": "Dwi Siswanto", "comments": null, "stats": "{'additions': 4, 'deletions': 2, 'total': 6}", "files": {"apkleaks/apkleaks.py": {"additions": 4, "deletions": 2, "changes": 6, "status": "modified", "raw_url": "https://github.com/dwisiswant0/apkleaks/raw/a966e781499ff6fd4eea66876d7532301b13a382/apkleaks%2Fapkleaks.py", "patch": "@@ -2,6 +2,7 @@\n from apkleaks.colors import clr\n from contextlib import closing\n from distutils.spawn import find_executable\n+from pipes import quote\n from pyaxmlparser import APK\n from urllib.request import urlopen\n from zipfile import ZipFile\n@@ -84,8 +85,9 @@ def decompile(self):\n \t\t\t\t\tclasses.write(zipped.read(\"classes.dex\"))\n \t\t\texcept Exception as e:\n \t\t\t\tsys.exit(self.writeln(str(e), clr.WARNING))\n-\t\tdec = \"%s %s -d %s --deobf\" % (self.jadx, dex, self.tempdir)\n-\t\tos.system(dec)\n+\t\targs = [self.jadx, dex, \"-d\", self.tempdir, \"--deobf\"]\n+\t\tcomm = \"%s\" % (\" \".join(quote(arg) for arg in args))\n+\t\tos.system(comm)\n \t\treturn self.tempdir\n \n \tdef unique(self, list):"}}, "prior_version": " from apkleaks.colors import clr from contextlib import closing from distutils.spawn import find_executable from pyaxmlparser import APK from urllib.request import urlopen from zipfile import ZipFile def decompile(self): \t\t\t\t\tclasses.write(zipped.read(\"classes.dex\")) \t\t\texcept Exception as e: \t\t\t\tsys.exit(self.writeln(str(e), clr.WARNING)) \t\tdec = \"%s %s -d %s --deobf\" % (self.jadx, dex, self.tempdir) \t\tos.system(dec) \t\treturn self.tempdir  \tdef unique(self, list): ", "after_version": " from apkleaks.colors import clr from contextlib import closing from distutils.spawn import find_executable from pipes import quote from pyaxmlparser import APK from urllib.request import urlopen from zipfile import ZipFile def decompile(self): \t\t\t\t\tclasses.write(zipped.read(\"classes.dex\")) \t\t\texcept Exception as e: \t\t\t\tsys.exit(self.writeln(str(e), clr.WARNING)) \t\targs = [self.jadx, dex, \"-d\", self.tempdir, \"--deobf\"] \t\tcomm = \"%s\" % (\" \".join(quote(arg) for arg in args)) \t\tos.system(comm) \t\treturn self.tempdir  \tdef unique(self, list): ", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "GHSA-8jxq-75rw-fhj9", "cwe_id": "{'CWE-94'}", "score": 9.8, "chain": "{'https://github.com/pyeve/eve/commit/f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98'}", "dataset": "osv", "summary": "Eve allows execution of arbitrary code via Code Injection in the where parameter io/mongo/parser.py in Eve (aka pyeve) before 0.7.5 allows remote attackers to execute arbitrary code via Code Injection in the where parameter.", "published_date": "2018-07-12", "chain_len": 1, "project": "https://github.com/pyeve/eve", "commit_href": "https://github.com/pyeve/eve/commit/f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98", "commit_sha": "f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98", "patch": "SINGLE", "chain_ord": "['f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98']", "before_first_fix_commit": "{'6d1526bf8ad93a3d259b1fd357f0c40e4ed9dbf5'}", "last_fix_commit": "f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98", "chain_ord_pos": 1, "commit_datetime": "01/14/2018, 16:51:26", "message": "fix mongo visitor parser", "author": "Nicola Iarocci", "comments": null, "stats": "{'additions': 9, 'deletions': 6, 'total': 15}", "files": {"eve/io/mongo/parser.py": {"additions": 9, "deletions": 6, "changes": 15, "status": "modified", "raw_url": "https://github.com/pyeve/eve/raw/f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98/eve%2Fio%2Fmongo%2Fparser.py", "patch": "@@ -122,16 +122,19 @@ def visit_Call(self, node):\n         datetime().\n         \"\"\"\n         if isinstance(node.func, ast.Name):\n-            expr = None\n             if node.func.id == 'ObjectId':\n-                expr = \"('\" + node.args[0].s + \"')\"\n+                try:\n+                    self.current_value = ObjectId(node.args[0].s)\n+                except:\n+                    pass\n             elif node.func.id == 'datetime':\n                 values = []\n                 for arg in node.args:\n-                    values.append(str(arg.n))\n-                expr = \"(\" + \", \".join(values) + \")\"\n-            if expr:\n-                self.current_value = eval(node.func.id + expr)\n+                    values.append(arg.n)\n+                try:\n+                    self.current_value = datetime(*values)\n+                except:\n+                    pass\n \n     def visit_Attribute(self, node):\n         \"\"\" Attribute handler ('Contact.Id')."}}, "prior_version": " def visit_Call(self, node):         datetime().         \"\"\"         if isinstance(node.func, ast.Name):             expr = None             if node.func.id == 'ObjectId':                 expr = \"('\" + node.args[0].s + \"')\"             elif node.func.id == 'datetime':                 values = []                 for arg in node.args:                     values.append(str(arg.n))                 expr = \"(\" + \", \".join(values) + \")\"             if expr:                 self.current_value = eval(node.func.id + expr)      def visit_Attribute(self, node):         \"\"\" Attribute handler ('Contact.Id').", "after_version": " def visit_Call(self, node):         datetime().         \"\"\"         if isinstance(node.func, ast.Name):             if node.func.id == 'ObjectId':                 try:                     self.current_value = ObjectId(node.args[0].s)                 except:                     pass             elif node.func.id == 'datetime':                 values = []                 for arg in node.args:                     values.append(arg.n)                 try:                     self.current_value = datetime(*values)                 except:                     pass      def visit_Attribute(self, node):         \"\"\" Attribute handler ('Contact.Id').", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "GHSA-8p5c-f328-9fvv", "cwe_id": "{'CWE-22'}", "score": 9.8, "chain": "{'https://github.com/anthraxx/diffoscope/commit/632a40828a54b399787c25e7fa243f732aef7e05'}", "dataset": "osv", "summary": "Diffoscope may write to arbitrary locations due to an untrusted archive diffoscope before 76 writes to arbitrary locations on disk based on the contents of an untrusted archive.", "published_date": "2018-07-13", "chain_len": 1, "project": "https://github.com/anthraxx/diffoscope", "commit_href": "https://github.com/anthraxx/diffoscope/commit/632a40828a54b399787c25e7fa243f732aef7e05", "commit_sha": "632a40828a54b399787c25e7fa243f732aef7e05", "patch": "SINGLE", "chain_ord": "['632a40828a54b399787c25e7fa243f732aef7e05']", "before_first_fix_commit": "{'b468a2840a097f4b2f7719929d690d5738dbcae4'}", "last_fix_commit": "632a40828a54b399787c25e7fa243f732aef7e05", "chain_ord_pos": 1, "commit_datetime": "02/09/2017, 21:47:05", "message": "Extract archive members using an auto-incrementing integer, avoiding the need to sanitise filenames. (Closes: #854723)\n\nSigned-off-by: Chris Lamb <lamby@debian.org>", "author": "Chris Lamb", "comments": null, "stats": "{'additions': 14, 'deletions': 27, 'total': 41}", "files": {"diffoscope/comparators/utils/libarchive.py": {"additions": 14, "deletions": 27, "changes": 41, "status": "modified", "raw_url": "https://github.com/anthraxx/diffoscope/raw/632a40828a54b399787c25e7fa243f732aef7e05/diffoscope%2Fcomparators%2Futils%2Flibarchive.py", "patch": "@@ -23,6 +23,7 @@\n import ctypes\n import logging\n import libarchive\n+import collections\n \n from diffoscope.tempfiles import get_temporary_directory\n \n@@ -168,11 +169,11 @@ def close_archive(self):\n \n     def get_member_names(self):\n         self.ensure_unpacked()\n-        return self._member_names\n+        return self._members.keys()\n \n     def extract(self, member_name, dest_dir):\n         self.ensure_unpacked()\n-        return os.path.join(self._unpacked, member_name)\n+        return self._members[member_name]\n \n     def get_member(self, member_name):\n         with libarchive.file_reader(self.source.path) as archive:\n@@ -197,45 +198,31 @@ def get_subclass(self, entry):\n         return LibarchiveMember(self, entry)\n \n     def ensure_unpacked(self):\n-        if hasattr(self, '_unpacked'):\n+        if hasattr(self, '_members'):\n             return\n \n-        self._unpacked = get_temporary_directory().name\n-        self._member_names = []\n+        tmpdir = get_temporary_directory().name\n+        self._members = collections.OrderedDict()\n \n-        logger.debug(\"Extracting %s to %s\", self.source.path, self._unpacked)\n+        logger.debug(\"Extracting %s to %s\", self.source.path, tmpdir)\n \n         with libarchive.file_reader(self.source.path) as archive:\n-            for entry in archive:\n-                self._member_names.append(entry.pathname)\n+            for idx, entry in enumerate(archive):\n+                # Maintain a mapping of archive path to the extracted path,\n+                # avoiding the need to sanitise filenames.\n+                dst = os.path.join(tmpdir, '{}'.format(idx))\n+                self._members[entry.pathname] = dst\n \n                 if entry.isdir:\n                     continue\n \n-                # All extracted locations must be underneath self._unpacked\n-                force_prefix = os.path.join(self._unpacked, \"\")\n-\n-                # Try to pick a safe and reasonable candidate name\n-                candidate_name = os.path.normpath(entry.pathname.rstrip('/' + os.sep))\n-                if os.path.isabs(candidate_name):\n-                    candidate_name = os.path.relpath(candidate_name, os.path.join(os.path.sep))\n-\n-                dst = os.path.normpath(os.path.join(self._unpacked, candidate_name))\n-                if not dst.startswith(force_prefix):\n-                    logger.warn(\"Skipping member because we could not make a safe name to extract it to: '%s'\",\n-                                entry.pathname)\n-                    continue\n-\n-                # TODO: need to fix reading these cleaned members. currently\n-                # reading will still try to use the uncleaned name.\n-                #logging.debug(\"Extracting %s to %s\", entry.pathname, dst)\n-                os.makedirs(os.path.dirname(dst), exist_ok=True)\n+                logger.debug(\"Extracting %s to %s\", entry.pathname, dst)\n \n                 with open(dst, 'wb') as f:\n                     for block in entry.get_blocks():\n                         f.write(block)\n \n         logger.debug(\n             \"Extracted %d entries from %s to %s\",\n-            len(self._member_names), self.source.path, self._unpacked,\n+            len(self._members), self.source.path, tmpdir,\n         )"}}, "prior_version": " import ctypes import logging import libarchive  from diffoscope.tempfiles import get_temporary_directory  def close_archive(self):      def get_member_names(self):         self.ensure_unpacked()         return self._member_names      def extract(self, member_name, dest_dir):         self.ensure_unpacked()         return os.path.join(self._unpacked, member_name)      def get_member(self, member_name):         with libarchive.file_reader(self.source.path) as archive: def get_subclass(self, entry):         return LibarchiveMember(self, entry)      def ensure_unpacked(self):         if hasattr(self, '_unpacked'):             return          self._unpacked = get_temporary_directory().name         self._member_names = []          logger.debug(\"Extracting %s to %s\", self.source.path, self._unpacked)          with libarchive.file_reader(self.source.path) as archive:             for entry in archive:                 self._member_names.append(entry.pathname)                  if entry.isdir:                     continue                  # All extracted locations must be underneath self._unpacked                 force_prefix = os.path.join(self._unpacked, \"\")                  # Try to pick a safe and reasonable candidate name                 candidate_name = os.path.normpath(entry.pathname.rstrip('/' + os.sep))                 if os.path.isabs(candidate_name):                     candidate_name = os.path.relpath(candidate_name, os.path.join(os.path.sep))                  dst = os.path.normpath(os.path.join(self._unpacked, candidate_name))                 if not dst.startswith(force_prefix):                     logger.warn(\"Skipping member because we could not make a safe name to extract it to: '%s'\",                                 entry.pathname)                     continue                  # TODO: need to fix reading these cleaned members. currently                 # reading will still try to use the uncleaned name.                 #logging.debug(\"Extracting %s to %s\", entry.pathname, dst)                 os.makedirs(os.path.dirname(dst), exist_ok=True)                  with open(dst, 'wb') as f:                     for block in entry.get_blocks():                         f.write(block)          logger.debug(             \"Extracted %d entries from %s to %s\",             len(self._member_names), self.source.path, self._unpacked,         )", "after_version": " import ctypes import logging import libarchive import collections  from diffoscope.tempfiles import get_temporary_directory  def close_archive(self):      def get_member_names(self):         self.ensure_unpacked()         return self._members.keys()      def extract(self, member_name, dest_dir):         self.ensure_unpacked()         return self._members[member_name]      def get_member(self, member_name):         with libarchive.file_reader(self.source.path) as archive: def get_subclass(self, entry):         return LibarchiveMember(self, entry)      def ensure_unpacked(self):         if hasattr(self, '_members'):             return          tmpdir = get_temporary_directory().name         self._members = collections.OrderedDict()          logger.debug(\"Extracting %s to %s\", self.source.path, tmpdir)          with libarchive.file_reader(self.source.path) as archive:             for idx, entry in enumerate(archive):                 # Maintain a mapping of archive path to the extracted path,                 # avoiding the need to sanitise filenames.                 dst = os.path.join(tmpdir, '{}'.format(idx))                 self._members[entry.pathname] = dst                  if entry.isdir:                     continue                  logger.debug(\"Extracting %s to %s\", entry.pathname, dst)                  with open(dst, 'wb') as f:                     for block in entry.get_blocks():                         f.write(block)          logger.debug(             \"Extracted %d entries from %s to %s\",             len(self._members), self.source.path, tmpdir,         )", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-8phj-f9w2-cjcc", "cwe_id": "{'CWE-22'}", "score": 8.6, "chain": "{'https://github.com/aimhubio/aim/pull/1003/commits/f01266a1a479ef11d7d6c539e7dd89e9d5639738'}", "dataset": "osv", "summary": "Arbitrary file reading vulnerability in Aim ### Impact\nA path traversal attack aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files.\n\nVulnerable code: https://github.com/aimhubio/aim/blob/0b99c6ca08e0ba7e7011453a2f68033e9b1d1bce/aim/web/api/views.py#L9-L16\n\n### Patches\nThe vulnerability issue is resolved in Aim v3.1.0.\n\n### References\nhttps://owasp.org/www-community/attacks/Path_Traversal", "published_date": "2021-11-23", "chain_len": 1, "project": "https://github.com/aimhubio/aim", "commit_href": "https://github.com/aimhubio/aim/pull/1003/commits/f01266a1a479ef11d7d6c539e7dd89e9d5639738", "commit_sha": "f01266a1a479ef11d7d6c539e7dd89e9d5639738", "patch": "SINGLE", "chain_ord": "['f01266a1a479ef11d7d6c539e7dd89e9d5639738']", "before_first_fix_commit": "{'0bcac8b709f9409518134b2eafee817278aca14f'}", "last_fix_commit": "f01266a1a479ef11d7d6c539e7dd89e9d5639738", "chain_ord_pos": 1, "commit_datetime": "11/12/2021, 14:03:22", "message": "Fix security issue when incorrect path is given to the endpoint that serves static files which can lead to a leak of non wanted files (e.g. /static-files/../../../../etc/passwd)", "author": "mihran113", "comments": null, "stats": "{'additions': 9, 'deletions': 1, 'total': 10}", "files": {"aim/web/api/views.py": {"additions": 9, "deletions": 1, "changes": 10, "status": "modified", "raw_url": "https://github.com/aimhubio/aim/raw/f01266a1a479ef11d7d6c539e7dd89e9d5639738/aim%2Fweb%2Fapi%2Fviews.py", "patch": "@@ -1,15 +1,23 @@\n import os\n+from pathlib import Path\n \n from aim.web.api.utils import APIRouter  # wrapper for fastapi.APIRouter\n from fastapi.responses import FileResponse\n+from fastapi import HTTPException\n \n statics_router = APIRouter()\n \n \n @statics_router.get('/static-files/{path:path}/')\n async def serve_static_files(path):\n     from aim import web\n-    static_file_name = os.path.join(os.path.dirname(web.__file__), 'ui', 'build', path)\n+    static_file_root = os.path.join(os.path.dirname(web.__file__), 'ui', 'build')\n+    static_file_name = os.path.join(static_file_root, path)\n+\n+    # check if path is leading inside ui/build directory\n+    if not Path(static_file_root) in Path(static_file_name).resolve().parents:\n+        raise HTTPException(404)\n+\n     compressed_file_name = '{}.gz'.format(static_file_name)\n     if os.path.exists(compressed_file_name):\n         return FileResponse(compressed_file_name, headers={'Content-Encoding': 'gzip'})"}}, "prior_version": " import os  from aim.web.api.utils import APIRouter  # wrapper for fastapi.APIRouter from fastapi.responses import FileResponse  statics_router = APIRouter()   @statics_router.get('/static-files/{path:path}/') async def serve_static_files(path):     from aim import web     static_file_name = os.path.join(os.path.dirname(web.__file__), 'ui', 'build', path)     compressed_file_name = '{}.gz'.format(static_file_name)     if os.path.exists(compressed_file_name):         return FileResponse(compressed_file_name, headers={'Content-Encoding': 'gzip'})", "after_version": " import os from pathlib import Path  from aim.web.api.utils import APIRouter  # wrapper for fastapi.APIRouter from fastapi.responses import FileResponse from fastapi import HTTPException  statics_router = APIRouter()   @statics_router.get('/static-files/{path:path}/') async def serve_static_files(path):     from aim import web     static_file_root = os.path.join(os.path.dirname(web.__file__), 'ui', 'build')     static_file_name = os.path.join(static_file_root, path)      # check if path is leading inside ui/build directory     if not Path(static_file_root) in Path(static_file_name).resolve().parents:         raise HTTPException(404)      compressed_file_name = '{}.gz'.format(static_file_name)     if os.path.exists(compressed_file_name):         return FileResponse(compressed_file_name, headers={'Content-Encoding': 'gzip'})", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-976r-qfjj-c24w", "cwe_id": "{'CWE-78'}", "score": 9.8, "chain": "{'https://github.com/apache/airflow/commit/afa4b11fddfdbadb048f742cf66d5c21c675a5c8'}", "dataset": "osv", "summary": "Command injection via Celery broker in Apache Airflow An issue was found in Apache Airflow versions 1.10.10 and below. When using CeleryExecutor, if an attacker can connect to the broker (Redis, RabbitMQ) directly, it is possible to inject commands, resulting in the celery worker running arbitrary commands.", "published_date": "2020-07-27", "chain_len": 1, "project": "https://github.com/apache/airflow", "commit_href": "https://github.com/apache/airflow/commit/afa4b11fddfdbadb048f742cf66d5c21c675a5c8", "commit_sha": "afa4b11fddfdbadb048f742cf66d5c21c675a5c8", "patch": "SINGLE", "chain_ord": "['afa4b11fddfdbadb048f742cf66d5c21c675a5c8']", "before_first_fix_commit": "{'63260c9955d12a60d8c143a932432013dd05eebb'}", "last_fix_commit": "afa4b11fddfdbadb048f742cf66d5c21c675a5c8", "chain_ord_pos": 1, "commit_datetime": "12/27/2019, 08:24:41", "message": "[AIRFLOW-6351] security - ui - Add Cross Site Scripting defence (#6913)", "author": "tooptoop4", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"airflow/www_rbac/views.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/apache/airflow/raw/afa4b11fddfdbadb048f742cf66d5c21c675a5c8/airflow%2Fwww_rbac%2Fviews.py", "patch": "@@ -321,7 +321,7 @@ def get_int_arg(value, default=0):\n             num_dag_to=min(end, num_of_all_dags),\n             num_of_all_dags=num_of_all_dags,\n             paging=wwwutils.generate_pages(current_page, num_of_pages,\n-                                           search=arg_search_query,\n+                                           search=escape(arg_search_query) if arg_search_query else None,\n                                            showPaused=not hide_paused),\n             num_runs=num_runs,\n             tags=tags)"}}, "prior_version": " def get_int_arg(value, default=0):             num_dag_to=min(end, num_of_all_dags),             num_of_all_dags=num_of_all_dags,             paging=wwwutils.generate_pages(current_page, num_of_pages,                                            search=arg_search_query,                                            showPaused=not hide_paused),             num_runs=num_runs,             tags=tags)", "after_version": " def get_int_arg(value, default=0):             num_dag_to=min(end, num_of_all_dags),             num_of_all_dags=num_of_all_dags,             paging=wwwutils.generate_pages(current_page, num_of_pages,                                            search=escape(arg_search_query) if arg_search_query else None,                                            showPaused=not hide_paused),             num_runs=num_runs,             tags=tags)", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "GHSA-98gj-wwxm-cj3h", "cwe_id": "{'CWE-79'}", "score": 6.1, "chain": "{'https://github.com/lepture/mistune/commit/5f06d724bc05580e7f203db2d4a4905fc1127f98'}", "dataset": "osv", "summary": "Moderate severity vulnerability that affects mistune Cross-site scripting (XSS) vulnerability in the _keyify function in mistune.py in Mistune before 0.8.1 allows remote attackers to inject arbitrary web script or HTML by leveraging failure to escape the \"key\" argument.", "published_date": "2019-01-04", "chain_len": 1, "project": "https://github.com/lepture/mistune", "commit_href": "https://github.com/lepture/mistune/commit/5f06d724bc05580e7f203db2d4a4905fc1127f98", "commit_sha": "5f06d724bc05580e7f203db2d4a4905fc1127f98", "patch": "SINGLE", "chain_ord": "['5f06d724bc05580e7f203db2d4a4905fc1127f98']", "before_first_fix_commit": "{'7f7f106a717e6cf58012304e56b41d6fb2b98e5f'}", "last_fix_commit": "5f06d724bc05580e7f203db2d4a4905fc1127f98", "chain_ord_pos": 1, "commit_datetime": "11/20/2017, 15:15:09", "message": "Fix CVE-2017-16876", "author": "Hsiaoming Yang", "comments": null, "stats": "{'additions': 5, 'deletions': 3, 'total': 8}", "files": {"mistune.py": {"additions": 5, "deletions": 3, "changes": 8, "status": "modified", "raw_url": "https://github.com/lepture/mistune/raw/5f06d724bc05580e7f203db2d4a4905fc1127f98/mistune.py", "patch": "@@ -11,7 +11,7 @@\n import re\n import inspect\n \n-__version__ = '0.8'\n+__version__ = '0.8.1'\n __author__ = 'Hsiaoming Yang <me@lepture.com>'\n __all__ = [\n     'BlockGrammar', 'BlockLexer',\n@@ -48,7 +48,8 @@ def _pure_pattern(regex):\n \n \n def _keyify(key):\n-    return _key_pattern.sub(' ', key.lower())\n+    key = escape(key.lower(), quote=True)\n+    return _key_pattern.sub(' ', key)\n \n \n def escape(text, quote=False, smart_amp=True):\n@@ -445,7 +446,8 @@ class InlineGrammar(object):\n     inline_html = re.compile(\n         r'^(?:%s|%s|%s)' % (\n             r'<!--[\\s\\S]*?-->',\n-            r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\/\\1>' % (_valid_end, _valid_attr),\n+            r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\/\\1>' % (\n+                _valid_end, _valid_attr),\n             r'<\\w+%s(?:%s)*?\\s*\\/?>' % (_valid_end, _valid_attr),\n         )\n     )"}}, "prior_version": " import re import inspect  __version__ = '0.8' __author__ = 'Hsiaoming Yang <me@lepture.com>' __all__ = [     'BlockGrammar', 'BlockLexer', def _pure_pattern(regex):   def _keyify(key):     return _key_pattern.sub(' ', key.lower())   def escape(text, quote=False, smart_amp=True): class InlineGrammar(object):     inline_html = re.compile(         r'^(?:%s|%s|%s)' % (             r'<!--[\\s\\S]*?-->',             r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\/\\1>' % (_valid_end, _valid_attr),             r'<\\w+%s(?:%s)*?\\s*\\/?>' % (_valid_end, _valid_attr),         )     )", "after_version": " import re import inspect  __version__ = '0.8.1' __author__ = 'Hsiaoming Yang <me@lepture.com>' __all__ = [     'BlockGrammar', 'BlockLexer', def _pure_pattern(regex):   def _keyify(key):     key = escape(key.lower(), quote=True)     return _key_pattern.sub(' ', key)   def escape(text, quote=False, smart_amp=True): class InlineGrammar(object):     inline_html = re.compile(         r'^(?:%s|%s|%s)' % (             r'<!--[\\s\\S]*?-->',             r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\/\\1>' % (                 _valid_end, _valid_attr),             r'<\\w+%s(?:%s)*?\\s*\\/?>' % (_valid_end, _valid_attr),         )     )", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "GHSA-9jjr-qqfp-ppwx", "cwe_id": "{'CWE-94'}", "score": 9.6, "chain": "{'https://github.com/jupyterhub/binderhub/commit/195caac172690456dcdc8cc7a6ca50e05abf8182'}", "dataset": "osv", "summary": "remote code execution via git repo provider ### Impact\n\nA remote code execution vulnerability has been identified in BinderHub, where providing BinderHub with maliciously crafted input could execute code in the BinderHub context, with the potential to egress credentials of the BinderHub deployment, including JupyterHub API tokens, kubernetes service accounts, and docker registry credentials. This may provide the ability to manipulate images and other user created pods in the deployment, with the potential to escalate to the host depending on the underlying kubernetes configuration.\n\n### Patches\n\nPatch below, or [on GitHub](https://github.com/jupyterhub/binderhub/commit/195caac172690456dcdc8cc7a6ca50e05abf8182.patch)\n\n```diff\nFrom 9f4043d9dddc1174920e687773f27b7933f48ab6 Mon Sep 17 00:00:00 2001\nFrom: Riccardo Castellotti <rcastell@cern.ch>\nDate: Thu, 19 Aug 2021 15:49:43 +0200\nSubject: [PATCH] Explicitly separate git-ls-remote options from positional\n arguments\n\n---\n binderhub/repoproviders.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a/binderhub/repoproviders.py b/binderhub/repoproviders.py\nindex f33347b..5d4b87c 100755\n--- a/binderhub/repoproviders.py\n+++ b/binderhub/repoproviders.py\n@@ -484,7 +484,7 @@ class GitRepoProvider(RepoProvider):\n             self.sha1_validate(self.unresolved_ref)\n         except ValueError:\n             # The ref is a head/tag and we resolve it using `git ls-remote`\n-            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\n+            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\n             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n             if result.returncode:\n                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))\n-- \n2.25.1\n\n```\n\n### Workarounds\n\nDisable the git repo provider by specifying the `BinderHub.repo_providers` config, e.g.:\n\n```python\nfrom binderhub.repoproviders import (GitHubRepoProvider,\n                            GitLabRepoProvider, GistRepoProvider,\n                            ZenodoProvider, FigshareProvider, HydroshareProvider,\n                            DataverseProvider)\n\nc.BinderHub.repo_providers =  {\n            'gh': GitHubRepoProvider,\n            'gist': GistRepoProvider,\n            'gl': GitLabRepoProvider,\n            'zenodo': ZenodoProvider,\n            'figshare': FigshareProvider,\n            'hydroshare': HydroshareProvider,\n            'dataverse': DataverseProvider,\n        }\n```\n\n### References\n\nCredit: Jose Carlos Luna Duran (CERN) and Riccardo Castellotti (CERN).\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Email us at [security@ipython.org](mailto:security@ipython.org)", "published_date": "2021-08-30", "chain_len": 1, "project": "https://github.com/jupyterhub/binderhub", "commit_href": "https://github.com/jupyterhub/binderhub/commit/195caac172690456dcdc8cc7a6ca50e05abf8182", "commit_sha": "195caac172690456dcdc8cc7a6ca50e05abf8182", "patch": "SINGLE", "chain_ord": "['195caac172690456dcdc8cc7a6ca50e05abf8182']", "before_first_fix_commit": "{'034430adc8ed379135f3ef46ee6ca650781ef67c'}", "last_fix_commit": "195caac172690456dcdc8cc7a6ca50e05abf8182", "chain_ord_pos": 1, "commit_datetime": "08/19/2021, 13:49:43", "message": "Explicitly separate git-ls-remote options from positional arguments", "author": "Riccardo Castellotti", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"binderhub/repoproviders.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/jupyterhub/binderhub/raw/195caac172690456dcdc8cc7a6ca50e05abf8182/binderhub%2Frepoproviders.py", "patch": "@@ -484,7 +484,7 @@ async def get_resolved_ref(self):\n             self.sha1_validate(self.unresolved_ref)\n         except ValueError:\n             # The ref is a head/tag and we resolve it using `git ls-remote`\n-            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\n+            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\n             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n             if result.returncode:\n                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))"}}, "prior_version": " async def get_resolved_ref(self):             self.sha1_validate(self.unresolved_ref)         except ValueError:             # The ref is a head/tag and we resolve it using `git ls-remote`             command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)             if result.returncode:                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))", "after_version": " async def get_resolved_ref(self):             self.sha1_validate(self.unresolved_ref)         except ValueError:             # The ref is a head/tag and we resolve it using `git ls-remote`             command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)             if result.returncode:                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "GHSA-cmc7-mfmr-xqrx", "cwe_id": "{'CWE-480', 'CWE-287'}", "score": 7.5, "chain": "{'https://github.com/abhinavsingh/proxy.py/pull/482/commits/9b00093288237f5073c403f2c4f62acfdfa8ed46'}", "dataset": "osv", "summary": "Logic error in authentication in proxy.py before_upstream_connection in AuthPlugin in http/proxy/auth.py in proxy.py before 2.3.1 accepts incorrect Proxy-Authorization header data because of a boolean confusion (and versus or).", "published_date": "2021-04-07", "chain_len": 1, "project": "https://github.com/abhinavsingh/proxy.py", "commit_href": "https://github.com/abhinavsingh/proxy.py/pull/482/commits/9b00093288237f5073c403f2c4f62acfdfa8ed46", "commit_sha": "9b00093288237f5073c403f2c4f62acfdfa8ed46", "patch": "SINGLE", "chain_ord": "['9b00093288237f5073c403f2c4f62acfdfa8ed46']", "before_first_fix_commit": "{'0f78e74705e295bbfccfba342bf9fd34a9aa9103'}", "last_fix_commit": "9b00093288237f5073c403f2c4f62acfdfa8ed46", "chain_ord_pos": 1, "commit_datetime": "01/10/2021, 16:30:14", "message": "Fix basic auth condition", "author": "Abhinav Singh", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"proxy/http/proxy/auth.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/abhinavsingh/proxy.py/raw/9b00093288237f5073c403f2c4f62acfdfa8ed46/proxy%2Fhttp%2Fproxy%2Fauth.py", "patch": "@@ -35,8 +35,8 @@ def before_upstream_connection(\n                 raise ProxyAuthenticationFailed()\n             parts = request.headers[b'proxy-authorization'][1].split()\n             if len(parts) != 2 \\\n-                    and parts[0].lower() != b'basic' \\\n-                    and parts[1] != self.flags.auth_code:\n+                    or parts[0].lower() != b'basic' \\\n+                    or parts[1] != self.flags.auth_code:\n                 raise ProxyAuthenticationFailed()\n         return request"}}, "prior_version": " def before_upstream_connection(                 raise ProxyAuthenticationFailed()             parts = request.headers[b'proxy-authorization'][1].split()             if len(parts) != 2 \\                     and parts[0].lower() != b'basic' \\                     and parts[1] != self.flags.auth_code:                 raise ProxyAuthenticationFailed()         return request ", "after_version": " def before_upstream_connection(                 raise ProxyAuthenticationFailed()             parts = request.headers[b'proxy-authorization'][1].split()             if len(parts) != 2 \\                     or parts[0].lower() != b'basic' \\                     or parts[1] != self.flags.auth_code:                 raise ProxyAuthenticationFailed()         return request ", "file_extension": "py", "cwe": "CWE-287"}
{"vuln_id": "GHSA-cwpm-f78v-7m5c", "cwe_id": "{'CWE-400', 'CWE-20'}", "score": 5.5, "chain": "{'https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e'}", "dataset": "osv", "summary": "Denial of service in `tf.ragged.constant` due to lack of validation ### Impact\nThe implementation of [`tf.ragged.constant`](https://github.com/tensorflow/tensorflow/blob/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python/ops/ragged/ragged_factory_ops.py#L146-L239) does not fully validate the input arguments. This results in a denial of service by consuming all available memory:\n\n```python\nimport tensorflow as tf\ntf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)\n```\n  \n### Patches\nWe have patched the issue in GitHub commit [bd4d5583ff9c8df26d47a23e508208844297310e](https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported externally via a [GitHub issue](https://github.com/tensorflow/tensorflow/issues/55199).", "published_date": "2022-05-24", "chain_len": 1, "project": "https://github.com/tensorflow/tensorflow", "commit_href": "https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e", "commit_sha": "bd4d5583ff9c8df26d47a23e508208844297310e", "patch": "SINGLE", "chain_ord": "['bd4d5583ff9c8df26d47a23e508208844297310e']", "before_first_fix_commit": "{'e74ef072ecd54ca54f3940ce9b98af796ded2a1a'}", "last_fix_commit": "bd4d5583ff9c8df26d47a23e508208844297310e", "chain_ord_pos": 1, "commit_datetime": "04/15/2022, 16:11:43", "message": "Prevent denial of service in `tf.ragged.constant`\n\nFixes #55199\n\nPiperOrigin-RevId: 442029525", "author": "Mihai Maruseac", "comments": null, "stats": "{'additions': 3, 'deletions': 0, 'total': 3}", "files": {"tensorflow/python/ops/ragged/ragged_factory_ops.py": {"additions": 3, "deletions": 0, "changes": 3, "status": "modified", "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd4d5583ff9c8df26d47a23e508208844297310e/tensorflow%2Fpython%2Fops%2Fragged%2Fragged_factory_ops.py", "patch": "@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\n     if max_depth > scalar_depth:\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\n                        \"than scalar value nesting\" % pylist)\n+    if ragged_rank is not None and max_depth < ragged_rank:\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\n+                       f\"ragged_rank={ragged_rank}\")\n \n   # If both inner_shape and ragged_rank were specified, then check that\n   # they are compatible with pylist."}}, "prior_version": " def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,     if max_depth > scalar_depth:       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"                        \"than scalar value nesting\" % pylist)    # If both inner_shape and ragged_rank were specified, then check that   # they are compatible with pylist.", "after_version": " def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,     if max_depth > scalar_depth:       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"                        \"than scalar value nesting\" % pylist)     if ragged_rank is not None and max_depth < ragged_rank:       raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"                        f\"ragged_rank={ragged_rank}\")    # If both inner_shape and ragged_rank were specified, then check that   # they are compatible with pylist.", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "GHSA-cwpm-f78v-7m5c", "cwe_id": "{'CWE-400', 'CWE-20'}", "score": 5.5, "chain": "{'https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e'}", "dataset": "osv", "summary": "Denial of service in `tf.ragged.constant` due to lack of validation ### Impact\nThe implementation of [`tf.ragged.constant`](https://github.com/tensorflow/tensorflow/blob/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python/ops/ragged/ragged_factory_ops.py#L146-L239) does not fully validate the input arguments. This results in a denial of service by consuming all available memory:\n\n```python\nimport tensorflow as tf\ntf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)\n```\n  \n### Patches\nWe have patched the issue in GitHub commit [bd4d5583ff9c8df26d47a23e508208844297310e](https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported externally via a [GitHub issue](https://github.com/tensorflow/tensorflow/issues/55199).", "published_date": "2022-05-24", "chain_len": 1, "project": "https://github.com/tensorflow/tensorflow", "commit_href": "https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e", "commit_sha": "bd4d5583ff9c8df26d47a23e508208844297310e", "patch": "SINGLE", "chain_ord": "['bd4d5583ff9c8df26d47a23e508208844297310e']", "before_first_fix_commit": "{'e74ef072ecd54ca54f3940ce9b98af796ded2a1a'}", "last_fix_commit": "bd4d5583ff9c8df26d47a23e508208844297310e", "chain_ord_pos": 1, "commit_datetime": "04/15/2022, 16:11:43", "message": "Prevent denial of service in `tf.ragged.constant`\n\nFixes #55199\n\nPiperOrigin-RevId: 442029525", "author": "Mihai Maruseac", "comments": null, "stats": "{'additions': 3, 'deletions': 0, 'total': 3}", "files": {"tensorflow/python/ops/ragged/ragged_factory_ops.py": {"additions": 3, "deletions": 0, "changes": 3, "status": "modified", "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd4d5583ff9c8df26d47a23e508208844297310e/tensorflow%2Fpython%2Fops%2Fragged%2Fragged_factory_ops.py", "patch": "@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\n     if max_depth > scalar_depth:\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\n                        \"than scalar value nesting\" % pylist)\n+    if ragged_rank is not None and max_depth < ragged_rank:\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\n+                       f\"ragged_rank={ragged_rank}\")\n \n   # If both inner_shape and ragged_rank were specified, then check that\n   # they are compatible with pylist."}}, "prior_version": " def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,     if max_depth > scalar_depth:       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"                        \"than scalar value nesting\" % pylist)    # If both inner_shape and ragged_rank were specified, then check that   # they are compatible with pylist.", "after_version": " def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,     if max_depth > scalar_depth:       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"                        \"than scalar value nesting\" % pylist)     if ragged_rank is not None and max_depth < ragged_rank:       raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"                        f\"ragged_rank={ragged_rank}\")    # If both inner_shape and ragged_rank were specified, then check that   # they are compatible with pylist.", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-f8m6-h2c7-8h9x", "cwe_id": "{'CWE-400'}", "score": 7.5, "chain": "{'https://github.com/nltk/nltk/commit/1405aad979c6b8080dbbc8e0858f89b2e3690341'}", "dataset": "osv", "summary": "Inefficient Regular Expression Complexity in nltk (word_tokenize, sent_tokenize) ### Impact\nThe vulnerability is present in [`PunktSentenceTokenizer`](https://www.nltk.org/api/nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer), [`sent_tokenize`](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.sent_tokenize)  and [`word_tokenize`](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.word_tokenize). Any users of this class, or these two functions, are vulnerable to a Regular Expression Denial of Service (ReDoS) attack. \nIn short, a specifically crafted long input to any of these vulnerable functions will cause them to take a significant amount of execution time. The effect of this vulnerability is noticeable with the following example:\n```python\nfrom nltk.tokenize import word_tokenize\n\nn = 8\nfor length in [10**i for i in range(2, n)]:\n    # Prepare a malicious input\n    text = \"a\" * length\n    start_t = time.time()\n    # Call `word_tokenize` and naively measure the execution time\n    word_tokenize(text)\n    print(f\"A length of {length:<{n}} takes {time.time() - start_t:.4f}s\")\n```\nWhich gave the following output during testing:\n```python\nA length of 100      takes 0.0060s\nA length of 1000     takes 0.0060s\nA length of 10000    takes 0.6320s\nA length of 100000   takes 56.3322s\n...\n```\nI canceled the execution of the program after running it for several hours.\n\nIf your program relies on any of the vulnerable functions for tokenizing unpredictable user input, then we would strongly recommend upgrading to a version of NLTK without the vulnerability, or applying the workaround described below.\n\n### Patches\nThe problem has been patched in NLTK 3.6.6. After the fix, running the above program gives the following result:\n```python\nA length of 100      takes 0.0070s\nA length of 1000     takes 0.0010s\nA length of 10000    takes 0.0060s\nA length of 100000   takes 0.0400s\nA length of 1000000  takes 0.3520s\nA length of 10000000 takes 3.4641s\n```\nThis output shows a linear relationship in execution time versus input length, which is desirable for regular expressions.\nWe recommend updating to NLTK 3.6.6+ if possible.\n\n### Workarounds\nThe execution time of the vulnerable functions is exponential to the length of a malicious input. With other words, the execution time can be bounded by limiting the maximum length of an input to any of the vulnerable functions. Our recommendation is to implement such a limit.\n\n### References\n* The issue showcasing the vulnerability: https://github.com/nltk/nltk/issues/2866\n* The pull request containing considerably more information on the vulnerability, and the fix: https://github.com/nltk/nltk/pull/2869\n* The commit containing the fix: 1405aad979c6b8080dbbc8e0858f89b2e3690341\n* Information on CWE-1333: Inefficient Regular Expression Complexity: https://cwe.mitre.org/data/definitions/1333.html\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [github.com/nltk/nltk](https://github.com/nltk/nltk)\n* Email us at [nltk.team@gmail.com](mailto:nltk.team@gmail.com)", "published_date": "2022-01-06", "chain_len": 1, "project": "https://github.com/nltk/nltk", "commit_href": "https://github.com/nltk/nltk/commit/1405aad979c6b8080dbbc8e0858f89b2e3690341", "commit_sha": "1405aad979c6b8080dbbc8e0858f89b2e3690341", "patch": "SINGLE", "chain_ord": "['1405aad979c6b8080dbbc8e0858f89b2e3690341']", "before_first_fix_commit": "{'0b7b076247ec41f9b6b8a94400d48ea299e4b507'}", "last_fix_commit": "1405aad979c6b8080dbbc8e0858f89b2e3690341", "chain_ord_pos": 1, "commit_datetime": "11/26/2021, 11:58:19", "message": "Resolved serious ReDoS in PunktSentenceTokenizer (#2869)\n\n* Resolved serious ReDOS in PunktSentenceTokenizer\r\n\r\n* Improve performance by relying on string split instead of re.search\r\n\r\n* Solved issue if sentence contains just one token", "author": "Tom Aarsen", "comments": null, "stats": "{'additions': 61, 'deletions': 5, 'total': 66}", "files": {"nltk/tokenize/punkt.py": {"additions": 61, "deletions": 5, "changes": 66, "status": "modified", "raw_url": "https://github.com/nltk/nltk/raw/1405aad979c6b8080dbbc8e0858f89b2e3690341/nltk%2Ftokenize%2Fpunkt.py", "patch": "@@ -266,7 +266,6 @@ def word_tokenize(self, s):\n         return self._word_tokenizer_re().findall(s)\n \n     _period_context_fmt = r\"\"\"\n-        \\S*                          # some word material\n         %(SentEndChars)s             # a potential sentence ending\n         (?=(?P<after_tok>\n             %(NonWord)s              # either other punctuation\n@@ -1284,8 +1283,7 @@ def debug_decisions(self, text):\n         See format_debug_decision() to help make this output readable.\n         \"\"\"\n \n-        for match in self._lang_vars.period_context_re().finditer(text):\n-            decision_text = match.group() + match.group(\"after_tok\")\n+        for match, decision_text in self._match_potential_end_contexts(text):\n             tokens = self._tokenize_words(decision_text)\n             tokens = list(self._annotate_first_pass(tokens))\n             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars):\n@@ -1333,10 +1331,68 @@ def sentences_from_text(self, text, realign_boundaries=True):\n         \"\"\"\n         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\n \n+    def _match_potential_end_contexts(self, text):\n+        \"\"\"\n+        Given a text, find the matches of potential sentence breaks,\n+        alongside the contexts surrounding these sentence breaks.\n+\n+        Since the fix for the ReDOS discovered in issue #2866, we no longer match\n+        the word before a potential end of sentence token. Instead, we use a separate\n+        regex for this. As a consequence, `finditer`'s desire to find non-overlapping\n+        matches no longer aids us in finding the single longest match.\n+        Where previously, we could use::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +SKIP\n+            [<re.Match object; span=(9, 18), match='acting!!!'>]\n+\n+        Now we have to find the word before (i.e. 'acting') separately, and `finditer`\n+        returns::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +NORMALIZE_WHITESPACE\n+            [<re.Match object; span=(15, 16), match='!'>,\n+            <re.Match object; span=(16, 17), match='!'>,\n+            <re.Match object; span=(17, 18), match='!'>]\n+\n+        So, we need to find the word before the match from right to left, and then manually remove\n+        the overlaps. That is what this method does::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> pst._match_potential_end_contexts(text)\n+            [(<re.Match object; span=(17, 18), match='!'>, 'acting!!! I')]\n+\n+        :param text: String of one or more sentences\n+        :type text: str\n+        :return: List of match-context tuples.\n+        :rtype: List[Tuple[re.Match, str]]\n+        \"\"\"\n+        before_words = {}\n+        matches = []\n+        for match in reversed(list(self._lang_vars.period_context_re().finditer(text))):\n+            # Ignore matches that have already been captured by matches to the right of this match\n+            if matches and match.end() > before_start:\n+                continue\n+            # Find the word before the current match\n+            split = text[: match.start()].rsplit(maxsplit=1)\n+            before_start = len(split[0]) if len(split) == 2 else 0\n+            before_words[match] = split[-1]\n+            matches.append(match)\n+\n+        return [\n+            (\n+                match,\n+                before_words[match] + match.group() + match.group(\"after_tok\"),\n+            )\n+            for match in matches[::-1]\n+        ]\n+\n     def _slices_from_text(self, text):\n         last_break = 0\n-        for match in self._lang_vars.period_context_re().finditer(text):\n-            context = match.group() + match.group(\"after_tok\")\n+        for match, context in self._match_potential_end_contexts(text):\n             if self.text_contains_sentbreak(context):\n                 yield slice(last_break, match.end())\n                 if match.group(\"next_tok\"):"}}, "prior_version": " def word_tokenize(self, s):         return self._word_tokenizer_re().findall(s)      _period_context_fmt = r\"\"\"         \\S*                          # some word material         %(SentEndChars)s             # a potential sentence ending         (?=(?P<after_tok>             %(NonWord)s              # either other punctuation def debug_decisions(self, text):         See format_debug_decision() to help make this output readable.         \"\"\"          for match in self._lang_vars.period_context_re().finditer(text):             decision_text = match.group() + match.group(\"after_tok\")             tokens = self._tokenize_words(decision_text)             tokens = list(self._annotate_first_pass(tokens))             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars): def sentences_from_text(self, text, realign_boundaries=True):         \"\"\"         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]      def _slices_from_text(self, text):         last_break = 0         for match in self._lang_vars.period_context_re().finditer(text):             context = match.group() + match.group(\"after_tok\")             if self.text_contains_sentbreak(context):                 yield slice(last_break, match.end())                 if match.group(\"next_tok\"):", "after_version": " def word_tokenize(self, s):         return self._word_tokenizer_re().findall(s)      _period_context_fmt = r\"\"\"         %(SentEndChars)s             # a potential sentence ending         (?=(?P<after_tok>             %(NonWord)s              # either other punctuation def debug_decisions(self, text):         See format_debug_decision() to help make this output readable.         \"\"\"          for match, decision_text in self._match_potential_end_contexts(text):             tokens = self._tokenize_words(decision_text)             tokens = list(self._annotate_first_pass(tokens))             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars): def sentences_from_text(self, text, realign_boundaries=True):         \"\"\"         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]      def _match_potential_end_contexts(self, text):         \"\"\"         Given a text, find the matches of potential sentence breaks,         alongside the contexts surrounding these sentence breaks.          Since the fix for the ReDOS discovered in issue #2866, we no longer match         the word before a potential end of sentence token. Instead, we use a separate         regex for this. As a consequence, `finditer`'s desire to find non-overlapping         matches no longer aids us in finding the single longest match.         Where previously, we could use::              >>> pst = PunktSentenceTokenizer()             >>> text = \"Very bad acting!!! I promise.\"             >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +SKIP             [<re.Match object; span=(9, 18), match='acting!!!'>]          Now we have to find the word before (i.e. 'acting') separately, and `finditer`         returns::              >>> pst = PunktSentenceTokenizer()             >>> text = \"Very bad acting!!! I promise.\"             >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +NORMALIZE_WHITESPACE             [<re.Match object; span=(15, 16), match='!'>,             <re.Match object; span=(16, 17), match='!'>,             <re.Match object; span=(17, 18), match='!'>]          So, we need to find the word before the match from right to left, and then manually remove         the overlaps. That is what this method does::              >>> pst = PunktSentenceTokenizer()             >>> text = \"Very bad acting!!! I promise.\"             >>> pst._match_potential_end_contexts(text)             [(<re.Match object; span=(17, 18), match='!'>, 'acting!!! I')]          :param text: String of one or more sentences         :type text: str         :return: List of match-context tuples.         :rtype: List[Tuple[re.Match, str]]         \"\"\"         before_words = {}         matches = []         for match in reversed(list(self._lang_vars.period_context_re().finditer(text))):             # Ignore matches that have already been captured by matches to the right of this match             if matches and match.end() > before_start:                 continue             # Find the word before the current match             split = text[: match.start()].rsplit(maxsplit=1)             before_start = len(split[0]) if len(split) == 2 else 0             before_words[match] = split[-1]             matches.append(match)          return [             (                 match,                 before_words[match] + match.group() + match.group(\"after_tok\"),             )             for match in matches[::-1]         ]      def _slices_from_text(self, text):         last_break = 0         for match, context in self._match_potential_end_contexts(text):             if self.text_contains_sentbreak(context):                 yield slice(last_break, match.end())                 if match.group(\"next_tok\"):", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-fh37-cx83-q542", "cwe_id": "{'CWE-306', 'CWE-269', 'CWE-287'}", "score": 5.3, "chain": "{'https://github.com/apache/airflow/commit/21cedff205e7d62675949fda2aa4616d77232b76'}", "dataset": "osv", "summary": "Improper Authentication in Apache Airflow The lineage endpoint of the deprecated Experimental API was not protected by authentication in Airflow 2.0.0. This allowed unauthenticated users to hit that endpoint. This is low-severity issue as the attacker needs to be aware of certain parameters to pass to that endpoint and even after can just get some metadata about a DAG and a Task. This issue only affects Apache Airflow 2.0.0.", "published_date": "2021-06-18", "chain_len": 1, "project": "https://github.com/apache/airflow", "commit_href": "https://github.com/apache/airflow/commit/21cedff205e7d62675949fda2aa4616d77232b76", "commit_sha": "21cedff205e7d62675949fda2aa4616d77232b76", "patch": "SINGLE", "chain_ord": "['21cedff205e7d62675949fda2aa4616d77232b76']", "before_first_fix_commit": "{'4b1a6f78d132e42f1c946f53eca89789d21bdc1d'}", "last_fix_commit": "21cedff205e7d62675949fda2aa4616d77232b76", "chain_ord_pos": 1, "commit_datetime": "01/27/2021, 21:47:45", "message": "Add authentication to lineage endpoint for experimental API (#13870)\n\n(cherry picked from commit 24a54242d56058846c7978130b3f37ca045d5142)", "author": "Ian Carroll", "comments": null, "stats": "{'additions': 1, 'deletions': 0, 'total': 1}", "files": {"airflow/www/api/experimental/endpoints.py": {"additions": 1, "deletions": 0, "changes": 1, "status": "modified", "raw_url": "https://github.com/apache/airflow/raw/21cedff205e7d62675949fda2aa4616d77232b76/airflow%2Fwww%2Fapi%2Fexperimental%2Fendpoints.py", "patch": "@@ -389,6 +389,7 @@ def delete_pool(name):\n \n \n @api_experimental.route('/lineage/<string:dag_id>/<string:execution_date>', methods=['GET'])\n+@requires_authentication\n def get_lineage(dag_id: str, execution_date: str):\n     \"\"\"Get Lineage details for a DagRun\"\"\"\n     # Convert string datetime into actual datetime"}}, "prior_version": " def delete_pool(name):   @api_experimental.route('/lineage/<string:dag_id>/<string:execution_date>', methods=['GET']) def get_lineage(dag_id: str, execution_date: str):     \"\"\"Get Lineage details for a DagRun\"\"\"     # Convert string datetime into actual datetime", "after_version": " def delete_pool(name):   @api_experimental.route('/lineage/<string:dag_id>/<string:execution_date>', methods=['GET']) @requires_authentication def get_lineage(dag_id: str, execution_date: str):     \"\"\"Get Lineage details for a DagRun\"\"\"     # Convert string datetime into actual datetime", "file_extension": "py", "cwe": "CWE-287"}
{"vuln_id": "GHSA-h8pj-cxx2-jfg2", "cwe_id": "{'CWE-20'}", "score": 9.1, "chain": "{'https://github.com/encode/httpx/pull/2185/commits/e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1'}", "dataset": "osv", "summary": "Improper Input Validation in httpx Encode OSS httpx <=1.0.0.beta0 is affected by improper input validation in `httpx.URL`, `httpx.Client` and some functions using `httpx.URL.copy_with`.", "published_date": "2022-04-29", "chain_len": 1, "project": "https://github.com/encode/httpx", "commit_href": "https://github.com/encode/httpx/pull/2185/commits/e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1", "commit_sha": "e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1", "patch": "SINGLE", "chain_ord": "['e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1']", "before_first_fix_commit": "{'b07fe7b0745e62be5ef9bce1bee9e7d7a8878552'}", "last_fix_commit": "e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1", "chain_ord_pos": 1, "commit_datetime": "04/21/2022, 06:22:38", "message": "Patch `copy_with`", "author": "lebr0nli", "comments": null, "stats": "{'additions': 5, 'deletions': 1, 'total': 6}", "files": {"httpx/_urls.py": {"additions": 5, "deletions": 1, "changes": 6, "status": "modified", "raw_url": "https://github.com/encode/httpx/raw/e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1/httpx%2F_urls.py", "patch": "@@ -484,7 +484,11 @@ def copy_with(self, **kwargs: typing.Any) -> \"URL\":\n         #  \\_/   \\______________/\\_________/ \\_________/ \\__/\n         #   |           |            |            |        |\n         # scheme     authority       path        query   fragment\n-        return URL(self._uri_reference.copy_with(**kwargs).unsplit())\n+        new_url = URL(self)\n+        new_url._uri_reference = self._uri_reference.copy_with(**kwargs)\n+        if new_url.is_absolute_url:\n+            new_url._uri_reference = new_url._uri_reference.normalize()\n+        return URL(new_url)\n \n     def copy_set_param(self, key: str, value: typing.Any = None) -> \"URL\":\n         return self.copy_with(params=self.params.set(key, value))"}}, "prior_version": " def copy_with(self, **kwargs: typing.Any) -> \"URL\":         #  \\_/   \\______________/\\_________/ \\_________/ \\__/         #   |           |            |            |        |         # scheme     authority       path        query   fragment         return URL(self._uri_reference.copy_with(**kwargs).unsplit())      def copy_set_param(self, key: str, value: typing.Any = None) -> \"URL\":         return self.copy_with(params=self.params.set(key, value))", "after_version": " def copy_with(self, **kwargs: typing.Any) -> \"URL\":         #  \\_/   \\______________/\\_________/ \\_________/ \\__/         #   |           |            |            |        |         # scheme     authority       path        query   fragment         new_url = URL(self)         new_url._uri_reference = self._uri_reference.copy_with(**kwargs)         if new_url.is_absolute_url:             new_url._uri_reference = new_url._uri_reference.normalize()         return URL(new_url)      def copy_set_param(self, key: str, value: typing.Any = None) -> \"URL\":         return self.copy_with(params=self.params.set(key, value))", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "GHSA-hj5v-574p-mj7c", "cwe_id": "{'CWE-400'}", "score": 7.5, "chain": "{'https://github.com/pytest-dev/py/pull/257/commits/4a9017dc6199d2a564b6e4b0aa39d6d8870e4144'}", "dataset": "osv", "summary": "Regular expression deinal of service in py A denial of service via regular expression in the py.path.svnwc component of py (aka python-py) through 1.9.0 could be used by attackers to cause a compute-time denial of service attack by supplying malicious input to the blame functionality.", "published_date": "2021-04-20", "chain_len": 1, "project": "https://github.com/pytest-dev/py", "commit_href": "https://github.com/pytest-dev/py/pull/257/commits/4a9017dc6199d2a564b6e4b0aa39d6d8870e4144", "commit_sha": "4a9017dc6199d2a564b6e4b0aa39d6d8870e4144", "patch": "SINGLE", "chain_ord": "['4a9017dc6199d2a564b6e4b0aa39d6d8870e4144']", "before_first_fix_commit": "{'2da2caea38812eaa3ce09dd5292e3635ce9b16c8'}", "last_fix_commit": "4a9017dc6199d2a564b6e4b0aa39d6d8870e4144", "chain_ord_pos": 1, "commit_datetime": "09/04/2020, 10:57:26", "message": "svnwc: fix regular expression vulnerable to DoS in blame functionality\n\nThe subpattern `\\d+\\s*\\S+` is ambiguous which makes the pattern subject\nto catastrophic backtracing given a string like `\"1\" * 5000`.\n\nSVN blame output seems to always have at least one space between the\nrevision number and the user name, so the ambiguity can be fixed by\nchanging the `*` to `+`.\n\nFixes #256.", "author": "Ran Benita", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"py/_path/svnwc.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/pytest-dev/py/raw/4a9017dc6199d2a564b6e4b0aa39d6d8870e4144/py%2F_path%2Fsvnwc.py", "patch": "@@ -396,7 +396,7 @@ def makecmdoptions(self):\n     def __str__(self):\n         return \"<SvnAuth username=%s ...>\" %(self.username,)\n \n-rex_blame = re.compile(r'\\s*(\\d+)\\s*(\\S+) (.*)')\n+rex_blame = re.compile(r'\\s*(\\d+)\\s+(\\S+) (.*)')\n \n class SvnWCCommandPath(common.PathBase):\n     \"\"\" path implementation offering access/modification to svn working copies."}}, "prior_version": " def makecmdoptions(self):     def __str__(self):         return \"<SvnAuth username=%s ...>\" %(self.username,)  rex_blame = re.compile(r'\\s*(\\d+)\\s*(\\S+) (.*)')  class SvnWCCommandPath(common.PathBase):     \"\"\" path implementation offering access/modification to svn working copies.", "after_version": " def makecmdoptions(self):     def __str__(self):         return \"<SvnAuth username=%s ...>\" %(self.username,)  rex_blame = re.compile(r'\\s*(\\d+)\\s+(\\S+) (.*)')  class SvnWCCommandPath(common.PathBase):     \"\"\" path implementation offering access/modification to svn working copies.", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-hq37-853p-g5cf", "cwe_id": "{'CWE-400'}", "score": 0.0, "chain": "{'https://github.com/Kozea/CairoSVG/commit/cfc9175e590531d90384aa88845052de53d94bf3'}", "dataset": "osv", "summary": "Regular Expression Denial of Service in CairoSVG # Doyensec Vulnerability Advisory \n\n* Regular Expression Denial of Service (REDoS) in cairosvg\n* Affected Product: CairoSVG v2.0.0+\n* Vendor: https://github.com/Kozea\n* Severity: Medium\n* Vulnerability Class: Denial of Service\n* Author(s): Ben Caller ([Doyensec](https://doyensec.com))\n\n## Summary\n\nWhen processing SVG files, the python package CairoSVG uses two regular expressions which are vulnerable to Regular Expression Denial of Service (REDoS).\nIf an attacker provides a malicious SVG, it can make cairosvg get stuck processing the file for a very long time.\n\n## Technical description\n\nThe vulnerable regular expressions are\n\nhttps://github.com/Kozea/CairoSVG/blob/9c4a982b9a021280ad90e89707eacc1d114e4ac4/cairosvg/colors.py#L190-L191\n\nThe section between 'rgb(' and the final ')' contains multiple overlapping groups.\n\nSince all three infinitely repeating groups accept spaces, a long string of spaces causes catastrophic backtracking when it is not followed by a closing parenthesis.\n\nThe complexity is cubic, so doubling the length of the malicious string of spaces makes processing take 8 times as long.\n\n## Reproduction steps\n\nCreate a malicious SVG of the form:\n\n    <svg width=\"1\" height=\"1\"><rect fill=\"rgb(                     ;\"/></svg>\n\nwith the following code:\n\n    '<svg width=\"1\" height=\"1\"><rect fill=\"rgb(' + (' ' * 3456) + ';\"/></svg>'\n\nNote that there is no closing parenthesis before the semi-colon.\n\nRun cairosvg e.g.:\n\n    cairosvg cairo-redos.svg -o x.png\n\nand notice that it hangs at 100% CPU. Increasing the number of spaces increases the processing time with cubic complexity.\n\n## Remediation\n\nFix the regexes to avoid overlapping parts. Perhaps remove the [ \\n\\r\\t]* groups from the regex, and use .strip() on the returned capture group.\n\n## Disclosure timeline\n\n- 2020-12-30: Vulnerability disclosed via email to CourtBouillon", "published_date": "2021-01-06", "chain_len": 1, "project": "https://github.com/Kozea/CairoSVG", "commit_href": "https://github.com/Kozea/CairoSVG/commit/cfc9175e590531d90384aa88845052de53d94bf3", "commit_sha": "cfc9175e590531d90384aa88845052de53d94bf3", "patch": "SINGLE", "chain_ord": "['cfc9175e590531d90384aa88845052de53d94bf3']", "before_first_fix_commit": "{'9c4a982b9a021280ad90e89707eacc1d114e4ac4', '063185b60588a41d4df661ad70f9f7b699901abc'}", "last_fix_commit": "cfc9175e590531d90384aa88845052de53d94bf3", "chain_ord_pos": 1, "commit_datetime": "01/06/2021, 14:43:14", "message": "Merge pull request from GHSA-hq37-853p-g5cf\n\nDon\u2019t use overlapping groups for regular expressions", "author": "Guillaume Ayoub", "comments": null, "stats": "{'additions': 4, 'deletions': 4, 'total': 8}", "files": {"cairosvg/colors.py": {"additions": 4, "deletions": 4, "changes": 8, "status": "modified", "raw_url": "https://github.com/Kozea/CairoSVG/raw/cfc9175e590531d90384aa88845052de53d94bf3/cairosvg%2Fcolors.py", "patch": "@@ -187,8 +187,8 @@\n     'transparent': (0, 0, 0, 0),\n }\n \n-RGBA = re.compile(r'rgba\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)')\n-RGB = re.compile(r'rgb\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)')\n+RGBA = re.compile(r'rgba\\((.+?)\\)')\n+RGB = re.compile(r'rgb\\((.+?)\\)')\n HEX_RRGGBB = re.compile('#[0-9a-f]{6}')\n HEX_RGB = re.compile('#[0-9a-f]{3}')\n \n@@ -212,14 +212,14 @@ def color(string, opacity=1):\n     if match:\n         r, g, b, a = tuple(\n             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255\n-            for i in match.group(1).split(','))\n+            for i in match.group(1).strip().split(','))\n         return (r, g, b, a * 255 * opacity)\n \n     match = RGB.search(string)\n     if match:\n         r, g, b = tuple(\n             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255\n-            for i in match.group(1).split(','))\n+            for i in match.group(1).strip().split(','))\n         return (r, g, b, opacity)\n \n     match = HEX_RRGGBB.search(string)"}}, "prior_version": "     'transparent': (0, 0, 0, 0), }  RGBA = re.compile(r'rgba\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)') RGB = re.compile(r'rgb\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)') HEX_RRGGBB = re.compile('#[0-9a-f]{6}') HEX_RGB = re.compile('#[0-9a-f]{3}')  def color(string, opacity=1):     if match:         r, g, b, a = tuple(             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255             for i in match.group(1).split(','))         return (r, g, b, a * 255 * opacity)      match = RGB.search(string)     if match:         r, g, b = tuple(             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255             for i in match.group(1).split(','))         return (r, g, b, opacity)      match = HEX_RRGGBB.search(string)", "after_version": "     'transparent': (0, 0, 0, 0), }  RGBA = re.compile(r'rgba\\((.+?)\\)') RGB = re.compile(r'rgb\\((.+?)\\)') HEX_RRGGBB = re.compile('#[0-9a-f]{6}') HEX_RGB = re.compile('#[0-9a-f]{3}')  def color(string, opacity=1):     if match:         r, g, b, a = tuple(             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255             for i in match.group(1).strip().split(','))         return (r, g, b, a * 255 * opacity)      match = RGB.search(string)     if match:         r, g, b = tuple(             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255             for i in match.group(1).strip().split(','))         return (r, g, b, opacity)      match = HEX_RRGGBB.search(string)", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-hwv5-w8gm-fq9f", "cwe_id": "{'CWE-22'}", "score": 3.5, "chain": "{'https://github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75'}", "dataset": "osv", "summary": "Directory Traversal vulnerability in GET/PUT allows attackers to Disclose Information or Write Files via a crafted GET/PUT request ### Impact\n\n#### Information Disclosure\n\nWhen the GET method is attacked, attackers can read files which have a `.data` suffix and which are accompanied by a JSON file with the `.meta` suffix. This can lead to Information Disclosure and in some shared-hosting scenarios also to circumvention of authentication or other limitations on the outbound (GET) traffic.\n\nFor example, in a scenario where a single server has multiple instances of the application running (with separate DATA_ROOT settings), an attacker who has knowledge about the directory structure is able to read files from any other instance to which the process has read access.\n\nIf instances have individual authentication (for example, HTTP authentication via a reverse proxy, source IP based filtering) or other restrictions (such as quotas), attackers may circumvent those limits in such a scenario by using the Directory Traversal to retrieve data from the other instances.\n\n#### File Write\n\nIf the associated XMPP server (or anyone knowing the SECRET_KEY) is malicious, they can write files outside the DATA_ROOT. The files which are written are constrained to have the `.meta` and the `.data` suffixes; the `.meta` file will contain the JSON with the Content-Type of the original request and the `.data` file will contain the payload.\n\n### Patches\n\nPR #12 fixes the issue. The PR has been merged into version 0.4.0 and 0.4.0 has been released and pushed to PyPI. Users are advised to upgrade immediately.\n\n### Workarounds\n\n- Apache can apparently be configured to filter such malicious paths when reverse-proxying. \n- There are no other workarounds known.\n\n### References\n\n- [Pull Request #12](https://github.com/horazont/xmpp-http-upload/pull/12)", "published_date": "2020-10-06", "chain_len": 1, "project": "https://github.com/horazont/xmpp-http-upload", "commit_href": "https://github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75", "commit_sha": "82056540191e89f0cd697c81f57714c00962ed75", "patch": "SINGLE", "chain_ord": "['82056540191e89f0cd697c81f57714c00962ed75']", "before_first_fix_commit": "{'f0fc7443c06a0e8aecb5696fc2bd513a2cc8b611'}", "last_fix_commit": "82056540191e89f0cd697c81f57714c00962ed75", "chain_ord_pos": 1, "commit_datetime": "10/05/2020, 23:06:21", "message": "Simplify path handling, use safe_join\n\nThe current implementation of sanitized_join did not handle\n\"..\" properly. The problem is, that .absolute() does not do\nwhat .resolve() does, but .resolve() does not work on non\nexistant paths.\n\nAnyway, flask has a function exactly for this: safe_join.\n\nSo let's use that one.\n\nWhile at it, simplified the whole path handling a bit.", "author": "Christian Tacke", "comments": null, "stats": "{'additions': 15, 'deletions': 34, 'total': 49}", "files": {"xhu.py": {"additions": 15, "deletions": 34, "changes": 49, "status": "modified", "raw_url": "https://github.com/horazont/xmpp-http-upload/raw/82056540191e89f0cd697c81f57714c00962ed75/xhu.py", "patch": "@@ -29,6 +29,7 @@\n import typing\n \n import flask\n+import werkzeug.exceptions\n \n app = flask.Flask(\"xmpp-http-upload\")\n app.config.from_envvar(\"XMPP_HTTP_UPLOAD_CONFIG\")\n@@ -39,16 +40,11 @@\n     CORS(app)\n \n \n-def sanitized_join(path: str, root: pathlib.Path) -> pathlib.Path:\n-    result = (root / path).absolute()\n-    if not str(result).startswith(str(root) + \"/\"):\n-        raise ValueError(\"resulting path is outside root\")\n-    return result\n-\n-\n-def get_paths(base_path: pathlib.Path):\n-    data_file = pathlib.Path(str(base_path) + \".data\")\n-    metadata_file = pathlib.Path(str(base_path) + \".meta\")\n+def get_paths(root: str, sub_path: str) \\\n+        -> typing.Tuple[pathlib.Path, pathlib.Path]:\n+    base_path = flask.safe_join(root, sub_path)\n+    data_file = pathlib.Path(base_path + \".data\")\n+    metadata_file = pathlib.Path(base_path + \".meta\")\n \n     return data_file, metadata_file\n \n@@ -58,15 +54,10 @@ def load_metadata(metadata_file):\n         return json.load(f)\n \n \n-def get_info(path: str, root: pathlib.Path) -> typing.Tuple[\n+def get_info(path: str) -> typing.Tuple[\n         pathlib.Path,\n         dict]:\n-    dest_path = sanitized_join(\n-        path,\n-        pathlib.Path(app.config[\"DATA_ROOT\"]),\n-    )\n-\n-    data_file, metadata_file = get_paths(dest_path)\n+    data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\n \n     return data_file, load_metadata(metadata_file)\n \n@@ -104,11 +95,8 @@ def stream_file(src, dest, nbytes):\n @app.route(\"/<path:path>\", methods=[\"PUT\"])\n def put_file(path):\n     try:\n-        dest_path = sanitized_join(\n-            path,\n-            pathlib.Path(app.config[\"DATA_ROOT\"]),\n-        )\n-    except ValueError:\n+        data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\n+    except werkzeug.exceptions.NotFound:\n         return flask.Response(\n             \"Not Found\",\n             404,\n@@ -134,8 +122,7 @@ def put_file(path):\n         \"application/octet-stream\",\n     )\n \n-    dest_path.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\n-    data_file, metadata_file = get_paths(dest_path)\n+    data_file.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\n \n     try:\n         with write_file(data_file) as fout:\n@@ -189,13 +176,10 @@ def generate_headers(response_headers, metadata_headers):\n @app.route(\"/<path:path>\", methods=[\"HEAD\"])\n def head_file(path):\n     try:\n-        data_file, metadata = get_info(\n-            path,\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\n-        )\n+        data_file, metadata = get_info(path)\n \n         stat = data_file.stat()\n-    except (OSError, ValueError):\n+    except (OSError, werkzeug.exceptions.NotFound):\n         return flask.Response(\n             \"Not Found\",\n             404,\n@@ -214,11 +198,8 @@ def head_file(path):\n @app.route(\"/<path:path>\", methods=[\"GET\"])\n def get_file(path):\n     try:\n-        data_file, metadata = get_info(\n-            path,\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\n-        )\n-    except (OSError, ValueError):\n+        data_file, metadata = get_info(path)\n+    except (OSError, werkzeug.exceptions.NotFound):\n         return flask.Response(\n             \"Not Found\",\n             404,"}}, "prior_version": " import typing  import flask  app = flask.Flask(\"xmpp-http-upload\") app.config.from_envvar(\"XMPP_HTTP_UPLOAD_CONFIG\")     CORS(app)   def sanitized_join(path: str, root: pathlib.Path) -> pathlib.Path:     result = (root / path).absolute()     if not str(result).startswith(str(root) + \"/\"):         raise ValueError(\"resulting path is outside root\")     return result   def get_paths(base_path: pathlib.Path):     data_file = pathlib.Path(str(base_path) + \".data\")     metadata_file = pathlib.Path(str(base_path) + \".meta\")      return data_file, metadata_file  def load_metadata(metadata_file):         return json.load(f)   def get_info(path: str, root: pathlib.Path) -> typing.Tuple[         pathlib.Path,         dict]:     dest_path = sanitized_join(         path,         pathlib.Path(app.config[\"DATA_ROOT\"]),     )      data_file, metadata_file = get_paths(dest_path)      return data_file, load_metadata(metadata_file)  def stream_file(src, dest, nbytes): @app.route(\"/<path:path>\", methods=[\"PUT\"]) def put_file(path):     try:         dest_path = sanitized_join(             path,             pathlib.Path(app.config[\"DATA_ROOT\"]),         )     except ValueError:         return flask.Response(             \"Not Found\",             404, def put_file(path):         \"application/octet-stream\",     )      dest_path.parent.mkdir(parents=True, exist_ok=True, mode=0o770)     data_file, metadata_file = get_paths(dest_path)      try:         with write_file(data_file) as fout: def generate_headers(response_headers, metadata_headers): @app.route(\"/<path:path>\", methods=[\"HEAD\"]) def head_file(path):     try:         data_file, metadata = get_info(             path,             pathlib.Path(app.config[\"DATA_ROOT\"])         )          stat = data_file.stat()     except (OSError, ValueError):         return flask.Response(             \"Not Found\",             404, def head_file(path): @app.route(\"/<path:path>\", methods=[\"GET\"]) def get_file(path):     try:         data_file, metadata = get_info(             path,             pathlib.Path(app.config[\"DATA_ROOT\"])         )     except (OSError, ValueError):         return flask.Response(             \"Not Found\",             404,", "after_version": " import typing  import flask import werkzeug.exceptions  app = flask.Flask(\"xmpp-http-upload\") app.config.from_envvar(\"XMPP_HTTP_UPLOAD_CONFIG\")     CORS(app)   def get_paths(root: str, sub_path: str) \\         -> typing.Tuple[pathlib.Path, pathlib.Path]:     base_path = flask.safe_join(root, sub_path)     data_file = pathlib.Path(base_path + \".data\")     metadata_file = pathlib.Path(base_path + \".meta\")      return data_file, metadata_file  def load_metadata(metadata_file):         return json.load(f)   def get_info(path: str) -> typing.Tuple[         pathlib.Path,         dict]:     data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)      return data_file, load_metadata(metadata_file)  def stream_file(src, dest, nbytes): @app.route(\"/<path:path>\", methods=[\"PUT\"]) def put_file(path):     try:         data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)     except werkzeug.exceptions.NotFound:         return flask.Response(             \"Not Found\",             404, def put_file(path):         \"application/octet-stream\",     )      data_file.parent.mkdir(parents=True, exist_ok=True, mode=0o770)      try:         with write_file(data_file) as fout: def generate_headers(response_headers, metadata_headers): @app.route(\"/<path:path>\", methods=[\"HEAD\"]) def head_file(path):     try:         data_file, metadata = get_info(path)          stat = data_file.stat()     except (OSError, werkzeug.exceptions.NotFound):         return flask.Response(             \"Not Found\",             404, def head_file(path): @app.route(\"/<path:path>\", methods=[\"GET\"]) def get_file(path):     try:         data_file, metadata = get_info(path)     except (OSError, werkzeug.exceptions.NotFound):         return flask.Response(             \"Not Found\",             404,", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-j7c4-2xj8-wm7r", "cwe_id": "{'CWE-20'}", "score": 7.5, "chain": "{'https://github.com/latchset/kdcproxy/commit/f274aa6787cb8b3ec1cc12c440a56665b7231882'}", "dataset": "osv", "summary": "Moderate severity vulnerability that affects kdcproxy python-kdcproxy before 0.3.2 allows remote attackers to cause a denial of service via a large POST request.", "published_date": "2018-11-01", "chain_len": 1, "project": "https://github.com/latchset/kdcproxy", "commit_href": "https://github.com/latchset/kdcproxy/commit/f274aa6787cb8b3ec1cc12c440a56665b7231882", "commit_sha": "f274aa6787cb8b3ec1cc12c440a56665b7231882", "patch": "SINGLE", "chain_ord": "['f274aa6787cb8b3ec1cc12c440a56665b7231882']", "before_first_fix_commit": "{'e4a71193099cd395578bcf32f4eb8beaa7da3e43'}", "last_fix_commit": "f274aa6787cb8b3ec1cc12c440a56665b7231882", "chain_ord_pos": 1, "commit_datetime": "08/03/2015, 18:38:49", "message": "Enforce a maximum packet length\n\nPermanently fixes CVE-2015-5159 for all applications.", "author": "Nathaniel McCallum", "comments": null, "stats": "{'additions': 6, 'deletions': 1, 'total': 7}", "files": {"kdcproxy/__init__.py": {"additions": 6, "deletions": 1, "changes": 7, "status": "modified", "raw_url": "https://github.com/latchset/kdcproxy/raw/f274aa6787cb8b3ec1cc12c440a56665b7231882/kdcproxy%2F__init__.py", "patch": "@@ -61,6 +61,7 @@ def __str__(self):\n \n \n class Application:\n+    MAX_LENGTH = 128 * 1024\n     SOCKTYPES = {\n         \"tcp\": socket.SOCK_STREAM,\n         \"udp\": socket.SOCK_DGRAM,\n@@ -180,7 +181,11 @@ def __call__(self, env, start_response):\n             try:\n                 length = int(env[\"CONTENT_LENGTH\"])\n             except AttributeError:\n-                length = -1\n+                raise HTTPException(411, \"Length required.\")\n+            if length < 0:\n+                raise HTTPException(411, \"Length required.\")\n+            if length > self.MAX_LENGTH:\n+                raise HTTPException(413, \"Request entity too large.\")\n             try:\n                 pr = codec.decode(env[\"wsgi.input\"].read(length))\n             except codec.ParsingError as e:"}}, "prior_version": " def __str__(self):   class Application:     SOCKTYPES = {         \"tcp\": socket.SOCK_STREAM,         \"udp\": socket.SOCK_DGRAM, def __call__(self, env, start_response):             try:                 length = int(env[\"CONTENT_LENGTH\"])             except AttributeError:                 length = -1             try:                 pr = codec.decode(env[\"wsgi.input\"].read(length))             except codec.ParsingError as e:", "after_version": " def __str__(self):   class Application:     MAX_LENGTH = 128 * 1024     SOCKTYPES = {         \"tcp\": socket.SOCK_STREAM,         \"udp\": socket.SOCK_DGRAM, def __call__(self, env, start_response):             try:                 length = int(env[\"CONTENT_LENGTH\"])             except AttributeError:                 raise HTTPException(411, \"Length required.\")             if length < 0:                 raise HTTPException(411, \"Length required.\")             if length > self.MAX_LENGTH:                 raise HTTPException(413, \"Request entity too large.\")             try:                 pr = codec.decode(env[\"wsgi.input\"].read(length))             except codec.ParsingError as e:", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "GHSA-mq5p-2mcr-m52j", "cwe_id": "{'CWE-94'}", "score": 0.0, "chain": "{'https://github.com/jupyterhub/nbgitpuller/commit/07690644f29a566011dd0d7ba14cae3eb0490481'}", "dataset": "osv", "summary": "Code injection in nbgitpuller ### Impact\n\nDue to an unsanitized input, visiting maliciously crafted links could result in arbitrary code execution in the user environment.\n\n### Patches\n\n0.10.2\n\n### Workarounds\n\nNone, other than upgrade to 0.10.2 or downgrade to 0.8.x.\n\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Open an issue in [nbgitpuller](https://github.com/jupyterhub/nbgitpuller/issues)\n* Email our security team at [security@ipython.org](mailto:security@ipython.org)", "published_date": "2021-08-30", "chain_len": 1, "project": "https://github.com/jupyterhub/nbgitpuller", "commit_href": "https://github.com/jupyterhub/nbgitpuller/commit/07690644f29a566011dd0d7ba14cae3eb0490481", "commit_sha": "07690644f29a566011dd0d7ba14cae3eb0490481", "patch": "SINGLE", "chain_ord": "['07690644f29a566011dd0d7ba14cae3eb0490481']", "before_first_fix_commit": "{'f25d3f2685035c11bd668d48e71caf4fc245ba68', '2cad6147f1769a962f8d0733045967663add53cb'}", "last_fix_commit": "07690644f29a566011dd0d7ba14cae3eb0490481", "chain_ord_pos": 1, "commit_datetime": "08/25/2021, 12:23:02", "message": "Merge pull request from GHSA-mq5p-2mcr-m52j\n\nmake positional args explicit", "author": "Erik Sundell", "comments": null, "stats": "{'additions': 4, 'deletions': 4, 'total': 8}", "files": {"nbgitpuller/pull.py": {"additions": 4, "deletions": 4, "changes": 8, "status": "modified", "raw_url": "https://github.com/jupyterhub/nbgitpuller/raw/07690644f29a566011dd0d7ba14cae3eb0490481/nbgitpuller%2Fpull.py", "patch": "@@ -88,13 +88,13 @@ def branch_exists(self, branch):\n         \"\"\"\n         try:\n             heads = subprocess.run(\n-                [\"git\", \"ls-remote\", \"--heads\", self.git_url],\n+                [\"git\", \"ls-remote\", \"--heads\", \"--\", self.git_url],\n                 capture_output=True,\n                 text=True,\n                 check=True\n             )\n             tags = subprocess.run(\n-                [\"git\", \"ls-remote\", \"--tags\", self.git_url],\n+                [\"git\", \"ls-remote\", \"--tags\", \"--\", self.git_url],\n                 capture_output=True,\n                 text=True,\n                 check=True\n@@ -118,7 +118,7 @@ def resolve_default_branch(self):\n         \"\"\"\n         try:\n             head_branch = subprocess.run(\n-                [\"git\", \"ls-remote\", \"--symref\", self.git_url, \"HEAD\"],\n+                [\"git\", \"ls-remote\", \"--symref\", \"--\", self.git_url, \"HEAD\"],\n                 capture_output=True,\n                 text=True,\n                 check=True\n@@ -154,7 +154,7 @@ def initialize_repo(self):\n         if self.depth and self.depth > 0:\n             clone_args.extend(['--depth', str(self.depth)])\n         clone_args.extend(['--branch', self.branch_name])\n-        clone_args.extend([self.git_url, self.repo_dir])\n+        clone_args.extend([\"--\", self.git_url, self.repo_dir])\n         yield from execute_cmd(clone_args)\n         logging.info('Repo {} initialized'.format(self.repo_dir))"}}, "prior_version": " def branch_exists(self, branch):         \"\"\"         try:             heads = subprocess.run(                 [\"git\", \"ls-remote\", \"--heads\", self.git_url],                 capture_output=True,                 text=True,                 check=True             )             tags = subprocess.run(                 [\"git\", \"ls-remote\", \"--tags\", self.git_url],                 capture_output=True,                 text=True,                 check=True def resolve_default_branch(self):         \"\"\"         try:             head_branch = subprocess.run(                 [\"git\", \"ls-remote\", \"--symref\", self.git_url, \"HEAD\"],                 capture_output=True,                 text=True,                 check=True def initialize_repo(self):         if self.depth and self.depth > 0:             clone_args.extend(['--depth', str(self.depth)])         clone_args.extend(['--branch', self.branch_name])         clone_args.extend([self.git_url, self.repo_dir])         yield from execute_cmd(clone_args)         logging.info('Repo {} initialized'.format(self.repo_dir)) ", "after_version": " def branch_exists(self, branch):         \"\"\"         try:             heads = subprocess.run(                 [\"git\", \"ls-remote\", \"--heads\", \"--\", self.git_url],                 capture_output=True,                 text=True,                 check=True             )             tags = subprocess.run(                 [\"git\", \"ls-remote\", \"--tags\", \"--\", self.git_url],                 capture_output=True,                 text=True,                 check=True def resolve_default_branch(self):         \"\"\"         try:             head_branch = subprocess.run(                 [\"git\", \"ls-remote\", \"--symref\", \"--\", self.git_url, \"HEAD\"],                 capture_output=True,                 text=True,                 check=True def initialize_repo(self):         if self.depth and self.depth > 0:             clone_args.extend(['--depth', str(self.depth)])         clone_args.extend(['--branch', self.branch_name])         clone_args.extend([\"--\", self.git_url, self.repo_dir])         yield from execute_cmd(clone_args)         logging.info('Repo {} initialized'.format(self.repo_dir)) ", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "GHSA-mr7p-25v2-35wr", "cwe_id": "{'CWE-22'}", "score": 7.5, "chain": "{'https://github.com/nltk/nltk/commit/f59d7ed8df2e0e957f7f247fe218032abdbe9a10'}", "dataset": "osv", "summary": "Path Traversal in nltk NLTK Downloader before 3.4.5 is vulnerable to a directory traversal, allowing attackers to write arbitrary files via a ../ (dot dot slash) in an NLTK package (ZIP archive) that is mishandled during extraction.", "published_date": "2019-08-23", "chain_len": 1, "project": "https://github.com/nltk/nltk", "commit_href": "https://github.com/nltk/nltk/commit/f59d7ed8df2e0e957f7f247fe218032abdbe9a10", "commit_sha": "f59d7ed8df2e0e957f7f247fe218032abdbe9a10", "patch": "SINGLE", "chain_ord": "['f59d7ed8df2e0e957f7f247fe218032abdbe9a10']", "before_first_fix_commit": "{'2554ff48feed878ba7e830ada9825196f3eaa86a'}", "last_fix_commit": "f59d7ed8df2e0e957f7f247fe218032abdbe9a10", "chain_ord_pos": 1, "commit_datetime": "08/20/2019, 10:35:00", "message": "CVE-2019-14751:\nFixed security bug in downloader\n(https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-14751)", "author": "Steven Bird", "comments": "{'com_1': {'author': 'greysteil', 'datetime': '08/26/2019, 11:01:35', 'body': \"Thanks for this @stevenbird, and for all your work on `nltk`.\\r\\n\\r\\nHave you got 5 minutes to talk me through the process you went through fixing this, and any way GitHub can help? I'm on GitHub's security team and am working to make it easier for maintainers to alert users of security vulnerabilities.\\r\\n\\r\\nCurrently we have the security alert emails (which we're working to improve) and Security Advisories (the security tab on this repo). In future we're planning to make it easy for maintainers to apply for CVEs through GitHub (via creating Security Advisories).\\r\\n\\r\\nWas there any part of the flow of finding, fixing, and alerting users of this vulnerability that GitHub could have helped with? Or anything we're doing now that you'd like us to do differently?\\r\\n\\r\\nAny feedback very much appreciated. I'm on greysteil@github.com if you'd rather email it privately.\\r\\n\\r\\nThanks for all your do, and please don't hesitate to reach out if there's ever any way GitHub can help.\"}}", "stats": "{'additions': 1, 'deletions': 35, 'total': 36}", "files": {"nltk/downloader.py": {"additions": 1, "deletions": 35, "changes": 36, "status": "modified", "raw_url": "https://github.com/nltk/nltk/raw/f59d7ed8df2e0e957f7f247fe218032abdbe9a10/nltk%2Fdownloader.py", "patch": "@@ -2260,42 +2260,8 @@ def _unzip_iter(filename, root, verbose=True):\n         yield ErrorMessage(filename, e)\n         return\n \n-    # Get lists of directories & files\n-    namelist = zf.namelist()\n-    dirlist = set()\n-    for x in namelist:\n-        if x.endswith('/'):\n-            dirlist.add(x)\n-        else:\n-            dirlist.add(x.rsplit('/', 1)[0] + '/')\n-    filelist = [x for x in namelist if not x.endswith('/')]\n-\n-    # Create the target directory if it doesn't exist\n-    if not os.path.exists(root):\n-        os.mkdir(root)\n-\n-    # Create the directory structure\n-    for dirname in sorted(dirlist):\n-        pieces = dirname[:-1].split('/')\n-        for i in range(len(pieces)):\n-            dirpath = os.path.join(root, *pieces[: i + 1])\n-            if not os.path.exists(dirpath):\n-                os.mkdir(dirpath)\n-\n-    # Extract files.\n-    for i, filename in enumerate(filelist):\n-        filepath = os.path.join(root, *filename.split('/'))\n-\n-        try:\n-            with open(filepath, 'wb') as dstfile, zf.open(filename) as srcfile:\n-                shutil.copyfileobj(srcfile, dstfile)\n-        except Exception as e:\n-            yield ErrorMessage(filename, e)\n-            return\n+    zf.extractall(root)\n \n-        if verbose and (i * 10 / len(filelist) > (i - 1) * 10 / len(filelist)):\n-            sys.stdout.write('.')\n-            sys.stdout.flush()\n     if verbose:\n         print()"}}, "prior_version": " def _unzip_iter(filename, root, verbose=True):         yield ErrorMessage(filename, e)         return      # Get lists of directories & files     namelist = zf.namelist()     dirlist = set()     for x in namelist:         if x.endswith('/'):             dirlist.add(x)         else:             dirlist.add(x.rsplit('/', 1)[0] + '/')     filelist = [x for x in namelist if not x.endswith('/')]      # Create the target directory if it doesn't exist     if not os.path.exists(root):         os.mkdir(root)      # Create the directory structure     for dirname in sorted(dirlist):         pieces = dirname[:-1].split('/')         for i in range(len(pieces)):             dirpath = os.path.join(root, *pieces[: i + 1])             if not os.path.exists(dirpath):                 os.mkdir(dirpath)      # Extract files.     for i, filename in enumerate(filelist):         filepath = os.path.join(root, *filename.split('/'))          try:             with open(filepath, 'wb') as dstfile, zf.open(filename) as srcfile:                 shutil.copyfileobj(srcfile, dstfile)         except Exception as e:             yield ErrorMessage(filename, e)             return          if verbose and (i * 10 / len(filelist) > (i - 1) * 10 / len(filelist)):             sys.stdout.write('.')             sys.stdout.flush()     if verbose:         print() ", "after_version": " def _unzip_iter(filename, root, verbose=True):         yield ErrorMessage(filename, e)         return      zf.extractall(root)      if verbose:         print() ", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-qh9q-34h6-hcv9", "cwe_id": "{'CWE-12', 'CWE-22'}", "score": 7.5, "chain": "{'https://github.com/mkdocs/mkdocs/pull/2604/commits/cddc453c9d49298e60e7d56fb71130c151cbcbe5'}", "dataset": "osv", "summary": "Directory traversal in mkdocs The mkdocs 1.2.2 built-in dev-server allows directory traversal using the port 8000, enabling remote exploitation to obtain :sensitive information.", "published_date": "2021-10-12", "chain_len": 1, "project": "https://github.com/mkdocs/mkdocs", "commit_href": "https://github.com/mkdocs/mkdocs/pull/2604/commits/cddc453c9d49298e60e7d56fb71130c151cbcbe5", "commit_sha": "cddc453c9d49298e60e7d56fb71130c151cbcbe5", "patch": "SINGLE", "chain_ord": "['cddc453c9d49298e60e7d56fb71130c151cbcbe5']", "before_first_fix_commit": "{'c426455878556baa34cc829c579337236d335581'}", "last_fix_commit": "cddc453c9d49298e60e7d56fb71130c151cbcbe5", "chain_ord_pos": 1, "commit_datetime": "10/10/2021, 08:52:05", "message": "Prevent directory traversal in the dev server", "author": "Oleh Prypin", "comments": null, "stats": "{'additions': 4, 'deletions': 1, 'total': 5}", "files": {"mkdocs/livereload/__init__.py": {"additions": 4, "deletions": 1, "changes": 5, "status": "modified", "raw_url": "https://github.com/mkdocs/mkdocs/raw/cddc453c9d49298e60e7d56fb71130c151cbcbe5/mkdocs%2Flivereload%2F__init__.py", "patch": "@@ -4,6 +4,7 @@\n import mimetypes\n import os\n import os.path\n+import posixpath\n import re\n import socketserver\n import threading\n@@ -183,9 +184,11 @@ def condition():\n         if path == \"/js/livereload.js\":\n             file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"livereload.js\")\n         elif path.startswith(self.mount_path):\n-            rel_file_path = path[len(self.mount_path):].lstrip(\"/\")\n+            rel_file_path = path[len(self.mount_path):]\n             if path.endswith(\"/\"):\n                 rel_file_path += \"index.html\"\n+            # Prevent directory traversal - normalize the path.\n+            rel_file_path = posixpath.normpath(\"/\" + rel_file_path).lstrip(\"/\")\n             file_path = os.path.join(self.root, rel_file_path)\n         elif path == \"/\":\n             start_response(\"302 Found\", [(\"Location\", self.mount_path)])"}}, "prior_version": " import mimetypes import os import os.path import re import socketserver import threading def condition():         if path == \"/js/livereload.js\":             file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"livereload.js\")         elif path.startswith(self.mount_path):             rel_file_path = path[len(self.mount_path):].lstrip(\"/\")             if path.endswith(\"/\"):                 rel_file_path += \"index.html\"             file_path = os.path.join(self.root, rel_file_path)         elif path == \"/\":             start_response(\"302 Found\", [(\"Location\", self.mount_path)])", "after_version": " import mimetypes import os import os.path import posixpath import re import socketserver import threading def condition():         if path == \"/js/livereload.js\":             file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"livereload.js\")         elif path.startswith(self.mount_path):             rel_file_path = path[len(self.mount_path):]             if path.endswith(\"/\"):                 rel_file_path += \"index.html\"             # Prevent directory traversal - normalize the path.             rel_file_path = posixpath.normpath(\"/\" + rel_file_path).lstrip(\"/\")             file_path = os.path.join(self.root, rel_file_path)         elif path == \"/\":             start_response(\"302 Found\", [(\"Location\", self.mount_path)])", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-qhmp-h54x-38qr", "cwe_id": "{'CWE-400'}", "score": 7.5, "chain": "{'https://github.com/caronc/apprise/commit/e20fce630d55e4ca9b0a1e325a5fea6997489831'}", "dataset": "osv", "summary": "CWE-730 Regex injection with IFTTT Plugin ### Impact\r\nAnyone _publicly_ hosting the Apprise library and granting them access to the IFTTT notification service.\r\n\r\n### Patches\r\nUpdate to Apprise v0.9.5.1\r\n   ```bash\r\n   # Install Apprise v0.9.5.1 from PyPI\r\n   pip install apprise==0.9.5.1\r\n   ```\r\n\r\nThe patch to the problem was performed [here](https://github.com/caronc/apprise/pull/436/files).\r\n\r\n### Workarounds\r\nAlternatively, if upgrading is not an option, you can safely remove the following file:\r\n- `apprise/plugins/NotifyIFTTT.py` \r\n\r\nThe above will eliminate the ability to use IFTTT, but everything else will work smoothly.\r\n\r\n### For more information\r\nIf you have any questions or comments about this advisory:\r\n* Open an issue in [Apprise](https://github.com/caronc/apprise/issues)\r\n* Email me at [lead2gold@gmail.com](mailto:lead2gold@gmail.com)\r\n\r\n### Additional Credit\r\nGithub would not allow me to additionally credit **Rasmus Petersen**, but I would like to put that here at the very least - thank you for finding and reporting this issue along with those already credited\r\n\r\n## Additional Notes:\r\n- Github would not allow me to add/tag the 2 CWE's this issue is applicable to (only CWE-400).  The other is: CWE-730 (placed in the title)", "published_date": "2021-09-20", "chain_len": 1, "project": "https://github.com/caronc/apprise", "commit_href": "https://github.com/caronc/apprise/commit/e20fce630d55e4ca9b0a1e325a5fea6997489831", "commit_sha": "e20fce630d55e4ca9b0a1e325a5fea6997489831", "patch": "SINGLE", "chain_ord": "['e20fce630d55e4ca9b0a1e325a5fea6997489831']", "before_first_fix_commit": "{'81d1ea72bcee4441278a809a95fc0f91dc916402'}", "last_fix_commit": "e20fce630d55e4ca9b0a1e325a5fea6997489831", "chain_ord_pos": 1, "commit_datetime": "09/06/2021, 17:51:32", "message": "Slight bulletproofing to IFTTT regex handling (#436)", "author": "Chris Caron", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"apprise/plugins/NotifyIFTTT.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/caronc/apprise/raw/e20fce630d55e4ca9b0a1e325a5fea6997489831/apprise%2Fplugins%2FNotifyIFTTT.py", "patch": "@@ -355,7 +355,7 @@ def parse_native_url(url):\n         result = re.match(\n             r'^https?://maker\\.ifttt\\.com/use/'\n             r'(?P<webhook_id>[A-Z0-9_-]+)'\n-            r'/?(?P<events>([A-Z0-9_-]+/?)+)?'\n+            r'((?P<events>(/[A-Z0-9_-]+)+))?'\n             r'/?(?P<params>\\?.+)?$', url, re.I)\n \n         if result:"}}, "prior_version": " def parse_native_url(url):         result = re.match(             r'^https?://maker\\.ifttt\\.com/use/'             r'(?P<webhook_id>[A-Z0-9_-]+)'             r'/?(?P<events>([A-Z0-9_-]+/?)+)?'             r'/?(?P<params>\\?.+)?$', url, re.I)          if result:", "after_version": " def parse_native_url(url):         result = re.match(             r'^https?://maker\\.ifttt\\.com/use/'             r'(?P<webhook_id>[A-Z0-9_-]+)'             r'((?P<events>(/[A-Z0-9_-]+)+))?'             r'/?(?P<params>\\?.+)?$', url, re.I)          if result:", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-rhq2-3vr9-6mcr", "cwe_id": "{'CWE-22'}", "score": 8.3, "chain": "{'https://github.com/gradio-app/gradio/commit/41bd3645bdb616e1248b2167ca83636a2653f781'}", "dataset": "osv", "summary": "Files on the host computer can be accessed from the Gradio interface ### Impact\nThis is a vulnerability that affects anyone who creates and publicly shares Gradio interfaces using `gradio<2.4.8`. Because of the way that static files were being served, someone who generated a public Gradio link and shared it with others would potentially be exposing the files on the computer that generated the link, while the link was active. An attacker would be able to view the contents of a file on the computer if they knew the exact relative filepath. We do not have any evidence that this was ever exploited, but we treated the issue seriously and immediately took steps to mitigate it (see below)\n\n### Response\n1. We worked with @haby0 to immediately patch the issue and released a new version, `gradio 2.5.0`, within 24 hours of the issue being brought to our attention \n2. We enabled a notification that is printed to anyone using an older version of gradio telling them to upgrade (see screenshot below)\n3. We expanded our test suite to test for this vulnerability ensuring that our patch does not get reverted in future releases of `gradio`\n\n![image](https://user-images.githubusercontent.com/1778297/146251425-f36b519b-6d4a-4dfb-8d89-c1ed005979d3.png)\n\n### Patches\nThe problem has been patched in `gradio>=2.5.0`.", "published_date": "2022-01-21", "chain_len": 1, "project": "https://github.com/gradio-app/gradio", "commit_href": "https://github.com/gradio-app/gradio/commit/41bd3645bdb616e1248b2167ca83636a2653f781", "commit_sha": "41bd3645bdb616e1248b2167ca83636a2653f781", "patch": "SINGLE", "chain_ord": "['41bd3645bdb616e1248b2167ca83636a2653f781']", "before_first_fix_commit": "{'0b2c4901a63b2e5a7d7b3964d27b8f82d6d330e1'}", "last_fix_commit": "41bd3645bdb616e1248b2167ca83636a2653f781", "chain_ord_pos": 1, "commit_datetime": "12/14/2021, 21:01:55", "message": "secure path hotfix", "author": "Ali Abid", "comments": null, "stats": "{'additions': 2, 'deletions': 3, 'total': 5}", "files": {"gradio/networking.py": {"additions": 2, "deletions": 3, "changes": 5, "status": "modified", "raw_url": "https://github.com/gradio-app/gradio/raw/41bd3645bdb616e1248b2167ca83636a2653f781/gradio%2Fnetworking.py", "patch": "@@ -377,15 +377,14 @@ def interpret():\n @app.route(\"/file/<path:path>\", methods=[\"GET\"])\n @login_check\n def file(path):\n-    path = secure_filename(path)\n     if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):\n-        with open(os.path.join(app.cwd, path), \"rb\") as encrypted_file:\n+        with open(safe_join(app.cwd, path), \"rb\") as encrypted_file:\n             encrypted_data = encrypted_file.read()\n         file_data = encryptor.decrypt(\n             app.interface.encryption_key, encrypted_data)\n         return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))\n     else:\n-        return send_file(os.path.join(app.cwd, path))\n+        return send_file(safe_join(app.cwd, path))\n \n \n @app.route(\"/api/queue/push/\", methods=[\"POST\"])"}}, "prior_version": " def interpret(): @app.route(\"/file/<path:path>\", methods=[\"GET\"]) @login_check def file(path):     path = secure_filename(path)     if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):         with open(os.path.join(app.cwd, path), \"rb\") as encrypted_file:             encrypted_data = encrypted_file.read()         file_data = encryptor.decrypt(             app.interface.encryption_key, encrypted_data)         return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))     else:         return send_file(os.path.join(app.cwd, path))   @app.route(\"/api/queue/push/\", methods=[\"POST\"])", "after_version": " def interpret(): @app.route(\"/file/<path:path>\", methods=[\"GET\"]) @login_check def file(path):     if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):         with open(safe_join(app.cwd, path), \"rb\") as encrypted_file:             encrypted_data = encrypted_file.read()         file_data = encryptor.decrypt(             app.interface.encryption_key, encrypted_data)         return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))     else:         return send_file(safe_join(app.cwd, path))   @app.route(\"/api/queue/push/\", methods=[\"POST\"])", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-vfrc-ggmc-5jwv", "cwe_id": "{'CWE-79'}", "score": 8.8, "chain": "{'https://github.com/django-helpdesk/django-helpdesk/commit/04483bdac3b5196737516398b5ce0383875a5c60'}", "dataset": "osv", "summary": "Cross-site Scripting in django-helpdesk django-helpdesk is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')", "published_date": "2021-11-23", "chain_len": 1, "project": "https://github.com/django-helpdesk/django-helpdesk", "commit_href": "https://github.com/django-helpdesk/django-helpdesk/commit/04483bdac3b5196737516398b5ce0383875a5c60", "commit_sha": "04483bdac3b5196737516398b5ce0383875a5c60", "patch": "SINGLE", "chain_ord": "['04483bdac3b5196737516398b5ce0383875a5c60']", "before_first_fix_commit": "{'2c7065e0c4296e0c692fb4a7ee19c7357583af30'}", "last_fix_commit": "04483bdac3b5196737516398b5ce0383875a5c60", "chain_ord_pos": 1, "commit_datetime": "11/18/2021, 03:42:02", "message": "Add `att.full_clean()` before saving\n\nFix issue https://github.com/django-helpdesk/django-helpdesk/issues/983\r\nAlso, fix bug stored XSS disclosure: https://huntr.dev/bounties/4d7a5fdd-b2de-467a-ade0-3f2fb386638e/", "author": "lethanhphuc", "comments": null, "stats": "{'additions': 1, 'deletions': 0, 'total': 1}", "files": {"helpdesk/lib.py": {"additions": 1, "deletions": 0, "changes": 1, "status": "modified", "raw_url": "https://github.com/django-helpdesk/django-helpdesk/raw/04483bdac3b5196737516398b5ce0383875a5c60/helpdesk%2Flib.py", "patch": "@@ -145,6 +145,7 @@ def process_attachments(followup, attached_files):\n                 'application/octet-stream',\n                 size=attached.size,\n             )\n+            att.full_clean()\n             att.save()\n \n             if attached.size < max_email_attachment_size:"}}, "prior_version": " def process_attachments(followup, attached_files):                 'application/octet-stream',                 size=attached.size,             )             att.save()              if attached.size < max_email_attachment_size:", "after_version": " def process_attachments(followup, attached_files):                 'application/octet-stream',                 size=attached.size,             )             att.full_clean()             att.save()              if attached.size < max_email_attachment_size:", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "GHSA-x7r7-wmj8-vv5g", "cwe_id": "{'CWE-79'}", "score": 7.5, "chain": "{'https://github.com/octoprint/octoprint/commit/8087528e4a7ddd15c7d95ff662deb5ef7de90045'}", "dataset": "osv", "summary": "Cross-site Scripting in OctoPrint Cross-site Scripting (XSS) - DOM in GitHub repository octoprint/octoprint prior to 1.8.0. The login endpoint allows for javascript injection which may lead to account takeover in a phishing scenario.", "published_date": "2022-05-19", "chain_len": 1, "project": "https://github.com/octoprint/octoprint", "commit_href": "https://github.com/octoprint/octoprint/commit/8087528e4a7ddd15c7d95ff662deb5ef7de90045", "commit_sha": "8087528e4a7ddd15c7d95ff662deb5ef7de90045", "patch": "SINGLE", "chain_ord": "['8087528e4a7ddd15c7d95ff662deb5ef7de90045']", "before_first_fix_commit": "{'700034d028ff3518b563a7b4ba4dacc920142d07'}", "last_fix_commit": "8087528e4a7ddd15c7d95ff662deb5ef7de90045", "chain_ord_pos": 1, "commit_datetime": "05/11/2022, 11:02:52", "message": "\ud83d\udd12\ufe0f Sanitize and validate login redirect\n\nFixes an XSS and an open redirect issue.", "author": "Gina H\u00e4u\u00dfge", "comments": null, "stats": "{'additions': 11, 'deletions': 1, 'total': 12}", "files": {"src/octoprint/server/views.py": {"additions": 11, "deletions": 1, "changes": 12, "status": "modified", "raw_url": "https://github.com/OctoPrint/OctoPrint/raw/8087528e4a7ddd15c7d95ff662deb5ef7de90045/src%2Foctoprint%2Fserver%2Fviews.py", "patch": "@@ -8,6 +8,7 @@\n import os\n import re\n from collections import defaultdict\n+from urllib.parse import urlparse\n \n from flask import (\n     Response,\n@@ -170,7 +171,16 @@ def _add_additional_assets(hook):\n def login():\n     from flask_login import current_user\n \n-    redirect_url = request.args.get(\"redirect\", request.script_root + url_for(\"index\"))\n+    default_redirect_url = request.script_root + url_for(\"index\")\n+    redirect_url = request.args.get(\"redirect\", default_redirect_url)\n+\n+    parsed = urlparse(redirect_url)  # check if redirect url is valid\n+    if parsed.scheme != \"\" or parsed.netloc != \"\":\n+        _logger.warning(\n+            f\"Got an invalid redirect URL with the login attempt, misconfiguration or attack attempt: {redirect_url}\"\n+        )\n+        redirect_url = default_redirect_url\n+\n     permissions = sorted(\n         filter(\n             lambda x: x is not None and isinstance(x, OctoPrintPermission),"}}, "prior_version": " import os import re from collections import defaultdict  from flask import (     Response, def _add_additional_assets(hook): def login():     from flask_login import current_user      redirect_url = request.args.get(\"redirect\", request.script_root + url_for(\"index\"))     permissions = sorted(         filter(             lambda x: x is not None and isinstance(x, OctoPrintPermission),", "after_version": " import os import re from collections import defaultdict from urllib.parse import urlparse  from flask import (     Response, def _add_additional_assets(hook): def login():     from flask_login import current_user      default_redirect_url = request.script_root + url_for(\"index\")     redirect_url = request.args.get(\"redirect\", default_redirect_url)      parsed = urlparse(redirect_url)  # check if redirect url is valid     if parsed.scheme != \"\" or parsed.netloc != \"\":         _logger.warning(             f\"Got an invalid redirect URL with the login attempt, misconfiguration or attack attempt: {redirect_url}\"         )         redirect_url = default_redirect_url      permissions = sorted(         filter(             lambda x: x is not None and isinstance(x, OctoPrintPermission),", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2012-3366", "cwe_id": "{'CWE-78'}", "score": 10.0, "chain": "{'https://github.com/Bcfg2/bcfg2/commit/a524967e8d5c4c22e49cd619aed20c87a316c0be'}", "dataset": "nvd", "summary": "The Trigger plugin in bcfg2 1.2.x before 1.2.3 allows remote attackers with root access to the client to execute arbitrary commands via shell metacharacters in the UUID field to the server process (bcfg2-server).", "published_date": "2012-07-03", "chain_len": 1, "project": "https://github.com/Bcfg2/bcfg2", "commit_href": "https://github.com/Bcfg2/bcfg2/commit/a524967e8d5c4c22e49cd619aed20c87a316c0be", "commit_sha": "a524967e8d5c4c22e49cd619aed20c87a316c0be", "patch": "SINGLE", "chain_ord": "['a524967e8d5c4c22e49cd619aed20c87a316c0be']", "before_first_fix_commit": "{'503ea9de36d74ac6d7ad564d04a923a016592ccd'}", "last_fix_commit": "a524967e8d5c4c22e49cd619aed20c87a316c0be", "chain_ord_pos": 1, "commit_datetime": "06/12/2012, 13:20:10", "message": "fixed major security flaw in Trigger plugin", "author": "Chris St. Pierre", "comments": null, "stats": "{'additions': 25, 'deletions': 15, 'total': 40}", "files": {"src/lib/Server/Plugins/Trigger.py": {"additions": 25, "deletions": 15, "changes": 40, "status": "modified", "raw_url": "https://github.com/Bcfg2/bcfg2/raw/a524967e8d5c4c22e49cd619aed20c87a316c0be/src%2Flib%2FServer%2FPlugins%2FTrigger.py", "patch": "@@ -1,17 +1,7 @@\n import os\n+import pipes\n import Bcfg2.Server.Plugin\n-\n-\n-def async_run(prog, args):\n-    pid = os.fork()\n-    if pid:\n-        os.waitpid(pid, 0)\n-    else:\n-        dpid = os.fork()\n-        if not dpid:\n-            os.system(\" \".join([prog] + args))\n-        os._exit(0)\n-\n+from subprocess import Popen, PIPE\n \n class Trigger(Bcfg2.Server.Plugin.Plugin,\n               Bcfg2.Server.Plugin.Statistics):\n@@ -30,15 +20,35 @@ def __init__(self, core, datastore):\n                               \"unloading\" % self.data)\n             raise Bcfg2.Server.Plugin.PluginInitError\n \n+    def async_run(self, args):\n+        pid = os.fork()\n+        if pid:\n+            os.waitpid(pid, 0)\n+        else:\n+            dpid = os.fork()\n+            if not dpid:\n+                self.debug_log(\"Running %s\" % \" \".join(pipes.quote(a)\n+                                                       for a in args))\n+                proc = Popen(args, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n+                (out, err) = proc.communicate()\n+                rv = proc.wait()\n+                if rv != 0:\n+                    self.logger.error(\"Trigger: Error running %s (%s): %s\" %\n+                                      (args[0], rv, err))\n+                elif err:\n+                    self.debug_log(\"Trigger: Error: %s\" % err)\n+            os._exit(0)\n+\n     def process_statistics(self, metadata, _):\n         args = [metadata.hostname, '-p', metadata.profile, '-g',\n                 ':'.join([g for g in metadata.groups])]\n+        self.debug_log(\"running triggers\")\n         for notifier in os.listdir(self.data):\n+            self.debug_log(\"running %s\" % notifier)\n             if ((notifier[-1] == '~') or\n                 (notifier[:2] == '.#') or\n                 (notifier[-4:] == '.swp') or\n                 (notifier in ['SCCS', '.svn', '4913'])):\n                 continue\n-            npath = self.data + '/' + notifier\n-            self.logger.debug(\"Running %s %s\" % (npath, \" \".join(args)))\n-            async_run(npath, args)\n+            npath = os.path.join(self.data, notifier)\n+            self.async_run([npath] + args)"}}, "prior_version": " import os import Bcfg2.Server.Plugin   def async_run(prog, args):     pid = os.fork()     if pid:         os.waitpid(pid, 0)     else:         dpid = os.fork()         if not dpid:             os.system(\" \".join([prog] + args))         os._exit(0)   class Trigger(Bcfg2.Server.Plugin.Plugin,               Bcfg2.Server.Plugin.Statistics): def __init__(self, core, datastore):                               \"unloading\" % self.data)             raise Bcfg2.Server.Plugin.PluginInitError      def process_statistics(self, metadata, _):         args = [metadata.hostname, '-p', metadata.profile, '-g',                 ':'.join([g for g in metadata.groups])]         for notifier in os.listdir(self.data):             if ((notifier[-1] == '~') or                 (notifier[:2] == '.#') or                 (notifier[-4:] == '.swp') or                 (notifier in ['SCCS', '.svn', '4913'])):                 continue             npath = self.data + '/' + notifier             self.logger.debug(\"Running %s %s\" % (npath, \" \".join(args)))             async_run(npath, args)", "after_version": " import os import pipes import Bcfg2.Server.Plugin from subprocess import Popen, PIPE  class Trigger(Bcfg2.Server.Plugin.Plugin,               Bcfg2.Server.Plugin.Statistics): def __init__(self, core, datastore):                               \"unloading\" % self.data)             raise Bcfg2.Server.Plugin.PluginInitError      def async_run(self, args):         pid = os.fork()         if pid:             os.waitpid(pid, 0)         else:             dpid = os.fork()             if not dpid:                 self.debug_log(\"Running %s\" % \" \".join(pipes.quote(a)                                                        for a in args))                 proc = Popen(args, stdin=PIPE, stdout=PIPE, stderr=PIPE)                 (out, err) = proc.communicate()                 rv = proc.wait()                 if rv != 0:                     self.logger.error(\"Trigger: Error running %s (%s): %s\" %                                       (args[0], rv, err))                 elif err:                     self.debug_log(\"Trigger: Error: %s\" % err)             os._exit(0)      def process_statistics(self, metadata, _):         args = [metadata.hostname, '-p', metadata.profile, '-g',                 ':'.join([g for g in metadata.groups])]         self.debug_log(\"running triggers\")         for notifier in os.listdir(self.data):             self.debug_log(\"running %s\" % notifier)             if ((notifier[-1] == '~') or                 (notifier[:2] == '.#') or                 (notifier[-4:] == '.swp') or                 (notifier in ['SCCS', '.svn', '4913'])):                 continue             npath = os.path.join(self.data, notifier)             self.async_run([npath] + args)", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2012-3371", "cwe_id": "{'CWE-20'}", "score": 2.9, "chain": "{'https://github.com/openstack/nova/commit/034762e8060dcf0a11cb039b9d426b0d0bb1801d'}", "dataset": "nvd", "summary": "The Nova scheduler in OpenStack Compute (Nova) Folsom (2012.2) and Essex (2012.1), when DifferentHostFilter or SameHostFilter is enabled, allows remote authenticated users to cause a denial of service (excessive database lookup calls and server hang) via a request with many repeated IDs in the os:scheduler_hints section.", "published_date": "2012-07-17", "chain_len": 1, "project": "https://github.com/openstack/nova", "commit_href": "https://github.com/openstack/nova/commit/034762e8060dcf0a11cb039b9d426b0d0bb1801d", "commit_sha": "034762e8060dcf0a11cb039b9d426b0d0bb1801d", "patch": "SINGLE", "chain_ord": "['034762e8060dcf0a11cb039b9d426b0d0bb1801d']", "before_first_fix_commit": "{'b91d2fc02d927066ed0fe21439ccb7548de4138f'}", "last_fix_commit": "034762e8060dcf0a11cb039b9d426b0d0bb1801d", "chain_ord_pos": 1, "commit_datetime": "06/26/2012, 16:44:35", "message": "Use compute_api.get_all in affinity filters.\n\nUpdates the affinity filters so they make a single compute API\ncall to lookup instance host information rather than single\nlookups for each UUID.\n\nThis resolves a potential performance issue which can cause a\nscheduler to hang while processing requests which contain large numbers\nof UUID's in the scheduler_hints.\n\nFixes LP Bug #1017795.\n\nChange-Id: I30f434faf109058573ee41c4a6abce2e48939e8d", "author": "Dan Prince", "comments": null, "stats": "{'additions': 9, 'deletions': 4, 'total': 13}", "files": {"nova/scheduler/filters/affinity_filter.py": {"additions": 9, "deletions": 4, "changes": 13, "status": "modified", "raw_url": "https://github.com/openstack/nova/raw/034762e8060dcf0a11cb039b9d426b0d0bb1801d/nova%2Fscheduler%2Ffilters%2Faffinity_filter.py", "patch": "@@ -25,8 +25,11 @@ class AffinityFilter(filters.BaseHostFilter):\n     def __init__(self):\n         self.compute_api = compute.API()\n \n-    def _affinity_host(self, context, instance_id):\n-        return self.compute_api.get(context, instance_id)['host']\n+    def _all_hosts(self, context):\n+        all_hosts = {}\n+        for instance in self.compute_api.get_all(context):\n+            all_hosts[instance['uuid']] = instance['host']\n+        return all_hosts\n \n \n class DifferentHostFilter(AffinityFilter):\n@@ -41,8 +44,9 @@ def host_passes(self, host_state, filter_properties):\n         if isinstance(affinity_uuids, basestring):\n             affinity_uuids = [affinity_uuids]\n         if affinity_uuids:\n+            all_hosts = self._all_hosts(context)\n             return not any([i for i in affinity_uuids\n-                              if self._affinity_host(context, i) == me])\n+                              if all_hosts.get(i) == me])\n         # With no different_host key\n         return True\n \n@@ -61,9 +65,10 @@ def host_passes(self, host_state, filter_properties):\n         if isinstance(affinity_uuids, basestring):\n             affinity_uuids = [affinity_uuids]\n         if affinity_uuids:\n+            all_hosts = self._all_hosts(context)\n             return any([i for i\n                           in affinity_uuids\n-                          if self._affinity_host(context, i) == me])\n+                          if all_hosts.get(i) == me])\n         # With no same_host key\n         return True"}}, "prior_version": " class AffinityFilter(filters.BaseHostFilter):     def __init__(self):         self.compute_api = compute.API()      def _affinity_host(self, context, instance_id):         return self.compute_api.get(context, instance_id)['host']   class DifferentHostFilter(AffinityFilter): def host_passes(self, host_state, filter_properties):         if isinstance(affinity_uuids, basestring):             affinity_uuids = [affinity_uuids]         if affinity_uuids:             return not any([i for i in affinity_uuids                               if self._affinity_host(context, i) == me])         # With no different_host key         return True  def host_passes(self, host_state, filter_properties):         if isinstance(affinity_uuids, basestring):             affinity_uuids = [affinity_uuids]         if affinity_uuids:             return any([i for i                           in affinity_uuids                           if self._affinity_host(context, i) == me])         # With no same_host key         return True ", "after_version": " class AffinityFilter(filters.BaseHostFilter):     def __init__(self):         self.compute_api = compute.API()      def _all_hosts(self, context):         all_hosts = {}         for instance in self.compute_api.get_all(context):             all_hosts[instance['uuid']] = instance['host']         return all_hosts   class DifferentHostFilter(AffinityFilter): def host_passes(self, host_state, filter_properties):         if isinstance(affinity_uuids, basestring):             affinity_uuids = [affinity_uuids]         if affinity_uuids:             all_hosts = self._all_hosts(context)             return not any([i for i in affinity_uuids                               if all_hosts.get(i) == me])         # With no different_host key         return True  def host_passes(self, host_state, filter_properties):         if isinstance(affinity_uuids, basestring):             affinity_uuids = [affinity_uuids]         if affinity_uuids:             all_hosts = self._all_hosts(context)             return any([i for i                           in affinity_uuids                           if all_hosts.get(i) == me])         # With no same_host key         return True ", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "CVE-2012-3540", "cwe_id": "{'CWE-20'}", "score": 4.9, "chain": "{'https://github.com/openstack/horizon/commit/35eada8a27323c0f83c400177797927aba6bc99b'}", "dataset": "nvd", "summary": "Open redirect vulnerability in views/auth_forms.py in OpenStack Dashboard (Horizon) Essex (2012.1) allows remote attackers to redirect users to arbitrary web sites and conduct phishing attacks via a URL in the next parameter to auth/login/.  NOTE: this issue was originally assigned CVE-2012-3542 by mistake.", "published_date": "2012-09-05", "chain_len": 1, "project": "https://github.com/openstack/horizon", "commit_href": "https://github.com/openstack/horizon/commit/35eada8a27323c0f83c400177797927aba6bc99b", "commit_sha": "35eada8a27323c0f83c400177797927aba6bc99b", "patch": "SINGLE", "chain_ord": "['35eada8a27323c0f83c400177797927aba6bc99b']", "before_first_fix_commit": "{'648b07895c3e09218e165ec0f61bca7e3d6eb691'}", "last_fix_commit": "35eada8a27323c0f83c400177797927aba6bc99b", "chain_ord_pos": 1, "commit_datetime": "08/22/2012, 19:15:40", "message": "Fix open redirect in Horizon.\n\nLP 1039077. Disallow login redirects to anywhere other than the same origin.\n\nChange-Id: I36e8e4f30cf440ecc73534af38fcd8d2a111a603", "author": "Paul McMillan", "comments": null, "stats": "{'additions': 8, 'deletions': 1, 'total': 9}", "files": {"horizon/views/auth_forms.py": {"additions": 8, "deletions": 1, "changes": 9, "status": "modified", "raw_url": "https://github.com/openstack/horizon/raw/35eada8a27323c0f83c400177797927aba6bc99b/horizon%2Fviews%2Fauth_forms.py", "patch": "@@ -28,6 +28,7 @@\n from django.conf import settings\n from django.contrib import messages\n from django.contrib.auth import REDIRECT_FIELD_NAME\n+from django.utils.http import same_origin\n from django.utils.translation import ugettext as _\n from keystoneclient import exceptions as keystone_exceptions\n \n@@ -94,7 +95,13 @@ def handle(self, request, data):\n         request.session['region_endpoint'] = endpoint\n         request.session['region_name'] = region_name\n \n-        redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, \"\")\n+        redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, None)\n+        # Make sure the requested redirect matches the protocol,\n+        # domain, and port of this request\n+        if redirect_to and not same_origin(\n+                request.build_absolute_uri(redirect_to),\n+                request.build_absolute_uri()):\n+            redirect_to = None\n \n         if data.get('tenant', None):\n             try:"}}, "prior_version": " from django.conf import settings from django.contrib import messages from django.contrib.auth import REDIRECT_FIELD_NAME from django.utils.translation import ugettext as _ from keystoneclient import exceptions as keystone_exceptions  def handle(self, request, data):         request.session['region_endpoint'] = endpoint         request.session['region_name'] = region_name          redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, \"\")          if data.get('tenant', None):             try:", "after_version": " from django.conf import settings from django.contrib import messages from django.contrib.auth import REDIRECT_FIELD_NAME from django.utils.http import same_origin from django.utils.translation import ugettext as _ from keystoneclient import exceptions as keystone_exceptions  def handle(self, request, data):         request.session['region_endpoint'] = endpoint         request.session['region_name'] = region_name          redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, None)         # Make sure the requested redirect matches the protocol,         # domain, and port of this request         if redirect_to and not same_origin(                 request.build_absolute_uri(redirect_to),                 request.build_absolute_uri()):             redirect_to = None          if data.get('tenant', None):             try:", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "CVE-2013-2006", "cwe_id": "{'CWE-200'}", "score": 2.9, "chain": "{'https://github.com/openstack/keystone/commit/c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd'}", "dataset": "nvd", "summary": "OpenStack Identity (Keystone) Grizzly 2013.1.1, when DEBUG mode logging is enabled, logs the (1) admin_token and (2) LDAP password in plaintext, which allows local users to obtain sensitive by reading the log file.", "published_date": "2013-05-21", "chain_len": 1, "project": "https://github.com/openstack/keystone", "commit_href": "https://github.com/openstack/keystone/commit/c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd", "commit_sha": "c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd", "patch": "SINGLE", "chain_ord": "['c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd']", "before_first_fix_commit": "{'5929850979b0ccf348c1b913961d581ccac9732c'}", "last_fix_commit": "c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd", "chain_ord_pos": 1, "commit_datetime": "04/12/2013, 08:19:37", "message": "Mark LDAP password and admin_token secret\n\nAdd secret=True to LDAP password and admin_token\nof keystone configuration.\n\nFix bug #1172195\n\nChange-Id: I8ef7f705e3f6b374ff427c20eb761892d5146a75\n(cherry picked from commit d43e2a51a1ed7adbed3c5ddf001d46bc4a824ae8)", "author": "Xuhan Peng", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"keystone/common/config.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/openstack/keystone/raw/c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd/keystone%2Fcommon%2Fconfig.py", "patch": "@@ -188,7 +188,7 @@ def configure():\n     register_cli_str('pydev-debug-host', default=None)\n     register_cli_int('pydev-debug-port', default=None)\n \n-    register_str('admin_token', default='ADMIN')\n+    register_str('admin_token', secret=True, default='ADMIN')\n     register_str('bind_host', default='0.0.0.0')\n     register_int('compute_port', default=8774)\n     register_int('admin_port', default=35357)\n@@ -271,7 +271,7 @@ def configure():\n     # ldap\n     register_str('url', group='ldap', default='ldap://localhost')\n     register_str('user', group='ldap', default=None)\n-    register_str('password', group='ldap', default=None)\n+    register_str('password', group='ldap', secret=True, default=None)\n     register_str('suffix', group='ldap', default='cn=example,cn=com')\n     register_bool('use_dumb_member', group='ldap', default=False)\n     register_str('dumb_member', group='ldap', default='cn=dumb,dc=nonexistent')"}}, "prior_version": " def configure():     register_cli_str('pydev-debug-host', default=None)     register_cli_int('pydev-debug-port', default=None)      register_str('admin_token', default='ADMIN')     register_str('bind_host', default='0.0.0.0')     register_int('compute_port', default=8774)     register_int('admin_port', default=35357) def configure():     # ldap     register_str('url', group='ldap', default='ldap://localhost')     register_str('user', group='ldap', default=None)     register_str('password', group='ldap', default=None)     register_str('suffix', group='ldap', default='cn=example,cn=com')     register_bool('use_dumb_member', group='ldap', default=False)     register_str('dumb_member', group='ldap', default='cn=dumb,dc=nonexistent')", "after_version": " def configure():     register_cli_str('pydev-debug-host', default=None)     register_cli_int('pydev-debug-port', default=None)      register_str('admin_token', secret=True, default='ADMIN')     register_str('bind_host', default='0.0.0.0')     register_int('compute_port', default=8774)     register_int('admin_port', default=35357) def configure():     # ldap     register_str('url', group='ldap', default='ldap://localhost')     register_str('user', group='ldap', default=None)     register_str('password', group='ldap', secret=True, default=None)     register_str('suffix', group='ldap', default='cn=example,cn=com')     register_bool('use_dumb_member', group='ldap', default=False)     register_str('dumb_member', group='ldap', default='cn=dumb,dc=nonexistent')", "file_extension": "py", "cwe": "CWE-200"}
{"vuln_id": "CVE-2017-5938", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad'}", "dataset": "nvd", "summary": "Cross-site scripting (XSS) vulnerability in the nav_path function in lib/viewvc.py in ViewVC before 1.0.14 and 1.1.x before 1.1.26 allows remote attackers to inject arbitrary web script or HTML via the nav_data name.", "published_date": "2017-03-15", "chain_len": 1, "project": "https://github.com/viewvc/viewvc", "commit_href": "https://github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad", "commit_sha": "9dcfc7daa4c940992920d3b2fbd317da20e44aad", "patch": "SINGLE", "chain_ord": "['9dcfc7daa4c940992920d3b2fbd317da20e44aad']", "before_first_fix_commit": "{'8507aa4e745e4cf5cac811ccb6d2fbf768bb9cba'}", "last_fix_commit": "9dcfc7daa4c940992920d3b2fbd317da20e44aad", "chain_ord_pos": 1, "commit_datetime": "01/24/2017, 20:39:56", "message": "Escape some raw path data before handing off to templates\n\n* lib/viewvc.py\n  (nav_path): Escape the 'name' property of navigation path components\n    the same way we escape that of the 'root' path component.\n\nReported by: Thomas Gerbet <thomas.gerbet@enalean.com>", "author": "C. Michael Pilato", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"lib/viewvc.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/viewvc/viewvc/raw/9dcfc7daa4c940992920d3b2fbd317da20e44aad/lib%2Fviewvc.py", "patch": "@@ -980,7 +980,7 @@ def nav_path(request):\n     path_parts.append(part)\n     is_last = len(path_parts) == len(request.path_parts)\n \n-    item = _item(name=part, href=None)\n+    item = _item(name=request.server.escape(part), href=None)\n \n     if not is_last or (is_dir and request.view_func is not view_directory):\n       item.href = request.get_url(view_func=view_directory,"}}, "prior_version": " def nav_path(request):     path_parts.append(part)     is_last = len(path_parts) == len(request.path_parts)      item = _item(name=part, href=None)      if not is_last or (is_dir and request.view_func is not view_directory):       item.href = request.get_url(view_func=view_directory,", "after_version": " def nav_path(request):     path_parts.append(part)     is_last = len(path_parts) == len(request.path_parts)      item = _item(name=request.server.escape(part), href=None)      if not is_last or (is_dir and request.view_func is not view_directory):       item.href = request.get_url(view_func=view_directory,", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2017-7572", "cwe_id": "{'CWE-362'}", "score": 10.0, "chain": "{'https://github.com/bit-team/backintime/commit/7f208dc547f569b689c888103e3b593a48cd1869'}", "dataset": "nvd", "summary": "The _checkPolkitPrivilege function in serviceHelper.py in Back In Time (aka backintime) 1.1.18 and earlier uses a deprecated polkit authorization method (unix-process) that is subject to a race condition (time of check, time of use). With this authorization method, the owner of a process requesting a polkit operation is checked by polkitd via /proc/<pid>/status, by which time the requesting process may have been replaced by a different process with the same PID that has different privileges then the original requester.", "published_date": "2017-04-06", "chain_len": 1, "project": "https://github.com/bit-team/backintime", "commit_href": "https://github.com/bit-team/backintime/commit/7f208dc547f569b689c888103e3b593a48cd1869", "commit_sha": "7f208dc547f569b689c888103e3b593a48cd1869", "patch": "SINGLE", "chain_ord": "['7f208dc547f569b689c888103e3b593a48cd1869']", "before_first_fix_commit": "{'c689a4d815ce3ba2c212a42f777a1ca4727f473b'}", "last_fix_commit": "7f208dc547f569b689c888103e3b593a48cd1869", "chain_ord_pos": 1, "commit_datetime": "04/05/2017, 11:57:59", "message": "polkit CheckAuthorization: fix race condition in privilege authorization\n\nThe unix-process authorization subject is deprecated:\n\nhttps://www.freedesktop.org/software/polkit/docs/latest/PolkitUnixProcess.html#polkit-unix-process-new\n\nas it is subject to a race condition. A client process requesting\nauthorization can replace itself by a suid or otherwise root owned\nexecutable, thus granting the original non-privileged request\nprivileges.\n\nSee also:\n\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1002375\nhttps://github.com/Kabot/Unix-Privilege-Escalation-Exploits-Pack/blob/master/2011/CVE-2011-1485/polkit-pwnage.c\n\nPolkit uses the real-uid of the process by now, thus mitigating the\nexploit using suid binaries. It is still possible, however, to exit the\nclient process and try to get a root program to get the same PID.\n\nIn worst case this would allow an unauthenticated user to get backintime\nor some other program to be executed via udev rules as root user.", "author": "Matthias Gerstner", "comments": "{'com_1': {'author': 'carnil', 'datetime': '04/07/2017, 10:33:47', 'body': '[CVE-2017-7572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-7572)'}}", "stats": "{'additions': 1, 'deletions': 7, 'total': 8}", "files": {"qt/serviceHelper.py": {"additions": 1, "deletions": 7, "changes": 8, "status": "modified", "raw_url": "https://github.com/bit-team/backintime/raw/7f208dc547f569b689c888103e3b593a48cd1869/qt%2FserviceHelper.py", "patch": "@@ -282,18 +282,12 @@ def _checkPolkitPrivilege(self, sender, conn, privilege):\n             # bus, and it does not make sense to restrict operations here\n             return\n \n-        info = SenderInfo(sender, conn)\n-\n-        # get peer PID\n-        pid = info.connectionPid()\n-\n         # query PolicyKit\n         self._initPolkit()\n         try:\n             # we don't need is_challenge return here, since we call with AllowUserInteraction\n             (is_auth, _, details) = self.polkit.CheckAuthorization(\n-                    ('unix-process', {'pid': dbus.UInt32(pid, variant_level=1),\n-                    'start-time': dbus.UInt64(0, variant_level=1)}),\n+                    ('system-bus-name', {'name': dbus.String(sender, variant_level=1)}),\n                     privilege, {'': ''}, dbus.UInt32(1), '', timeout=3000)\n         except dbus.DBusException as e:\n             if e._dbus_error_name == 'org.freedesktop.DBus.Error.ServiceUnknown':"}}, "prior_version": " def _checkPolkitPrivilege(self, sender, conn, privilege):             # bus, and it does not make sense to restrict operations here             return          info = SenderInfo(sender, conn)          # get peer PID         pid = info.connectionPid()          # query PolicyKit         self._initPolkit()         try:             # we don't need is_challenge return here, since we call with AllowUserInteraction             (is_auth, _, details) = self.polkit.CheckAuthorization(                     ('unix-process', {'pid': dbus.UInt32(pid, variant_level=1),                     'start-time': dbus.UInt64(0, variant_level=1)}),                     privilege, {'': ''}, dbus.UInt32(1), '', timeout=3000)         except dbus.DBusException as e:             if e._dbus_error_name == 'org.freedesktop.DBus.Error.ServiceUnknown':", "after_version": " def _checkPolkitPrivilege(self, sender, conn, privilege):             # bus, and it does not make sense to restrict operations here             return          # query PolicyKit         self._initPolkit()         try:             # we don't need is_challenge return here, since we call with AllowUserInteraction             (is_auth, _, details) = self.polkit.CheckAuthorization(                     ('system-bus-name', {'name': dbus.String(sender, variant_level=1)}),                     privilege, {'': ''}, dbus.UInt32(1), '', timeout=3000)         except dbus.DBusException as e:             if e._dbus_error_name == 'org.freedesktop.DBus.Error.ServiceUnknown':", "file_extension": "py", "cwe": "CWE-362"}
{"vuln_id": "CVE-2018-1000070", "cwe_id": "{'CWE-94'}", "score": 6.4, "chain": "{'https://github.com/Bitmessage/PyBitmessage/commit/3a8016d31f517775d226aa8b902480f4a3a148a9'}", "dataset": "nvd", "summary": "Bitmessage PyBitmessage version v0.6.2 (and introduced in or after commit 8ce72d8d2d25973b7064b1cf76a6b0b3d62f0ba0) contains a Eval injection vulnerability in main program, file src/messagetypes/__init__.py function constructObject that can result in Code Execution. This attack appears to be exploitable via remote attacker using a malformed message which must be processed by the victim - e.g. arrive from any sender on bitmessage network. This vulnerability appears to have been fixed in v0.6.3.", "published_date": "2018-03-13", "chain_len": 1, "project": "https://github.com/Bitmessage/PyBitmessage", "commit_href": "https://github.com/Bitmessage/PyBitmessage/commit/3a8016d31f517775d226aa8b902480f4a3a148a9", "commit_sha": "3a8016d31f517775d226aa8b902480f4a3a148a9", "patch": "SINGLE", "chain_ord": "['3a8016d31f517775d226aa8b902480f4a3a148a9']", "before_first_fix_commit": "{'96ea36cfd245f7dc10209b01278b5fa2970f360c'}", "last_fix_commit": "3a8016d31f517775d226aa8b902480f4a3a148a9", "chain_ord_pos": 1, "commit_datetime": "02/13/2018, 15:39:35", "message": "Fix message encoding bug\n\n- prevent loading invalid message types", "author": "Peter Surda", "comments": "{'com_1': {'author': 'PeterSurda', 'datetime': '02/13/2018, 16:30:49', 'body': \"It's allows a remote execution, but it probably crashed for most people before it could execute anything. In the logs I see attempts to run a windows executable and to steal electrum wallet files.\"}, 'com_2': {'author': 'rfreemobile', 'datetime': '02/13/2018, 18:44:46', 'body': '@PeterSurda god damn. Using eval() should be illegal by law.\\r\\n\\r\\nThis is used in encode() ... but still it is called on the data coming from network then? \\r\\n\\r\\nRequesting CVE number for it? Remote arbitrary code execution in widely used application...'}, 'com_3': {'author': 'copumpkin', 'datetime': '02/13/2018, 21:07:56', 'body': \"This still doesn't feel ideal. Although it isn't arbitrary code anymore, you still let untrusted data specify which method to call on an object. Is this a temporary fix or the final one?\"}, 'com_4': {'author': 'PeterSurda', 'datetime': '02/13/2018, 21:31:49', 'body': \"I am open for suggestions on how to improve it. I haven't build the binaries yet, possibly I'll release 0.6.3.1 with an improved fix, but I had to move quickly.\"}, 'com_5': {'author': 'copumpkin', 'datetime': '02/13/2018, 21:39:16', 'body': \"I'd probably assert that `title()` is one of the known/expected values before invoking it, or something like that. In the longer run, it's probably better to make it a more formal message parser: see langsec/weird machines and so on: http://langsec.org/\"}, 'com_6': {'author': 'tintinweb', 'datetime': '02/13/2018, 21:48:30', 'body': 'yeah as @copumpkin mentioned this could need some input validation.\\r\\n\\r\\nand maybe also check the [other evals](https://github.com/Bitmessage/PyBitmessage/blob/fd1a6c1fa14ab719f43d97ad52f464826fb32b4c/src/bitmessagecli.py#L379)? Usually there is not many reasons to use eval.'}, 'com_7': {'author': 'copumpkin', 'datetime': '02/13/2018, 22:00:26', 'body': \"Yeah, `eval` is a huge no-no in security-sensitive software (so all of it, really). In some cases the input might effectively be trusted, but it's easier to just outlaw `eval` so people don't have to stare extra hard at code using it to make sure it's not stupid.\"}, 'com_8': {'author': 'g1itch', 'datetime': '02/13/2018, 22:23:43', 'body': 'Did someone used message type `Vote` ever? @copumpkin [title()](https://docs.python.org/2.7/library/stdtypes.html#str.title), if you have no such file or no such class in it - it will be ignored.'}, 'com_9': {'author': 'copumpkin', 'datetime': '02/13/2018, 22:30:43', 'body': \"Oh, I'm sorry, I misunderstood what was going on. It still seems good to explicitly validate this sort of thing. If only so that future readers can see when behavior like this changes, and can be sure that it's actually running against an explicitly defined message schema rather than relying on reflective behavior against a living codebase.\"}, 'com_10': {'author': 'PeterSurda', 'datetime': '02/13/2018, 22:37:03', 'body': '@g1itch vote doesn\\'t really do anything, it\\'s an example.\\r\\n\\r\\n@copumpkin I\\'ll restrict extended encoding to \"message\" type for the time being, it can be loosened later after a more thorough review.'}, 'com_11': {'author': 'tigusoft', 'datetime': '02/13/2018, 23:07:36', 'body': '@PeterSurda @rfree-d \\r\\napplied for CVE, seems bug was first in tagged version v0.6.2 and now fixed in v0.6.3\\r\\n\\r\\nhttps://docs.google.com/spreadsheets/d/1PlDOsZ4Q36JU4Dz9zyBB2F3814dScppCRCe1muCT7JI/edit#gid=1009122160\\r\\n\\r\\n(search \"bitmessage\")'}, 'com_12': {'author': 'PeterSurda', 'datetime': '02/13/2018, 23:20:22', 'body': 'Thank you.'}, 'com_13': {'author': 'celmar01', 'datetime': '02/15/2018, 01:33:45', 'body': '\ud83d\udc4d'}, 'com_14': {'author': 'ValdikSS', 'datetime': '02/15/2018, 07:25:25', 'body': 'To prevent serious damage from such kind of vulnerabilities, you should write SELinux/AppArmor/Firejail profiles and bundle it with the application.'}, 'com_15': {'author': 'PeterSurda', 'datetime': '02/15/2018, 10:03:26', 'body': \"I'll be happy to accept pull requests for security profiles.\"}, 'com_16': {'author': 'KOLANICH', 'datetime': '02/15/2018, 20:11:44', 'body': \"@PeterSurda, I wanna know how this have happened that such a backdory function like `eval` have appeared in such a security-critical application as bitmessage. I wanna know which measures are you going to take to make this kind of backdoors never appear again.\\r\\n\\r\\nIMHO at least we need a blacklist of functions which must not be used in bm and any of it dependencies. All the PRs using them must be automatically rejected. All the PR's introducing new dependencies must be rejected. Dependencies and all their dependencies must be checked and forked and freezed and installed only from this project's repos, not from pip. Only after creating an own fork of dependencies which involves manual checking a dependency may be used.\\r\\n\\r\\nI also have some ideas about building security into python interpreter, I'm currently trying to convert my thoughts into a document.\"}, 'com_17': {'author': 'PeterSurda', 'datetime': '02/15/2018, 21:21:26', 'body': '@KOLANICH You can apply for an audit/hardening job: #1136'}, 'com_18': {'author': 'PeterSurda', 'datetime': '02/15/2018, 21:25:42', 'body': '@KOLANICH And the bug appeared because I am a guy who decided to take care of an abandoned project that I found very important not realising the huge scope of such an endeavor. Luckily there are more contributors in the meantime who do review my code, and the workflow has slightly improved.'}, 'com_19': {'author': 'tigusoft', 'datetime': '02/25/2018, 20:17:52', 'body': 'CVE is assigned: CVE-2018-1000070 (still not published, just reserved)\\r\\n\\r\\nhttps://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1000070'}, 'com_20': {'author': 'PeterSurda', 'datetime': '03/14/2018, 09:39:36', 'body': 'CVE published.'}, 'com_21': {'author': 'sigoa', 'datetime': '03/18/2018, 14:21:57', 'body': '>  I wanna know which measures are you going to take to make this kind of backdoors never appear again.\\r\\n\\r\\n `well,` codacy will throw **B307 alert** if   **eval()**  is being used anywhere. @KOLANICH'}, 'com_22': {'author': 'KOLANICH', 'datetime': '03/18/2018, 14:44:51', 'body': \"@sigoa not only, I'm currently working on a draft of the spec combining taint checking, mandatory access control, capability-based security and permissions into a framework enforcing that\\r\\n* no data from network and other untrusted sources will be passed into security-sensitive functions like `eval`\\r\\n* no sensitive data will be leaked into untrusted destinations like net\\r\\n* no sensitive data resulted in invocation of a privileged API will be available to any module not having a permission to read results from that API\\r\\n* every module will have to explicitly declare the API inputs to which that it controls\\r\\n* and I hope that the framework can be applied to real-world applications\\r\\n\\r\\nbut I have some problems with proofs because the functions to explicitly change taints spoil all the picture, in presence of these functions I cannot prove anything, in absence the scheme is complete garbage unusable in real world apps. For example a private key is a sensitive piece of data, that's why everything touched by it will also be marked as sensitive, even the digital signature which is in fact by default not sensitive assumming no vulnrs in crypto. To solve this issue we need to mark it as non-sensitive, but doing so spoils the whole picture, we cannot prove that the system is secure anymore. \\r\\n\\r\\nFor now I recommend to start implementing taint checking using some frameworks available for python.\"}, 'com_23': {'author': 'sigoa', 'datetime': '03/18/2018, 17:04:52', 'body': \"yeah, its tricky  :cactus: , ain't it. maybe some QUBE OS users made some progress, I don't know.\"}, 'com_24': {'author': 'sigoa', 'datetime': '03/18/2018, 17:11:58', 'body': '@PeterSurda   please add label \"**SECURITY**\" to this  ISSUE  ,  so one can find it better / sortability  , since this is no laughing matter as we know. thanks  :+1: \\r\\n... well you can\\'t , because  it is a RELEASE not an ISSUE . :ping_pong:  \\r\\n\\r\\nsee secu issues here:  https://github.com/Bitmessage/PyBitmessage/labels/security'}, 'com_25': {'author': 'PeterSurda', 'datetime': '03/18/2018, 18:11:42', 'body': \"Thank you @KOLANICH , the security audit job is still open, but contributions that either harden the code directly, or provide a framework for hardening too. Since the vulnerability was revealed, I launched a multi-pronged approach, here are some of the highlights:\\r\\n\\r\\n### Infrastructure\\r\\n\\r\\n- infrastructure (build, bootstrap, website, ...) was hardened and separated from the development environment. This way, even if I get hacked, other people can continue developing, binaries can continue to be built, people can connect to the network. I now have a separate laptop for accessing the infrastructure\\r\\n\\r\\n- my development environment was also hardened and I increased the use of smart cards for authentication and encryption\\r\\n\\r\\n### Development\\r\\n\\r\\n- all new code, including mine, has to be reviewed before being merged\\r\\n\\r\\n- better integration with codacy, and I fine-tuned some settings\\r\\n\\r\\n- existing code will have all the codacy complaints fixed before I do further development (well, maybe some can't be fixed entirely, but they will be treated)\\r\\n\\r\\n- design documentation will be reverse-enginered from the code so that it's easier for new developers/reviewers to understand what's happening\\r\\n\\r\\n- I'll do less development and work more on design/organisational layer\\r\\n\\r\\n### Other things\\r\\n\\r\\n- I spent about 2 weeks reading through CVs an interviewing developers, and recruited a company to help me with the development. This means more people fixing coding issues and reviewing the code\\r\\n\\r\\n- I sent some money to tip4commit so that contributors can be better rewarded, and I want to institute a bug bounty program\\r\\n\\r\\n- I got rid of ALL the evals in the code. There are still some `call`s, e.g. the apinotify or the `make` for autobuilding the C PoW. These are more difficult to get rid of, but at least they can be hardened somewhat\\r\\n\\r\\n@sigoa Yep, can't assign a label.\"}, 'com_26': {'author': 'KOLANICH', 'datetime': '03/18/2018, 18:20:48', 'body': \">design documentation will be reverse-enginered from the code so that it's easier for new developers/reviewers to understand what's happening\\r\\n\\r\\nCould I ask you to write the docs to the message format in Kaitai Struct language (parser can be auto-generated further from the docs, it is machine-readable formal language)? Here is my draft (I have reverse-engineered it from the code and existing docs, but have not tested it anyhow) https://github.com/KOLANICH/kaitai_struct_formats/blob/bitmessage/network/bitmessage.ksy, I expect you to check and test it and develop further. If you wanna check it against a pcap dump inthe same repo you can find a parser for [pcap](https://github.com/kaitai-io/kaitai_struct_formats/blob/pcapng/network/pcapng.ksy) and [pcapng](https://github.com/KOLANICH/kaitai_struct_formats/blob/pcapng/network/pcapng.ksy) formats and my lib https://github.com/KOLANICH/Pipeline.py (which in fact was created for the [similar task](https://github.com/KOLANICH/USBPcapOdinDumper) ) may be useful too.\\r\\n\\r\\n>increased the use of smart cards \\r\\n\\r\\nwhich ones?\\r\\n\\r\\n>I now have a separate laptop for accessing the infrastructure\\r\\n\\r\\nI hope without any backdoors by Intel/AMD/longsoon/any other chineese/taiwanese/russian company/etc?\\r\\n\\r\\n>interviewing developers, and recruited a company to help me with the development\\r\\n\\r\\nI see you are serious with it. Are you going to make business on it? But how are you going to make it sustainable? This will require money and I see no legitimate (backdors are certainly illegitimate) sources of money providing enough money for such a project (you know, most of people don't need decentralised systems, they only need fashionable centralised things: whatsapp, viber, telegram, instagram, prisma, Alexa, Cortana, Siri, iPhone, etc, and without a big market company will likely go bankrupt), maybe except a grant by Mozilla.\"}, 'com_27': {'author': 'sigoa', 'datetime': '03/18/2018, 19:59:54', 'body': 'Mozilla has kind of funny attitudes.  :clown_face:'}, 'com_28': {'author': 'sigoa', 'datetime': '03/18/2018, 20:11:42', 'body': 'could @PeterSurda  pls link  CODACY  into  wiki [here](https://github.com/Bitmessage/PyBitmessage/wiki)  ?  thx :+1:'}, 'com_29': {'author': 'PeterSurda', 'datetime': '03/21/2018, 08:42:13', 'body': \"> Could I ask you to write the docs to the message format in Kaitai Struct\\r\\n\\r\\nI'll look at it in more detail. It looks like a wire protocol specification, which is fine, but I want specification of both the Bitmessage system design as well as how PyBitmessage is put together (like what are the threads, what are they doing, and so on). For example the wire protocol specification cannot specify when an inv is being sent, what the handshake sequence looks like, and so on. It's also unclear to me at this point how TLS is supposed to be specified in Kaitai Struct.\\r\\n\\r\\n> which ones? (smartcards, e.d.)\\r\\n\\r\\nSo far Yubikey and Nitrokey are being tested. I'd also consider Trezor and Nano Ledger S but they look like an overkill. I also have a separate code signing card (Win/OSX), forgot who the manufacturer is, but I want to replace it as I'm not happy with it.\\r\\n\\r\\n> I hope without any backdoors by Intel/AMD/longsoon/any other chineese/taiwanese/russian company/etc?\\r\\n\\r\\nI don't know any laptops guaranteed without backdoors, apart from some very old models which aren't practically usable anymore, or they can't be bought in a physical shop in Europe. The one I bought has a CPU that according to specifications doesn't have TXE. If that means that the ME is entirely absent I don't know. The closest to what I want is probably Purism Librem (which uses Coreboot and has ME disabled) but I don't know how to get it in a physical shop in Europe.\\r\\n\\r\\n> Are you going to make business on it? But how are you going to make it sustainable? This will require money and I see no legit sources of money providing enough money for such a project, maybe except a grant by Mozilla.\\r\\n\\r\\nI've been thinking about revenue possibilities for quite some time and looking for a co-founder for about a year. I now found someone and we're investigating a particular business plan (he on the business side, me on the technical side). The details will be announced in due time. There are other possible business plans that can be investigated when we see growth. Supporting the project through grants is a possibility but I don't see it as a sustainable one.\"}, 'com_30': {'author': 'KOLANICH', 'datetime': '03/21/2018, 09:03:07', 'body': \">It looks like a wire protocol specification\\r\\n\\r\\nIt's binary formats spec, not protocol. Protocol spec is yet to be created, IMHO verilog shkuld be used for protocols specs.\\r\\n\\r\\n>but I want specification of both the Bitmessage system design as well as how PyBitmessage is put together\\r\\n\\r\\nI only advised a part suitable for describing message format.\\r\\n\\r\\n>It's also unclear to me at this point how TLS is supposed to be specified in Kaitai Struct.\\r\\n\\r\\nI have not implemented tls messages. And I guess BM has nothing to do with tls itself, tls should be managed by tls libraries, not by PBM itself.\\r\\n\\r\\n>I now found someone\\r\\n\\r\\nI hope it's not government agencies or cybercriminals.\"}}", "stats": "{'additions': 4, 'deletions': 3, 'total': 7}", "files": {"src/messagetypes/__init__.py": {"additions": 4, "deletions": 3, "changes": 7, "status": "modified", "raw_url": "https://github.com/Bitmessage/PyBitmessage/raw/3a8016d31f517775d226aa8b902480f4a3a148a9/src%2Fmessagetypes%2F__init__.py", "patch": "@@ -12,9 +12,10 @@ def encode(self):\n \n def constructObject(data):\n     try:\n-        classBase = eval(data[\"\"] + \".\" + data[\"\"].title())\n-    except NameError:\n-        logger.error(\"Don't know how to handle message type: \\\"%s\\\"\", data[\"\"])\n+        m = import_module(\"messagetypes.\" + data[\"\"])\n+        classBase = getattr(m, data[\"\"].title())\n+    except (NameError, ImportError):\n+        logger.error(\"Don't know how to handle message type: \\\"%s\\\"\", data[\"\"], exc_info=True)\n         return None\n     try:\n         returnObj = classBase()"}}, "prior_version": " def encode(self):  def constructObject(data):     try:         classBase = eval(data[\"\"] + \".\" + data[\"\"].title())     except NameError:         logger.error(\"Don't know how to handle message type: \\\"%s\\\"\", data[\"\"])         return None     try:         returnObj = classBase()", "after_version": " def encode(self):  def constructObject(data):     try:         m = import_module(\"messagetypes.\" + data[\"\"])         classBase = getattr(m, data[\"\"].title())     except (NameError, ImportError):         logger.error(\"Don't know how to handle message type: \\\"%s\\\"\", data[\"\"], exc_info=True)         return None     try:         returnObj = classBase()", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "CVE-2019-11340", "cwe_id": "{'CWE-20'}", "score": 2.9, "chain": "{'https://github.com/matrix-org/sydent/commit/4e1cfff53429c49c87d5c457a18ed435520044fc'}", "dataset": "nvd", "summary": "util/emailutils.py in Matrix Sydent before 1.0.2 mishandles registration restrictions that are based on e-mail domain, if the allowed_local_3pids option is enabled. This occurs because of potentially unwanted behavior in Python, in which an email.utils.parseaddr call on user@bad.example.net@good.example.com returns the user@bad.example.net substring.", "published_date": "2019-04-19", "chain_len": 1, "project": "https://github.com/matrix-org/sydent", "commit_href": "https://github.com/matrix-org/sydent/commit/4e1cfff53429c49c87d5c457a18ed435520044fc", "commit_sha": "4e1cfff53429c49c87d5c457a18ed435520044fc", "patch": "SINGLE", "chain_ord": "['4e1cfff53429c49c87d5c457a18ed435520044fc']", "before_first_fix_commit": "{'617ff31a52139f28e4780cb2793ddf552a1997e9'}", "last_fix_commit": "4e1cfff53429c49c87d5c457a18ed435520044fc", "chain_ord_pos": 1, "commit_datetime": "04/18/2019, 16:14:01", "message": "Require that parsed mail addresses match raw input\n\nPython's email parser turns malformed addresses into valid ones\nby removing anything after and including the second '@'. This\nmeant that sydent sent emails to the validated address but stored\nthe raw address as validated.\n\nThis rejects any requests where the parsed email address does not\nmatch the raw input.", "author": "David Baker", "comments": "{'com_1': {'author': 'myselfhimself', 'datetime': '04/23/2019, 17:40:19', 'body': \"How is this a fix... as shown also here https://bugs.python.org/msg329463 ?\\r\\nFollowing the [Python RFC here](https://docs.python.org/3/library/email.utils.html#email.utils.parseaddr) you should check for parsedFrom == ('', '') and same for parsedTo == ('', '')\"}, 'com_2': {'author': 'myselfhimself', 'datetime': '04/23/2019, 17:44:32', 'body': 'Don\\'t you want to check mailFrom != parsedFrom  and mailTo != parsedTo as stated in \"This rejects any requests where the parsed email address does not match the raw input.\" ?'}, 'com_3': {'author': 'kstefanini', 'datetime': '04/26/2019, 12:23:43', 'body': '@myselfhimself https://github.com/matrix-org/sydent/commit/3103b65dcfa37a9241dabedba560c4ded6c05ff6'}}", "stats": "{'additions': 11, 'deletions': 5, 'total': 16}", "files": {"sydent/util/emailutils.py": {"additions": 11, "deletions": 5, "changes": 16, "status": "modified", "raw_url": "https://github.com/matrix-org/sydent/raw/4e1cfff53429c49c87d5c457a18ed435520044fc/sydent%2Futil%2Femailutils.py", "patch": "@@ -55,12 +55,13 @@ def sendEmail(sydent, templateName, mailTo, substitutions):\n             allSubstitutions[k+\"_forhtml\"] = cgi.escape(v.decode('utf8'))\n             allSubstitutions[k+\"_forurl\"] = urllib.quote(v)\n \n-        mailString = open(mailTemplateFile).read() % allSubstitutions\n-        rawFrom = email.utils.parseaddr(mailFrom)[1]\n-        rawTo = email.utils.parseaddr(mailTo)[1]\n-        if rawFrom == '' or rawTo == '':\n+        mailString = open(mailTemplateFile).read().decode('utf8') % allSubstitutions\n+        parsedFrom = email.utils.parseaddr(mailFrom)[1]\n+        parsedTo = email.utils.parseaddr(mailTo)[1]\n+        if parsedFrom == '' or parsedTo == '':\n             logger.info(\"Couldn't parse from / to address %s / %s\", mailFrom, mailTo)\n             raise EmailAddressException()\n+\n         mailServer = sydent.cfg.get('email', 'email.smtphost')\n         mailPort = sydent.cfg.get('email', 'email.smtpport')\n         mailUsername = sydent.cfg.get('email', 'email.smtpusername')\n@@ -77,7 +78,12 @@ def sendEmail(sydent, templateName, mailTo, substitutions):\n                 smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n             if mailUsername != '':\n                 smtp.login(mailUsername, mailPassword)\n-            smtp.sendmail(rawFrom, rawTo, mailString.encode('utf-8'))\n+\n+            # We're using the parsing above to do basic validation, but instead of\n+            # failing it may munge the address it returns. So we should *not* use\n+            # that parsed address, as it may not match any validation done\n+            # elsewhere.\n+            smtp.sendmail(mailFrom, mailTo, mailString.encode('utf-8'))\n             smtp.quit()\n         except Exception as origException:\n             twisted.python.log.err()"}}, "prior_version": " def sendEmail(sydent, templateName, mailTo, substitutions):             allSubstitutions[k+\"_forhtml\"] = cgi.escape(v.decode('utf8'))             allSubstitutions[k+\"_forurl\"] = urllib.quote(v)          mailString = open(mailTemplateFile).read() % allSubstitutions         rawFrom = email.utils.parseaddr(mailFrom)[1]         rawTo = email.utils.parseaddr(mailTo)[1]         if rawFrom == '' or rawTo == '':             logger.info(\"Couldn't parse from / to address %s / %s\", mailFrom, mailTo)             raise EmailAddressException()         mailServer = sydent.cfg.get('email', 'email.smtphost')         mailPort = sydent.cfg.get('email', 'email.smtpport')         mailUsername = sydent.cfg.get('email', 'email.smtpusername') def sendEmail(sydent, templateName, mailTo, substitutions):                 smtp = smtplib.SMTP(mailServer, mailPort, myHostname)             if mailUsername != '':                 smtp.login(mailUsername, mailPassword)             smtp.sendmail(rawFrom, rawTo, mailString.encode('utf-8'))             smtp.quit()         except Exception as origException:             twisted.python.log.err()", "after_version": " def sendEmail(sydent, templateName, mailTo, substitutions):             allSubstitutions[k+\"_forhtml\"] = cgi.escape(v.decode('utf8'))             allSubstitutions[k+\"_forurl\"] = urllib.quote(v)          mailString = open(mailTemplateFile).read().decode('utf8') % allSubstitutions         parsedFrom = email.utils.parseaddr(mailFrom)[1]         parsedTo = email.utils.parseaddr(mailTo)[1]         if parsedFrom == '' or parsedTo == '':             logger.info(\"Couldn't parse from / to address %s / %s\", mailFrom, mailTo)             raise EmailAddressException()          mailServer = sydent.cfg.get('email', 'email.smtphost')         mailPort = sydent.cfg.get('email', 'email.smtpport')         mailUsername = sydent.cfg.get('email', 'email.smtpusername') def sendEmail(sydent, templateName, mailTo, substitutions):                 smtp = smtplib.SMTP(mailServer, mailPort, myHostname)             if mailUsername != '':                 smtp.login(mailUsername, mailPassword)              # We're using the parsing above to do basic validation, but instead of             # failing it may munge the address it returns. So we should *not* use             # that parsed address, as it may not match any validation done             # elsewhere.             smtp.sendmail(mailFrom, mailTo, mailString.encode('utf-8'))             smtp.quit()         except Exception as origException:             twisted.python.log.err()", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "CVE-2019-16215", "cwe_id": "{'CWE-400'}", "score": 2.9, "chain": "{'https://github.com/zulip/zulip/commit/5797f013b3be450c146a4141514bda525f2f1b51'}", "dataset": "nvd", "summary": "The Markdown parser in Zulip server before 2.0.5 used a regular expression vulnerable to exponential backtracking. A user who is logged into the server could send a crafted message causing the server to spend an effectively arbitrary amount of CPU time and stall the processing of future messages.", "published_date": "2019-09-18", "chain_len": 1, "project": "https://github.com/zulip/zulip", "commit_href": "https://github.com/zulip/zulip/commit/5797f013b3be450c146a4141514bda525f2f1b51", "commit_sha": "5797f013b3be450c146a4141514bda525f2f1b51", "patch": "SINGLE", "chain_ord": "['5797f013b3be450c146a4141514bda525f2f1b51']", "before_first_fix_commit": "{'1195841dfb9aa26b3b0dabc6f05d72e4af25be3e'}", "last_fix_commit": "5797f013b3be450c146a4141514bda525f2f1b51", "chain_ord_pos": 1, "commit_datetime": "04/05/2019, 00:31:57", "message": "CVE-2019-16215: Fix DoS vulnerability in Markdown LINK_RE.\n\nAny regex including a match-everything subpattern (.*, .*?, .+, or\n.+?) is almost automatically wrong because it fails to disambiguate\nwhen one subpattern should end and another should begin.  Among other\nbugs, these kind of regexes tend to be especially prone to denial of\nservice vulnerabilities through catastrophic backtracking on strings\nthat fail to match in a large (in this case, exponential) number of\nways.\n\nLacking a specification to say what characters should actually be\nallowed in these subpatterns (this syntax is too different from\nCommonMark to be able to precisely apply those rules), I\u2019ve tried to\nmake reasonable guesses and avoid changing much else.\n\nBecause Zulip doesn't store messages until they have successfully been\nprocessed by the Markdown processor, this is not a stored DoS issue.\n\nIn general, Zulip protects against the broad category of DoS issues in\nMarkdown rendering via a timeout managed by another thread.  However,\ndetails of Python's regular expression implementation mean that this\nparticular issue could prevent the timeout thread from being\nscheduled, resulting in this being a DoS issue.\n\nThis was fixed in master a few months ago as a side effect of\nabe2dab88ca96786bb32dea6caab873819b8c482 (#12979).\n\nSigned-off-by: Anders Kaseorg <anders@zulipchat.com>", "author": "Anders Kaseorg", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"zerver/lib/bugdown/__init__.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/zulip/zulip/raw/5797f013b3be450c146a4141514bda525f2f1b51/zerver%2Flib%2Fbugdown%2F__init__.py", "patch": "@@ -1484,7 +1484,7 @@ def get_link_re() -> str:\n \n     # [text](url) or [text](<url>) or [text](url \"title\")\n     LINK_RE = NOIMG + BRK + \\\n-        r'''\\(\\s*(<.*?>|((?:(?:\\(.*?\\))|[^\\(\\)]))*?)\\s*((['\"])(.*?)\\12\\s*)?\\)'''\n+        r'''\\(\\s*(<(?:[^<>\\\\]|\\\\.)*>|(\\([^()]*\\)|[^()])*?)\\s*(('(?:[^'\\\\]|\\\\.)*'|\"(?:[^\"\\\\]|\\\\.)*\")\\s*)?\\)'''\n     return normal_compile(LINK_RE)\n \n def prepare_realm_pattern(source: str) -> str:"}}, "prior_version": " def get_link_re() -> str:      # [text](url) or [text](<url>) or [text](url \"title\")     LINK_RE = NOIMG + BRK + \\         r'''\\(\\s*(<.*?>|((?:(?:\\(.*?\\))|[^\\(\\)]))*?)\\s*((['\"])(.*?)\\12\\s*)?\\)'''     return normal_compile(LINK_RE)  def prepare_realm_pattern(source: str) -> str:", "after_version": " def get_link_re() -> str:      # [text](url) or [text](<url>) or [text](url \"title\")     LINK_RE = NOIMG + BRK + \\         r'''\\(\\s*(<(?:[^<>\\\\]|\\\\.)*>|(\\([^()]*\\)|[^()])*?)\\s*(('(?:[^'\\\\]|\\\\.)*'|\"(?:[^\"\\\\]|\\\\.)*\")\\s*)?\\)'''     return normal_compile(LINK_RE)  def prepare_realm_pattern(source: str) -> str:", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "CVE-2019-25066", "cwe_id": "{'CWE-78'}", "score": 6.4, "chain": "{'https://github.com/ajenti/ajenti/commit/7aa146b724e0e20cfee2c71ca78fafbf53a8767c'}", "dataset": "nvd", "summary": "A vulnerability has been found in ajenti 2.1.31 and classified as critical. This vulnerability affects unknown code of the component API. The manipulation leads to privilege escalation. The attack can be initiated remotely. The exploit has been disclosed to the public and may be used. Upgrading to version 2.1.32 is able to address this issue. The name of the patch is 7aa146b724e0e20cfee2c71ca78fafbf53a8767c. It is recommended to upgrade the affected component.", "published_date": "2022-06-09", "chain_len": 1, "project": "https://github.com/ajenti/ajenti", "commit_href": "https://github.com/ajenti/ajenti/commit/7aa146b724e0e20cfee2c71ca78fafbf53a8767c", "commit_sha": "7aa146b724e0e20cfee2c71ca78fafbf53a8767c", "patch": "SINGLE", "chain_ord": "['7aa146b724e0e20cfee2c71ca78fafbf53a8767c']", "before_first_fix_commit": "{'ef385f96d7e9e09b81ca5e48dc4e04042d5a74a4'}", "last_fix_commit": "7aa146b724e0e20cfee2c71ca78fafbf53a8767c", "chain_ord_pos": 1, "commit_datetime": "10/05/2019, 14:06:48", "message": "fixed shell injection in os auth provider", "author": "Eugene Pankov", "comments": null, "stats": "{'additions': 8, 'deletions': 1, 'total': 9}", "files": {"ajenti-core/aj/auth.py": {"additions": 8, "deletions": 1, "changes": 9, "status": "modified", "raw_url": "https://github.com/ajenti/ajenti/raw/7aa146b724e0e20cfee2c71ca78fafbf53a8767c/ajenti-core%2Faj%2Fauth.py", "patch": "@@ -5,6 +5,7 @@\n import subprocess\n import syslog\n from jadi import component, service, interface\n+from six import PY3\n \n import aj\n from aj.api.http import BaseHttpHandler\n@@ -99,8 +100,14 @@ class OSAuthenticationProvider(AuthenticationProvider):\n \n     def authenticate(self, username, password):\n         child = None\n+\n+        if PY3:\n+            from shlex import quote\n+        else:\n+            from pipes import quote\n+\n         try:\n-            child = pexpect.spawn('/bin/sh', ['-c', '/bin/su -c \"/bin/echo SUCCESS\" - %s' % username], timeout=5)\n+            child = pexpect.spawn('/bin/sh', ['-c', '/bin/su -c \"/bin/echo SUCCESS\" - %s' % quote(username)], timeout=5)\n             child.expect('.*:')\n             child.sendline(password)\n             result = child.expect(['su: .*', 'SUCCESS'])"}}, "prior_version": " import subprocess import syslog from jadi import component, service, interface  import aj from aj.api.http import BaseHttpHandler class OSAuthenticationProvider(AuthenticationProvider):      def authenticate(self, username, password):         child = None         try:             child = pexpect.spawn('/bin/sh', ['-c', '/bin/su -c \"/bin/echo SUCCESS\" - %s' % username], timeout=5)             child.expect('.*:')             child.sendline(password)             result = child.expect(['su: .*', 'SUCCESS'])", "after_version": " import subprocess import syslog from jadi import component, service, interface from six import PY3  import aj from aj.api.http import BaseHttpHandler class OSAuthenticationProvider(AuthenticationProvider):      def authenticate(self, username, password):         child = None          if PY3:             from shlex import quote         else:             from pipes import quote          try:             child = pexpect.spawn('/bin/sh', ['-c', '/bin/su -c \"/bin/echo SUCCESS\" - %s' % quote(username)], timeout=5)             child.expect('.*:')             child.sendline(password)             result = child.expect(['su: .*', 'SUCCESS'])", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2020-23014", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/its-a-feature/Apfell/commit/5fc64502bc008388514f2b5d1160b677e3b4a7f3'}", "dataset": "nvd", "summary": "APfell 1.4 is vulnerable to authenticated reflected cross-site scripting (XSS) in /apiui/command_ through the payloadtypes_callback function, which allows an attacker to steal remote admin/user session and/or adding new users to the administration panel.", "published_date": "2021-01-26", "chain_len": 1, "project": "https://github.com/its-a-feature/Apfell", "commit_href": "https://github.com/its-a-feature/Apfell/commit/5fc64502bc008388514f2b5d1160b677e3b4a7f3", "commit_sha": "5fc64502bc008388514f2b5d1160b677e3b4a7f3", "patch": "SINGLE", "chain_ord": "['5fc64502bc008388514f2b5d1160b677e3b4a7f3']", "before_first_fix_commit": "{'f0fa9e680c9cfdd74b4f9178b0da0829ab8ea45f'}", "last_fix_commit": "5fc64502bc008388514f2b5d1160b677e3b4a7f3", "chain_ord_pos": 1, "commit_datetime": "04/19/2020, 16:58:23", "message": "fixed an 'Authenticated Cross-Site Scripting' bug on the command help page reported by 'Mohamed A. Baset' of 'Seekurity SA de C.V.' at 'Seekurity.com' on April 17,2020", "author": "Cody Thomas", "comments": null, "stats": "{'additions': 7, 'deletions': 2, 'total': 9}", "files": {"apfell-docker/app/routes/api_routes.py": {"additions": 7, "deletions": 2, "changes": 9, "status": "modified", "raw_url": "https://github.com/its-a-feature/Mythic/raw/5fc64502bc008388514f2b5d1160b677e3b4a7f3/apfell-docker%2Fapp%2Froutes%2Fapi_routes.py", "patch": "@@ -1,9 +1,10 @@\n-from app import apfell, links, use_ssl\n+from app import apfell, links, use_ssl, db_objects\n from sanic import response\n from jinja2 import Environment, PackageLoader\n from sanic_jwt.decorators import scoped, inject_user\n from app.routes.routes import respect_pivot\n import urllib.parse\n+import app.database_models.model as db_model\n \n env = Environment(loader=PackageLoader('app', 'templates'))\n \n@@ -15,7 +16,11 @@ async def apiui_command_help(request, user):\n     template = env.get_template('apiui_command_help.html')\n     if len(request.query_args) != 0:\n         data = urllib.parse.unquote(request.query_args[0][1])\n-        print(data)\n+        query = await db_model.payloadtype_query()\n+        try:\n+            payloadtype = await db_objects.get(query, ptype=data)\n+        except Exception as e:\n+            data = \"\"\n     else:\n         data = \"\"\n     if use_ssl:"}}, "prior_version": " from app import apfell, links, use_ssl from sanic import response from jinja2 import Environment, PackageLoader from sanic_jwt.decorators import scoped, inject_user from app.routes.routes import respect_pivot import urllib.parse  env = Environment(loader=PackageLoader('app', 'templates'))  async def apiui_command_help(request, user):     template = env.get_template('apiui_command_help.html')     if len(request.query_args) != 0:         data = urllib.parse.unquote(request.query_args[0][1])         print(data)     else:         data = \"\"     if use_ssl:", "after_version": " from app import apfell, links, use_ssl, db_objects from sanic import response from jinja2 import Environment, PackageLoader from sanic_jwt.decorators import scoped, inject_user from app.routes.routes import respect_pivot import urllib.parse import app.database_models.model as db_model  env = Environment(loader=PackageLoader('app', 'templates'))  async def apiui_command_help(request, user):     template = env.get_template('apiui_command_help.html')     if len(request.query_args) != 0:         data = urllib.parse.unquote(request.query_args[0][1])         query = await db_model.payloadtype_query()         try:             payloadtype = await db_objects.get(query, ptype=data)         except Exception as e:             data = \"\"     else:         data = \"\"     if use_ssl:", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2020-36324", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2'}", "dataset": "nvd", "summary": "Wikimedia Quarry analytics-quarry-web before 2020-12-15 allows Reflected XSS because app.py does not explicitly set the application/json content type.", "published_date": "2021-04-21", "chain_len": 1, "project": "https://github.com/wikimedia/analytics-quarry-web", "commit_href": "https://github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "commit_sha": "4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "patch": "SINGLE", "chain_ord": "['4b7e1d6a3a52ec6cf826a971135a38b0f74785d2']", "before_first_fix_commit": "{'085a51b2dee8b58882276d9fe090174252edb85e'}", "last_fix_commit": "4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "chain_ord_pos": 1, "commit_datetime": "12/15/2020, 16:55:55", "message": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "author": "Reedy", "comments": null, "stats": "{'additions': 12, 'deletions': 3, 'total': 15}", "files": {"quarry/web/app.py": {"additions": 12, "deletions": 3, "changes": 15, "status": "modified", "raw_url": "https://github.com/wikimedia/analytics-quarry-web/raw/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2/quarry%2Fweb%2Fapp.py", "patch": "@@ -398,9 +398,15 @@ def pref_get(key):\n         return \"Authentication required\", 401\n \n     if key in get_preferences():\n-        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n+        return Response(\n+            json.dumps({'key': key, 'value': get_preferences()[key]}),\n+            mimetype='application/json'\n+        )\n     else:\n-        return Response(json.dumps({'key': key, 'error': 'novalue'}))\n+        return Response(\n+            json.dumps({'key': key, 'error': 'novalue'}),\n+            mimetype='application/json'\n+        )\n \n \n @app.route(\"/api/preferences/set/<key>/<value>\")\n@@ -409,7 +415,10 @@ def pref_set(key, value):\n         return \"Authentication required\", 401\n \n     get_preferences()[key] = (None if value == 'null' else value)\n-    return Response(json.dumps({'key': key, 'success': ''})), 201\n+    return Response(\n+        json.dumps({'key': key, 'success': ''}),\n+        mimetype='application/json'\n+    ), 201\n \n \n if __name__ == '__main__':"}}, "prior_version": " def pref_get(key):         return \"Authentication required\", 401      if key in get_preferences():         return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))     else:         return Response(json.dumps({'key': key, 'error': 'novalue'}))   @app.route(\"/api/preferences/set/<key>/<value>\") def pref_set(key, value):         return \"Authentication required\", 401      get_preferences()[key] = (None if value == 'null' else value)     return Response(json.dumps({'key': key, 'success': ''})), 201   if __name__ == '__main__':", "after_version": " def pref_get(key):         return \"Authentication required\", 401      if key in get_preferences():         return Response(             json.dumps({'key': key, 'value': get_preferences()[key]}),             mimetype='application/json'         )     else:         return Response(             json.dumps({'key': key, 'error': 'novalue'}),             mimetype='application/json'         )   @app.route(\"/api/preferences/set/<key>/<value>\") def pref_set(key, value):         return \"Authentication required\", 401      get_preferences()[key] = (None if value == 'null' else value)     return Response(         json.dumps({'key': key, 'success': ''}),         mimetype='application/json'     ), 201   if __name__ == '__main__':", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2020-5283", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/viewvc/viewvc/commit/ad0f966e9a997b17d853a6972ea283d4dcd70fa8'}", "dataset": "nvd", "summary": "ViewVC before versions 1.1.28 and 1.2.1 has a XSS vulnerability in CVS show_subdir_lastmod support. The impact of this vulnerability is mitigated by the need for an attacker to have commit privileges to a CVS repository exposed by an otherwise trusted ViewVC instance that also has the `show_subdir_lastmod` feature enabled. The attack vector involves files with unsafe names (names that, when embedded into an HTML stream, would cause the browser to run unwanted code), which themselves can be challenging to create. This vulnerability is patched in versions 1.2.1 and 1.1.28.", "published_date": "2020-04-03", "chain_len": 1, "project": "https://github.com/viewvc/viewvc", "commit_href": "https://github.com/viewvc/viewvc/commit/ad0f966e9a997b17d853a6972ea283d4dcd70fa8", "commit_sha": "ad0f966e9a997b17d853a6972ea283d4dcd70fa8", "patch": "SINGLE", "chain_ord": "['ad0f966e9a997b17d853a6972ea283d4dcd70fa8']", "before_first_fix_commit": "{'793889520509e3eaa8252965f1aeec0b64cd25e6'}", "last_fix_commit": "ad0f966e9a997b17d853a6972ea283d4dcd70fa8", "chain_ord_pos": 1, "commit_datetime": "03/26/2020, 18:11:41", "message": "issue #211: escape CVS subdir last-modified file name", "author": "C. Michael Pilato", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"lib/viewvc.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/viewvc/viewvc/raw/ad0f966e9a997b17d853a6972ea283d4dcd70fa8/lib%2Fviewvc.py", "patch": "@@ -2412,7 +2412,7 @@ def view_directory(request):\n       if request.roottype == 'cvs' and file.rev is not None:\n         row.rev = None\n         if cfg.options.show_logs:\n-          row.log_file = file.newest_file\n+          row.log_file = request.server.escape(file.newest_file)\n           row.log_rev = file.rev\n \n       if request.roottype == 'svn':"}}, "prior_version": " def view_directory(request):       if request.roottype == 'cvs' and file.rev is not None:         row.rev = None         if cfg.options.show_logs:           row.log_file = file.newest_file           row.log_rev = file.rev        if request.roottype == 'svn':", "after_version": " def view_directory(request):       if request.roottype == 'cvs' and file.rev is not None:         row.rev = None         if cfg.options.show_logs:           row.log_file = request.server.escape(file.newest_file)           row.log_rev = file.rev        if request.roottype == 'svn':", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2020-8545", "cwe_id": "{'CWE-22'}", "score": 2.9, "chain": "{'https://github.com/CIRCL/AIL-framework/commit/e808840f957c810b8e3944cba808716dc722581b'}", "dataset": "nvd", "summary": "Global.py in AIL framework 2.8 allows path traversal.", "published_date": "2020-02-03", "chain_len": 1, "project": "https://github.com/CIRCL/AIL-framework", "commit_href": "https://github.com/CIRCL/AIL-framework/commit/e808840f957c810b8e3944cba808716dc722581b", "commit_sha": "e808840f957c810b8e3944cba808716dc722581b", "patch": "SINGLE", "chain_ord": "['e808840f957c810b8e3944cba808716dc722581b']", "before_first_fix_commit": "{'e19a3b3e630ed8cacd492e5c36ffa59c3cdfac78'}", "last_fix_commit": "e808840f957c810b8e3944cba808716dc722581b", "chain_ord_pos": 1, "commit_datetime": "02/03/2020, 09:32:20", "message": "fix: [Global: filename provided by all feeders] avoid path tranversal", "author": "Terrtia", "comments": null, "stats": "{'additions': 31, 'deletions': 23, 'total': 54}", "files": {"bin/Global.py": {"additions": 31, "deletions": 23, "changes": 54, "status": "modified", "raw_url": "https://github.com/CIRCL/AIL-framework/raw/e808840f957c810b8e3944cba808716dc722581b/bin%2FGlobal.py", "patch": "@@ -45,8 +45,10 @@ def rreplace(s, old, new, occurrence):\n \n     p = Process(config_section)\n \n+    # get and sanityze PASTE DIRECTORY\n     PASTES_FOLDER = os.path.join(os.environ['AIL_HOME'], p.config.get(\"Directories\", \"pastes\"))\n     PASTES_FOLDERS = PASTES_FOLDER + '/'\n+    PASTES_FOLDERS = os.path.join(os.path.realpath(PASTES_FOLDERS), '')\n \n     # LOGGING #\n     publisher.info(\"Feed Script started to receive & publish.\")\n@@ -75,40 +77,46 @@ def rreplace(s, old, new, occurrence):\n             time.sleep(1)\n             continue\n \n+        # remove PASTES_FOLDER from item path (crawled item + submited)\n+        if PASTES_FOLDERS in paste:\n+            paste = paste.replace(PASTES_FOLDERS, '', 1)\n+\n         file_name_paste = paste.split('/')[-1]\n         if len(file_name_paste)>255:\n             new_file_name_paste = '{}{}.gz'.format(file_name_paste[:215], str(uuid.uuid4()))\n             paste = rreplace(paste, file_name_paste, new_file_name_paste, 1)\n \n         # Creating the full filepath\n         filename = os.path.join(PASTES_FOLDER, paste)\n+        filename = os.path.realpath(filename)\n \n-        dirname = os.path.dirname(filename)\n-        if not os.path.exists(dirname):\n-            os.makedirs(dirname)\n-\n-        decoded = base64.standard_b64decode(gzip64encoded)\n+        # incorrect filename\n+        if not os.path.commonprefix([filename, PASTES_FOLDER]) == PASTES_FOLDER:\n+            print('Path traversal detected {}'.format(filename))\n+            publisher.warning('Global; Path traversal detected')\n+        else:\n+            dirname = os.path.dirname(filename)\n+            if not os.path.exists(dirname):\n+                os.makedirs(dirname)\n \n-        with open(filename, 'wb') as f:\n-            f.write(decoded)\n-        '''try:\n-            decoded2 = gunzip_bytes_obj(decoded)\n-        except:\n-            decoded2 =''\n+            decoded = base64.standard_b64decode(gzip64encoded)\n \n-        type = magic.from_buffer(decoded2, mime=True)\n+            with open(filename, 'wb') as f:\n+                f.write(decoded)\n+            '''try:\n+                decoded2 = gunzip_bytes_obj(decoded)\n+            except:\n+                decoded2 =''\n \n-        if type!= 'text/x-c++' and type!= 'text/html' and type!= 'text/x-c' and type!= 'text/x-python' and type!= 'text/x-php' and type!= 'application/xml' and type!= 'text/x-shellscript' and type!= 'text/plain' and type!= 'text/x-diff' and type!= 'text/x-ruby':\n+            type = magic.from_buffer(decoded2, mime=True)\n \n-            print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n-            print(filename)\n-            print(type)\n-            print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n-        '''\n+            if type!= 'text/x-c++' and type!= 'text/html' and type!= 'text/x-c' and type!= 'text/x-python' and type!= 'text/x-php' and type!= 'application/xml' and type!= 'text/x-shellscript' and type!= 'text/plain' and type!= 'text/x-diff' and type!= 'text/x-ruby':\n \n-        # remove PASTES_FOLDER from item path (crawled item + submited)\n-        if PASTES_FOLDERS in paste:\n-            paste = paste.replace(PASTES_FOLDERS, '', 1)\n+                print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n+                print(filename)\n+                print(type)\n+                print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n+            '''\n \n-        p.populate_set_out(paste)\n-        processed_paste+=1\n+            p.populate_set_out(paste)\n+            processed_paste+=1"}}, "prior_version": " def rreplace(s, old, new, occurrence):      p = Process(config_section)      PASTES_FOLDER = os.path.join(os.environ['AIL_HOME'], p.config.get(\"Directories\", \"pastes\"))     PASTES_FOLDERS = PASTES_FOLDER + '/'      # LOGGING #     publisher.info(\"Feed Script started to receive & publish.\") def rreplace(s, old, new, occurrence):             time.sleep(1)             continue          file_name_paste = paste.split('/')[-1]         if len(file_name_paste)>255:             new_file_name_paste = '{}{}.gz'.format(file_name_paste[:215], str(uuid.uuid4()))             paste = rreplace(paste, file_name_paste, new_file_name_paste, 1)          # Creating the full filepath         filename = os.path.join(PASTES_FOLDER, paste)          dirname = os.path.dirname(filename)         if not os.path.exists(dirname):             os.makedirs(dirname)          decoded = base64.standard_b64decode(gzip64encoded)          with open(filename, 'wb') as f:             f.write(decoded)         '''try:             decoded2 = gunzip_bytes_obj(decoded)         except:             decoded2 =''          type = magic.from_buffer(decoded2, mime=True)          if type!= 'text/x-c++' and type!= 'text/html' and type!= 'text/x-c' and type!= 'text/x-python' and type!= 'text/x-php' and type!= 'application/xml' and type!= 'text/x-shellscript' and type!= 'text/plain' and type!= 'text/x-diff' and type!= 'text/x-ruby':              print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             print(filename)             print(type)             print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')         '''          # remove PASTES_FOLDER from item path (crawled item + submited)         if PASTES_FOLDERS in paste:             paste = paste.replace(PASTES_FOLDERS, '', 1)          p.populate_set_out(paste)         processed_paste+=1", "after_version": " def rreplace(s, old, new, occurrence):      p = Process(config_section)      # get and sanityze PASTE DIRECTORY     PASTES_FOLDER = os.path.join(os.environ['AIL_HOME'], p.config.get(\"Directories\", \"pastes\"))     PASTES_FOLDERS = PASTES_FOLDER + '/'     PASTES_FOLDERS = os.path.join(os.path.realpath(PASTES_FOLDERS), '')      # LOGGING #     publisher.info(\"Feed Script started to receive & publish.\") def rreplace(s, old, new, occurrence):             time.sleep(1)             continue          # remove PASTES_FOLDER from item path (crawled item + submited)         if PASTES_FOLDERS in paste:             paste = paste.replace(PASTES_FOLDERS, '', 1)          file_name_paste = paste.split('/')[-1]         if len(file_name_paste)>255:             new_file_name_paste = '{}{}.gz'.format(file_name_paste[:215], str(uuid.uuid4()))             paste = rreplace(paste, file_name_paste, new_file_name_paste, 1)          # Creating the full filepath         filename = os.path.join(PASTES_FOLDER, paste)         filename = os.path.realpath(filename)          # incorrect filename         if not os.path.commonprefix([filename, PASTES_FOLDER]) == PASTES_FOLDER:             print('Path traversal detected {}'.format(filename))             publisher.warning('Global; Path traversal detected')         else:             dirname = os.path.dirname(filename)             if not os.path.exists(dirname):                 os.makedirs(dirname)              decoded = base64.standard_b64decode(gzip64encoded)              with open(filename, 'wb') as f:                 f.write(decoded)             '''try:                 decoded2 = gunzip_bytes_obj(decoded)             except:                 decoded2 =''              type = magic.from_buffer(decoded2, mime=True)              if type!= 'text/x-c++' and type!= 'text/html' and type!= 'text/x-c' and type!= 'text/x-python' and type!= 'text/x-php' and type!= 'application/xml' and type!= 'text/x-shellscript' and type!= 'text/plain' and type!= 'text/x-diff' and type!= 'text/x-ruby':                  print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')                 print(filename)                 print(type)                 print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             '''              p.populate_set_out(paste)             processed_paste+=1", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2021-21329", "cwe_id": "{'CWE-287'}", "score": 6.4, "chain": "{'https://github.com/ractf/core/commit/cebb67bd16a8296121201805332365ffccb29638'}", "dataset": "nvd", "summary": "RATCF is an open-source framework for hosting Cyber-Security Capture the Flag events. In affected versions of RATCF users with multi factor authentication enabled are able to log in without a valid token. This is fixed in commit cebb67b.", "published_date": "2021-03-08", "chain_len": 1, "project": "https://github.com/ractf/core", "commit_href": "https://github.com/ractf/core/commit/cebb67bd16a8296121201805332365ffccb29638", "commit_sha": "cebb67bd16a8296121201805332365ffccb29638", "patch": "SINGLE", "chain_ord": "['cebb67bd16a8296121201805332365ffccb29638']", "before_first_fix_commit": "{'dc06fb425cda8e3bec271cfe98620fab493c4992'}", "last_fix_commit": "cebb67bd16a8296121201805332365ffccb29638", "chain_ord_pos": 1, "commit_datetime": "02/26/2021, 11:41:20", "message": "Merge pull request from GHSA-fw57-f7mq-9q85", "author": "David Cooke", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"src/authentication/views.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/ractf/core/raw/cebb67bd16a8296121201805332365ffccb29638/src%2Fauthentication%2Fviews.py", "patch": "@@ -150,7 +150,7 @@ def post(self, request, *args, **kwargs):\n                     code.delete()\n                     return self.issue_token(user)\n \n-        return self.issue_token(user)\n+        return FormattedResponse(status=HTTP_401_UNAUTHORIZED, d={'reason': 'login_failed'}, m='login_failed')\n \n \n class RegenerateBackupCodesView(APIView):"}}, "prior_version": " def post(self, request, *args, **kwargs):                     code.delete()                     return self.issue_token(user)          return self.issue_token(user)   class RegenerateBackupCodesView(APIView):", "after_version": " def post(self, request, *args, **kwargs):                     code.delete()                     return self.issue_token(user)          return FormattedResponse(status=HTTP_401_UNAUTHORIZED, d={'reason': 'login_failed'}, m='login_failed')   class RegenerateBackupCodesView(APIView):", "file_extension": "py", "cwe": "CWE-287"}
{"vuln_id": "CVE-2021-21433", "cwe_id": "{'CWE-94'}", "score": 6.4, "chain": "{'https://github.com/DEMON1A/Discord-Recon/commit/26e2a084679679cccdeeabbb6889ce120eff7e50'}", "dataset": "nvd", "summary": "Discord Recon Server is a bot that allows you to do your reconnaissance process from your Discord. Remote code execution in version 0.0.1 would allow remote users to execute commands on the server resulting in serious issues. This flaw is patched in 0.0.2.", "published_date": "2021-04-09", "chain_len": 1, "project": "https://github.com/DEMON1A/Discord-Recon", "commit_href": "https://github.com/DEMON1A/Discord-Recon/commit/26e2a084679679cccdeeabbb6889ce120eff7e50", "commit_sha": "26e2a084679679cccdeeabbb6889ce120eff7e50", "patch": "SINGLE", "chain_ord": "['26e2a084679679cccdeeabbb6889ce120eff7e50']", "before_first_fix_commit": "{'a6996fb801df313173453084525cdb3973a89c0b'}", "last_fix_commit": "26e2a084679679cccdeeabbb6889ce120eff7e50", "chain_ord_pos": 1, "commit_datetime": "02/25/2021, 10:32:33", "message": "Fixing Command Injection Issues.", "author": "Mohamed Dief", "comments": null, "stats": "{'additions': 8, 'deletions': 0, 'total': 8}", "files": {"app.py": {"additions": 8, "deletions": 0, "changes": 8, "status": "modified", "raw_url": "https://github.com/DEMON1A/Discord-Recon/raw/26e2a084679679cccdeeabbb6889ce120eff7e50/app.py", "patch": "@@ -95,6 +95,10 @@ async def ip(ctx , *, argument):\n \n @Client.command()\n async def dirsearch(ctx , *, argument):\n+    if not CommandInjection.commandInjection(argument=argument , RCE=RCE):\n+        await ctx.send(\"**Your Command Contains Unallowed Chars. Don't Try To Use It Again.**\")\n+        return\n+    \n     Path = TOOLS['dirsearch']; MainPath = getcwd(); chdir(Path)\n     await ctx.send(f\"**Running Your Dirsearch Scan, We Will Send The Results When It's Done**\")\n     Process = subprocess.Popen(f'python3 dirsearch.py -u {argument} -e * -b' , shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)\n@@ -115,6 +119,10 @@ async def dirsearch(ctx , *, argument):\n \n @Client.command()\n async def arjun(ctx , *, argument):\n+    if not CommandInjection.commandInjection(argument=argument , RCE=RCE):\n+        await ctx.send(\"**Your Command Contains Unallowed Chars. Don't Try To Use It Again.**\")\n+        return\n+    \n     Path = TOOLS['arjun']; MainPath = getcwd(); chdir(Path)\n     await ctx.send(f\"**Running Your Arjun Scan, We Will Send The Results When It's Done**\")\n     await ctx.send(f\"**Note: The Bot Won't Respond Until The Scan is Done. All Of Your Commands Now Will Be Executed After This Process is Done.\")"}}, "prior_version": " async def ip(ctx , *, argument):  @Client.command() async def dirsearch(ctx , *, argument):     Path = TOOLS['dirsearch']; MainPath = getcwd(); chdir(Path)     await ctx.send(f\"**Running Your Dirsearch Scan, We Will Send The Results When It's Done**\")     Process = subprocess.Popen(f'python3 dirsearch.py -u {argument} -e * -b' , shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT) async def dirsearch(ctx , *, argument):  @Client.command() async def arjun(ctx , *, argument):     Path = TOOLS['arjun']; MainPath = getcwd(); chdir(Path)     await ctx.send(f\"**Running Your Arjun Scan, We Will Send The Results When It's Done**\")     await ctx.send(f\"**Note: The Bot Won't Respond Until The Scan is Done. All Of Your Commands Now Will Be Executed After This Process is Done.\")", "after_version": " async def ip(ctx , *, argument):  @Client.command() async def dirsearch(ctx , *, argument):     if not CommandInjection.commandInjection(argument=argument , RCE=RCE):         await ctx.send(\"**Your Command Contains Unallowed Chars. Don't Try To Use It Again.**\")         return          Path = TOOLS['dirsearch']; MainPath = getcwd(); chdir(Path)     await ctx.send(f\"**Running Your Dirsearch Scan, We Will Send The Results When It's Done**\")     Process = subprocess.Popen(f'python3 dirsearch.py -u {argument} -e * -b' , shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT) async def dirsearch(ctx , *, argument):  @Client.command() async def arjun(ctx , *, argument):     if not CommandInjection.commandInjection(argument=argument , RCE=RCE):         await ctx.send(\"**Your Command Contains Unallowed Chars. Don't Try To Use It Again.**\")         return          Path = TOOLS['arjun']; MainPath = getcwd(); chdir(Path)     await ctx.send(f\"**Running Your Arjun Scan, We Will Send The Results When It's Done**\")     await ctx.send(f\"**Note: The Bot Won't Respond Until The Scan is Done. All Of Your Commands Now Will Be Executed After This Process is Done.\")", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "CVE-2022-1531", "cwe_id": "{'CWE-89'}", "score": 10.0, "chain": "{'https://github.com/rtxteam/rtx/commit/fa2797e656e3dba18f990a2db1f0f029d41f1921'}", "dataset": "nvd", "summary": "SQL injection vulnerability in ARAX-UI Synonym Lookup functionality in GitHub repository rtxteam/rtx prior to checkpoint_2022-04-20 . This vulnerability is critical as it can lead to remote code execution and thus complete server takeover.", "published_date": "2022-04-29", "chain_len": 1, "project": "https://github.com/rtxteam/rtx", "commit_href": "https://github.com/rtxteam/rtx/commit/fa2797e656e3dba18f990a2db1f0f029d41f1921", "commit_sha": "fa2797e656e3dba18f990a2db1f0f029d41f1921", "patch": "SINGLE", "chain_ord": "['fa2797e656e3dba18f990a2db1f0f029d41f1921']", "before_first_fix_commit": "{'12b9fa79bbe71299dfe3e9211239b381153014df'}", "last_fix_commit": "fa2797e656e3dba18f990a2db1f0f029d41f1921", "chain_ord_pos": 1, "commit_datetime": "04/20/2022, 18:38:35", "message": "avoid SQL injection exploits", "author": "Eric Deutsch", "comments": "{'com_1': {'author': 'dkoslicki', 'datetime': '04/20/2022, 19:34:13', 'body': 'Should we use query parameters/substitution variables instead? Since otherwise we would need to anticipate all special characters, right? (disclaimer: Not my area of expertise)'}, 'com_2': {'author': 'dkoslicki', 'datetime': '04/20/2022, 19:41:21', 'body': 'Maybe something like changing:\\r\\n```\\r\\ncursor.execute(f\"SELECT term FROM terms WHERE term > \\\\\"{floor}\\\\\" AND term < \\\\\"{ceiling}\\\\\" AND term LIKE \\\\\"{word}%%\\\\\" ORDER BY length(term),term LIMIT {requested_limit}\")\\r\\n```\\r\\nto\\r\\n```\\r\\ncursor.execute(\"SELECT term FROM terms WHERE term > %(floor)s AND term < %(ceiling)s AND term LIKE %(word)s ORDER BY length(term),term LIMIT %(requested_limit)d\", {\\'floor\\': floor, \\'ceiling\\': ceiling, \\'word\\': word, \\'requested_limit\\': requested_limit)\\r\\n```\\r\\nthat way types are respected. My VM is borked atm, otherwise I would test this out'}, 'com_3': {'author': 'edeutsch', 'datetime': '04/20/2022, 23:20:54', 'body': 'I don\\'t really know for sure, but don\\'t think your proposal solves the problem. I think it would be just as vulnerable to the exploit. But I am not certain. Using prepared statements is likely the safest way to do this. But I think stripping out all \" characters renders it safe, too. I should do some more testing.'}, 'com_4': {'author': 'saramsey', 'datetime': '04/21/2022, 16:48:35', 'body': 'Good discussion. Yes, prepared statements are _generally_ described as protecting against SQL injection but of course, would need to be tested in the context of a specific library and query.'}}", "stats": "{'additions': 10, 'deletions': 2, 'total': 12}", "files": {"code/autocomplete/rtxcomplete.py": {"additions": 10, "deletions": 2, "changes": 12, "status": "modified", "raw_url": "https://github.com/RTXteam/RTX/raw/fa2797e656e3dba18f990a2db1f0f029d41f1921/code%2Fautocomplete%2Frtxcomplete.py", "patch": "@@ -23,6 +23,7 @@ def load():\n     database_name = f\"{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}\"\n     conn = sqlite3.connect(database_name)\n     cursor = conn.cursor()\n+    #print(f\"INFO: Connected to {database_name}\",file=sys.stderr)\n     return True\n \n \n@@ -39,6 +40,9 @@ def get_nodes_like(word,requested_limit):\n     if len(word) < 2:\n         return values\n \n+    #### Try to avoid SQL injection exploits by sanitizing input #1823\n+    word = word.replace('\"','')\n+\n     floor = word[:-1]\n     ceiling = floor + 'zz'\n \n@@ -103,8 +107,12 @@ def get_nodes_like(word,requested_limit):\n         if found_fragment is None:\n \n             #### Cache this fragment in the database\n-            cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))\n-            fragment_id = cursor.lastrowid\n+            try:\n+                cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))\n+                fragment_id = cursor.lastrowid\n+            except:\n+                print(f\"ERROR: Unable to INSERT into cached_fragments(fragment)\",file=sys.stderr)\n+                fragment_id = 0\n             if debug:\n                 print(f\"fragment_id = {fragment_id}\")"}}, "prior_version": " def load():     database_name = f\"{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}\"     conn = sqlite3.connect(database_name)     cursor = conn.cursor()     return True   def get_nodes_like(word,requested_limit):     if len(word) < 2:         return values      floor = word[:-1]     ceiling = floor + 'zz'  def get_nodes_like(word,requested_limit):         if found_fragment is None:              #### Cache this fragment in the database             cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))             fragment_id = cursor.lastrowid             if debug:                 print(f\"fragment_id = {fragment_id}\") ", "after_version": " def load():     database_name = f\"{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}\"     conn = sqlite3.connect(database_name)     cursor = conn.cursor()     #print(f\"INFO: Connected to {database_name}\",file=sys.stderr)     return True   def get_nodes_like(word,requested_limit):     if len(word) < 2:         return values      #### Try to avoid SQL injection exploits by sanitizing input #1823     word = word.replace('\"','')      floor = word[:-1]     ceiling = floor + 'zz'  def get_nodes_like(word,requested_limit):         if found_fragment is None:              #### Cache this fragment in the database             try:                 cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))                 fragment_id = cursor.lastrowid             except:                 print(f\"ERROR: Unable to INSERT into cached_fragments(fragment)\",file=sys.stderr)                 fragment_id = 0             if debug:                 print(f\"fragment_id = {fragment_id}\") ", "file_extension": "py", "cwe": "CWE-89"}
{"vuln_id": "CVE-2022-1806", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/rtxteam/rtx/commit/9bb109b0014f952f315c7b89e0f29a9ba84ee04c'}", "dataset": "nvd", "summary": "Cross-site Scripting (XSS) - Reflected in GitHub repository rtxteam/rtx prior to checkpoint_2022-05-18.", "published_date": "2022-05-20", "chain_len": 1, "project": "https://github.com/rtxteam/rtx", "commit_href": "https://github.com/rtxteam/rtx/commit/9bb109b0014f952f315c7b89e0f29a9ba84ee04c", "commit_sha": "9bb109b0014f952f315c7b89e0f29a9ba84ee04c", "patch": "SINGLE", "chain_ord": "['9bb109b0014f952f315c7b89e0f29a9ba84ee04c']", "before_first_fix_commit": "{'ebdb3856d3ce23df62fd7fc3186d3f5f13ea4337'}", "last_fix_commit": "9bb109b0014f952f315c7b89e0f29a9ba84ee04c", "chain_ord_pos": 1, "commit_datetime": "05/18/2022, 03:32:13", "message": "remove some cruft and implement a sanitizer for the client-supplied callback function name", "author": "Eric Deutsch", "comments": null, "stats": "{'additions': 25, 'deletions': 23, 'total': 48}", "files": {"code/autocomplete/server.py": {"additions": 25, "deletions": 23, "changes": 48, "status": "modified", "raw_url": "https://github.com/RTXteam/RTX/raw/9bb109b0014f952f315c7b89e0f29a9ba84ee04c/code%2Fautocomplete%2Fserver.py", "patch": "@@ -6,32 +6,35 @@\n import sys\n import rtxcomplete\n import traceback\n-\n-#class MainHandler(tornado.web.RequestHandler):\n-#    def get(self):\n-#        self.write(\"Hello, world\")\n-#print __file__\n+import re\n \n root = os.path.dirname(os.path.abspath(__file__))\n rtxcomplete.load()\n-#conn = sqlite3.connect('dict.db')\n-#conn.enable_load_extension(True)\n-#conn.load_extension(\"./spellfix\")\n-#cursor = conn.cursor()\n+\n+\n+#### Sanitize the client-provided callback function name\n+def sanitize_callback(callback):\n+    if callback is None or not isinstance(callback,str):\n+        return 'autocomplete_callback'\n+    match = re.match(r'([a-zA-Z0-9_]+).*$', callback)\n+    if match:\n+         callback = match.group(1)\n+    else:\n+         callback = 'autocomplete_callback'\n+    return callback\n+\n \n class autoSearch(tornado.web.RequestHandler):\n \n     def get(self, arg,word=None):\n-        #print \"match auto\"\n         try:\n             limit = self.get_argument(\"limit\")\n             word = self.get_argument(\"word\")\n-            callback = self.get_argument(\"callback\") #jsonp\n+            callback = sanitize_callback(self.get_argument(\"callback\"))\n \n             result = rtxcomplete.prefix(word,limit)\n-\n-            result = callback+\"(\"+json.dumps(result)+\");\" #jsonp\n-            #result = json.dumps(result) #typeahead\n+            \n+            result = callback+\"(\"+json.dumps(result)+\");\"\n             \n             self.write(result)\n             \n@@ -47,7 +50,7 @@ def get(self, arg,word=None):\n         try:\n             limit = self.get_argument(\"limit\")\n             word = self.get_argument(\"word\")\n-            callback = self.get_argument(\"callback\")\n+            callback = sanitize_callback(self.get_argument(\"callback\"))\n             #print word\n             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)\n             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit)\n@@ -73,7 +76,7 @@ def get(self, arg,word=None):\n         try:\n             limit = self.get_argument(\"limit\")\n             word = self.get_argument(\"word\")\n-            callback = self.get_argument(\"callback\")\n+            callback = sanitize_callback(self.get_argument(\"callback\"))\n             #print word\n             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)\n             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit)\n@@ -96,18 +99,17 @@ def get(self, arg,word=None):\n \n class nodesLikeSearch(tornado.web.RequestHandler):\n     def get(self, arg,word=None):\n-        #try:\n-        if 1 == 1:\n+        try:\n             limit = self.get_argument(\"limit\")\n             word = self.get_argument(\"word\")\n-            callback = self.get_argument(\"callback\")\n+            callback = sanitize_callback(self.get_argument(\"callback\"))\n             result = rtxcomplete.get_nodes_like(word,limit);\n             result = callback+\"(\"+json.dumps(result)+\");\"\n             self.write(result)\n-        #except:\n-        #    print(sys.exc_info()[:])\n-        #    traceback.print_tb(sys.exc_info()[-1])\n-        #    self.write(\"error\")\n+        except:\n+            print(sys.exc_info()[:])\n+            traceback.print_tb(sys.exc_info()[-1])\n+            self.write(\"error\")\n \n \n class defineSearch(tornado.web.RequestHandler):"}}, "prior_version": " import sys import rtxcomplete import traceback  #class MainHandler(tornado.web.RequestHandler): #    def get(self): #        self.write(\"Hello, world\") #print __file__  root = os.path.dirname(os.path.abspath(__file__)) rtxcomplete.load() #conn = sqlite3.connect('dict.db') #conn.enable_load_extension(True) #conn.load_extension(\"./spellfix\") #cursor = conn.cursor()  class autoSearch(tornado.web.RequestHandler):      def get(self, arg,word=None):         #print \"match auto\"         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = self.get_argument(\"callback\") #jsonp              result = rtxcomplete.prefix(word,limit)              result = callback+\"(\"+json.dumps(result)+\");\" #jsonp             #result = json.dumps(result) #typeahead                          self.write(result)              def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = self.get_argument(\"callback\")             #print word             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit) def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = self.get_argument(\"callback\")             #print word             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit) def get(self, arg,word=None):  class nodesLikeSearch(tornado.web.RequestHandler):     def get(self, arg,word=None):         #try:         if 1 == 1:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = self.get_argument(\"callback\")             result = rtxcomplete.get_nodes_like(word,limit);             result = callback+\"(\"+json.dumps(result)+\");\"             self.write(result)         #except:         #    print(sys.exc_info()[:])         #    traceback.print_tb(sys.exc_info()[-1])         #    self.write(\"error\")   class defineSearch(tornado.web.RequestHandler):", "after_version": " import sys import rtxcomplete import traceback import re  root = os.path.dirname(os.path.abspath(__file__)) rtxcomplete.load()   #### Sanitize the client-provided callback function name def sanitize_callback(callback):     if callback is None or not isinstance(callback,str):         return 'autocomplete_callback'     match = re.match(r'([a-zA-Z0-9_]+).*$', callback)     if match:          callback = match.group(1)     else:          callback = 'autocomplete_callback'     return callback   class autoSearch(tornado.web.RequestHandler):      def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = sanitize_callback(self.get_argument(\"callback\"))              result = rtxcomplete.prefix(word,limit)                          result = callback+\"(\"+json.dumps(result)+\");\"                          self.write(result)              def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = sanitize_callback(self.get_argument(\"callback\"))             #print word             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit) def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = sanitize_callback(self.get_argument(\"callback\"))             #print word             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit) def get(self, arg,word=None):  class nodesLikeSearch(tornado.web.RequestHandler):     def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = sanitize_callback(self.get_argument(\"callback\"))             result = rtxcomplete.get_nodes_like(word,limit);             result = callback+\"(\"+json.dumps(result)+\");\"             self.write(result)         except:             print(sys.exc_info()[:])             traceback.print_tb(sys.exc_info()[-1])             self.write(\"error\")   class defineSearch(tornado.web.RequestHandler):", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2022-1813", "cwe_id": "{'CWE-78'}", "score": 6.4, "chain": "{'https://github.com/yogeshojha/rengine/commit/8277cec0f008a0451371a92e7e0bf082ab3f0c34'}", "dataset": "nvd", "summary": "OS Command Injection in GitHub repository yogeshojha/rengine prior to 1.2.0.", "published_date": "2022-05-22", "chain_len": 1, "project": "https://github.com/yogeshojha/rengine", "commit_href": "https://github.com/yogeshojha/rengine/commit/8277cec0f008a0451371a92e7e0bf082ab3f0c34", "commit_sha": "8277cec0f008a0451371a92e7e0bf082ab3f0c34", "patch": "SINGLE", "chain_ord": "['8277cec0f008a0451371a92e7e0bf082ab3f0c34']", "before_first_fix_commit": "{'72a5fb2eb766c7b0334a3420af7576a60c95b182'}", "last_fix_commit": "8277cec0f008a0451371a92e7e0bf082ab3f0c34", "chain_ord_pos": 1, "commit_datetime": "05/22/2022, 15:41:29", "message": "Fix command injection issue on detect cms", "author": "Yogesh Ojha", "comments": null, "stats": "{'additions': 7, 'deletions': 2, 'total': 9}", "files": {"web/reNgine/common_func.py": {"additions": 7, "deletions": 2, "changes": 9, "status": "modified", "raw_url": "https://github.com/yogeshojha/rengine/raw/8277cec0f008a0451371a92e7e0bf082ab3f0c34/web%2FreNgine%2Fcommon_func.py", "patch": "@@ -6,6 +6,7 @@\n import tldextract\n import logging\n import shutil\n+import subprocess\n \n from threading import Thread\n \n@@ -668,8 +669,12 @@ def get_whois(ip_domain, save_db=False, fetch_from_db=True):\n def get_cms_details(url):\n     # this function will fetch cms details using cms_detector\n     response = {}\n-    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py -u {} --random-agent --batch --follow-redirect'.format(url)\n-    os.system(cms_detector_command)\n+    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py --random-agent --batch --follow-redirect'\n+    subprocess_splitted_command = cms_detector_command.split()\n+    subprocess_splitted_command.append('-u')\n+    subprocess_splitted_command.append(url)\n+    process = subprocess.Popen(subprocess_splitted_command)\n+    process.wait()\n \n     response['status'] = False\n     response['message'] = 'Could not detect CMS!'"}}, "prior_version": " import tldextract import logging import shutil  from threading import Thread  def get_whois(ip_domain, save_db=False, fetch_from_db=True): def get_cms_details(url):     # this function will fetch cms details using cms_detector     response = {}     cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py -u {} --random-agent --batch --follow-redirect'.format(url)     os.system(cms_detector_command)      response['status'] = False     response['message'] = 'Could not detect CMS!'", "after_version": " import tldextract import logging import shutil import subprocess  from threading import Thread  def get_whois(ip_domain, save_db=False, fetch_from_db=True): def get_cms_details(url):     # this function will fetch cms details using cms_detector     response = {}     cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py --random-agent --batch --follow-redirect'     subprocess_splitted_command = cms_detector_command.split()     subprocess_splitted_command.append('-u')     subprocess_splitted_command.append(url)     process = subprocess.Popen(subprocess_splitted_command)     process.wait()      response['status'] = False     response['message'] = 'Could not detect CMS!'", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2022-23609", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/bildsben/iTunesRPC-Remastered/commit/1eb1e5428f0926b2829a0bbbb65b0d946e608593'}", "dataset": "nvd", "summary": "iTunesRPC-Remastered is a Discord Rich Presence for iTunes on Windows utility. In affected versions iTunesRPC-Remastered did not properly sanitize user input used to remove files leading to file deletion only limited by the process permissions. Users are advised to upgrade as soon as possible.", "published_date": "2022-02-04", "chain_len": 1, "project": "https://github.com/bildsben/iTunesRPC-Remastered", "commit_href": "https://github.com/bildsben/iTunesRPC-Remastered/commit/1eb1e5428f0926b2829a0bbbb65b0d946e608593", "commit_sha": "1eb1e5428f0926b2829a0bbbb65b0d946e608593", "patch": "SINGLE", "chain_ord": "['1eb1e5428f0926b2829a0bbbb65b0d946e608593']", "before_first_fix_commit": "{'1bda8d191652c901613378e938775ca4717b9077'}", "last_fix_commit": "1eb1e5428f0926b2829a0bbbb65b0d946e608593", "chain_ord_pos": 1, "commit_datetime": "02/02/2022, 19:27:04", "message": "quick security fix", "author": "Ben", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"upload/server.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/bildsben/iTunesRPC-Remastered/raw/1eb1e5428f0926b2829a0bbbb65b0d946e608593/upload%2Fserver.py", "patch": "@@ -5,7 +5,7 @@\n import random\n from html import escape\n from os import remove\n-\n+import werkzeug.utils\n import magic\n from flask import Flask, abort, request\n from PIL import Image\n@@ -189,7 +189,7 @@ def uploadimage():\n     ):  # if it is not over the limit, it will skip. if it is, it does this.\n         # if we have gone over our cache limit, let's delete the first entry.\n         filename = all_files[0][1] + all_files[0][2]\n-        remove(filename)\n+        remove(werkzeug.utils.secure_filename(filename))\n         del all_files[0]\n         length = len(all_files)"}}, "prior_version": " import random from html import escape from os import remove  import magic from flask import Flask, abort, request from PIL import Image def uploadimage():     ):  # if it is not over the limit, it will skip. if it is, it does this.         # if we have gone over our cache limit, let's delete the first entry.         filename = all_files[0][1] + all_files[0][2]         remove(filename)         del all_files[0]         length = len(all_files) ", "after_version": " import random from html import escape from os import remove import werkzeug.utils import magic from flask import Flask, abort, request from PIL import Image def uploadimage():     ):  # if it is not over the limit, it will skip. if it is, it does this.         # if we have gone over our cache limit, let's delete the first entry.         filename = all_files[0][1] + all_files[0][2]         remove(werkzeug.utils.secure_filename(filename))         del all_files[0]         length = len(all_files) ", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2022-23611", "cwe_id": "{'CWE-78'}", "score": 6.4, "chain": "{'https://github.com/bildsben/iTunesRPC-Remastered/commit/cdcd48bbc44009ddcbd07a809b87376dc9ce37f4'}", "dataset": "nvd", "summary": "iTunesRPC-Remastered is a Discord Rich Presence for iTunes on Windows utility. In affected versions iTunesRPC-Remastered did not properly sanitize image file paths leading to OS level command injection. This issue has been patched in commit cdcd48b. Users are advised to upgrade.", "published_date": "2022-02-04", "chain_len": 1, "project": "https://github.com/bildsben/iTunesRPC-Remastered", "commit_href": "https://github.com/bildsben/iTunesRPC-Remastered/commit/cdcd48bbc44009ddcbd07a809b87376dc9ce37f4", "commit_sha": "cdcd48bbc44009ddcbd07a809b87376dc9ce37f4", "patch": "SINGLE", "chain_ord": "['cdcd48bbc44009ddcbd07a809b87376dc9ce37f4']", "before_first_fix_commit": "{'cbcea0a2c3e21f3a80675576792e783da59457cd'}", "last_fix_commit": "cdcd48bbc44009ddcbd07a809b87376dc9ce37f4", "chain_ord_pos": 1, "commit_datetime": "02/02/2022, 20:06:56", "message": "small fix", "author": "Ben", "comments": null, "stats": "{'additions': 3, 'deletions': 1, 'total': 4}", "files": {"module/connect_to_server.py": {"additions": 3, "deletions": 1, "changes": 4, "status": "modified", "raw_url": "https://github.com/bildsben/iTunesRPC-Remastered/raw/cdcd48bbc44009ddcbd07a809b87376dc9ce37f4/module%2Fconnect_to_server.py", "patch": "@@ -24,9 +24,11 @@ def get(image_file, domain, title, singer, album):\n     import json\n     import os\n     from html import unescape\n-\n+    import werkzeug.utils\n     import requests\n \n+    image_file = werkzeug.utils.secure_filename(ast.literal_eval(image_file))\n+\n     api = f\"http://{domain}:7873/bGVhdmVfcmlnaHRfbm93\"\n \n     with open(image_file, \"rb\") as f:"}}, "prior_version": " def get(image_file, domain, title, singer, album):     import json     import os     from html import unescape      import requests      api = f\"http://{domain}:7873/bGVhdmVfcmlnaHRfbm93\"      with open(image_file, \"rb\") as f:", "after_version": " def get(image_file, domain, title, singer, album):     import json     import os     from html import unescape     import werkzeug.utils     import requests      image_file = werkzeug.utils.secure_filename(ast.literal_eval(image_file))      api = f\"http://{domain}:7873/bGVhdmVfcmlnaHRfbm93\"      with open(image_file, \"rb\") as f:", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2022-31137", "cwe_id": "{'CWE-78'}", "score": 10.0, "chain": "{'https://github.com/hap-wi/roxy-wi/commit/82666df1e60c45dd6aa533b01a392f015d32f755'}", "dataset": "nvd", "summary": "Roxy-WI is a web interface for managing Haproxy, Nginx, Apache and Keepalived servers. Versions prior to 6.1.1.0 are subject to a remote code execution vulnerability. System commands can be run remotely via the subprocess_execute function without processing the inputs received from the user in the /app/options.py file. Attackers need not be authenticated to exploit this vulnerability. Users are advised to upgrade. There are no known workarounds for this vulnerability.", "published_date": "2022-07-08", "chain_len": 1, "project": "https://github.com/hap-wi/roxy-wi", "commit_href": "https://github.com/hap-wi/roxy-wi/commit/82666df1e60c45dd6aa533b01a392f015d32f755", "commit_sha": "82666df1e60c45dd6aa533b01a392f015d32f755", "patch": "SINGLE", "chain_ord": "['82666df1e60c45dd6aa533b01a392f015d32f755']", "before_first_fix_commit": "{'1fbcce83c0adae231f0652932757e0e3ecea033f'}", "last_fix_commit": "82666df1e60c45dd6aa533b01a392f015d32f755", "chain_ord_pos": 1, "commit_datetime": "07/08/2022, 17:43:13", "message": "v6.1.1.0\n\nChange log: https://roxy-wi.org/changelog.py#6_1_1", "author": "Pavel Loginov", "comments": null, "stats": "{'additions': 52, 'deletions': 188, 'total': 240}", "files": {"app/options.py": {"additions": 52, "deletions": 188, "changes": 240, "status": "modified", "raw_url": "https://github.com/hap-wi/roxy-wi/raw/82666df1e60c45dd6aa533b01a392f015d32f755/app%2Foptions.py", "patch": "@@ -61,10 +61,7 @@\n         print(e)\n \n if form.getvalue('getcert') is not None and serv is not None:\n-    cert_id = form.getvalue('getcert')\n-    if funct.checkAjaxInput(cert_id):\n-        print('error: Nice try')\n-        sys.exit()\n+    cert_id = funct.checkAjaxInput(form.getvalue('getcert'))\n \n     cert_path = sql.get_setting('cert_path')\n     commands = [\"openssl x509 -in \" + cert_path + \"/\" + cert_id + \" -text\"]\n@@ -74,10 +71,8 @@\n         print('error: Cannot connect to the server ' + e.args[0])\n \n if form.getvalue('delcert') is not None and serv is not None:\n-    if funct.checkAjaxInput(cert_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    cert_id = form.getvalue('delcert')\n+    cert_id = funct.checkAjaxInput(cert_id)\n     cert_path = sql.get_setting('cert_path')\n     commands = [\"sudo rm -f \" + cert_path + \"/\" + cert_id]\n     try:\n@@ -96,10 +91,7 @@\n     if form.getvalue('ssl_name') is None:\n         print('error: Please enter a desired name')\n     else:\n-        name = form.getvalue('ssl_name')\n-        if funct.checkAjaxInput(name):\n-            print('error: Nice try')\n-            sys.exit()\n+        name = funct.checkAjaxInput(form.getvalue('ssl_name'))\n \n     try:\n         with open(name, \"w\") as ssl_cert:\n@@ -132,10 +124,7 @@\n \n if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is None:\n     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))\n-    backend = form.getvalue('ipbackend')\n-    if funct.checkAjaxInput(backend):\n-        print('error: Nice try')\n-        sys.exit()\n+    backend = funct.checkAjaxInput(form.getvalue('ipbackend'))\n     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |awk \\'{print $4}\\'' % (serv, haproxy_sock_port, backend)\n     output, stderr = funct.subprocess_execute(cmd)\n     for i in output:\n@@ -146,23 +135,18 @@\n \n if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is not None:\n     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))\n-    backend = form.getvalue('ipbackend')\n-    backend_server = form.getvalue('backend_server')\n-    if funct.checkAjaxInput(backend) or funct.checkAjaxInput(backend_server):\n-        print('error: Nice try')\n-        sys.exit()\n+    backend = funct.checkAjaxInput(form.getvalue('ipbackend'))\n+    backend_server = funct.checkAjaxInput(form.getvalue('backend_server'))\n     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |grep \"%s\" |awk \\'{print $5\":\"$19}\\' |head -1' % (serv, haproxy_sock_port, backend, backend_server)\n     output, stderr = funct.subprocess_execute(cmd)\n     print(output[0])\n \n if form.getvalue('backend_ip') is not None:\n-    backend_backend = form.getvalue('backend_backend')\n-    backend_server = form.getvalue('backend_server')\n-    backend_ip = form.getvalue('backend_ip')\n-    backend_port = form.getvalue('backend_port')\n-    if any((funct.checkAjaxInput(backend_backend), funct.checkAjaxInput(backend_server), funct.checkAjaxInput(backend_ip), funct.checkAjaxInput(backend_port))):\n-        print('error: Nice try')\n-        sys.exit()\n+    backend_backend = funct.checkAjaxInput(form.getvalue('backend_backend'))\n+    backend_server = funct.checkAjaxInput(form.getvalue('backend_server'))\n+    backend_ip = funct.checkAjaxInput(form.getvalue('backend_ip'))\n+    backend_port = funct.checkAjaxInput(form.getvalue('backend_port'))\n+\n     if form.getvalue('backend_ip') is None:\n         print('error: Backend IP must be IP and not 0')\n         sys.exit()\n@@ -211,19 +195,13 @@\n         stderr = funct.master_slave_upload_and_restart(serv, cfg, just_save='save')\n \n if form.getvalue('maxconn_select') is not None:\n-    serv = form.getvalue('maxconn_select')\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n+    serv = funct.checkAjaxInput(form.getvalue('maxconn_select'))\n     funct.get_backends_from_config(serv, backends='frontend')\n \n if form.getvalue('maxconn_frontend') is not None:\n-    frontend = form.getvalue('maxconn_frontend')\n-    maxconn = form.getvalue('maxconn_int')\n+    frontend = funct.checkAjaxInput(form.getvalue('maxconn_frontend'))\n+    maxconn = funct.checkAjaxInput(form.getvalue('maxconn_int'))\n \n-    if funct.checkAjaxInput(frontend) or funct.checkAjaxInput(maxconn):\n-        print('error: Nice try')\n-        sys.exit()\n     if form.getvalue('maxconn_int') is None:\n         print('error: Maxconn must be integer and not 0')\n         sys.exit()\n@@ -297,12 +275,8 @@\n \n if form.getvalue('ip_for_delete') is not None:\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n-    ip = form.getvalue('ip_for_delete')\n-    table = form.getvalue('table_for_delete')\n-\n-    if funct.checkAjaxInput(ip) or funct.checkAjaxInput(table):\n-        print('error: Nice try')\n-        sys.exit()\n+    ip = funct.checkAjaxInput(form.getvalue('ip_for_delete'))\n+    table = funct.checkAjaxInput(form.getvalue('table_for_delete'))\n \n     cmd = 'echo \"clear table %s key %s\" |nc %s %s' % (table, ip, serv, haproxy_sock_port)\n     output, stderr = funct.subprocess_execute(cmd)\n@@ -311,11 +285,7 @@\n \n if form.getvalue('table_for_clear') is not None:\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n-    table = form.getvalue('table_for_clear')\n-\n-    if funct.checkAjaxInput(table):\n-        print('error: Nice try')\n-        sys.exit()\n+    table = funct.checkAjaxInput(form.getvalue('table_for_clear'))\n \n     cmd = 'echo \"clear table %s \" |nc %s %s' % (table, serv, haproxy_sock_port)\n     output, stderr = funct.subprocess_execute(cmd)\n@@ -334,12 +304,8 @@\n     env = Environment(loader=FileSystemLoader('templates/'), autoescape=True,\n                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)\n     template = env.get_template('ajax/list.html')\n-    list_id = form.getvalue('list_select_id')\n-    list_name = form.getvalue('list_select_name')\n-\n-    if funct.checkAjaxInput(list_id) or funct.checkAjaxInput(list_name):\n-        print('error: Nice try')\n-        sys.exit()\n+    list_id = funct.checkAjaxInput(form.getvalue('list_select_id'))\n+    list_name = funct.checkAjaxInput(form.getvalue('list_select_name'))\n \n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n     cmd = 'echo \"show acl #%s\"|nc %s %s' % (list_id, serv, haproxy_sock_port)\n@@ -351,17 +317,12 @@\n if form.getvalue('list_id_for_delete') is not None:\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n     lists_path = sql.get_setting('lists_path')\n-    lib_path = funct.get_config_var('main', 'lib_path')\n-    ip_id = form.getvalue('list_ip_id_for_delete')\n-    ip = form.getvalue('list_ip_for_delete')\n-    list_id = form.getvalue('list_id_for_delete')\n-    list_name = form.getvalue('list_name')\n-    user_group = funct.get_user_group(id=1)\n-\n-    if any((funct.checkAjaxInput(ip_id), funct.checkAjaxInput(ip), funct.checkAjaxInput(list_id), funct.checkAjaxInput(list_name))):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    lib_path = funct.checkAjaxInput(funct.get_config_var('main', 'lib_path'))\n+    ip_id = funct.checkAjaxInput(form.getvalue('list_ip_id_for_delete'))\n+    ip = funct.checkAjaxInput(form.getvalue('list_ip_for_delete'))\n+    list_id = funct.checkAjaxInput(form.getvalue('list_id_for_delete'))\n+    list_name = funct.checkAjaxInput(form.getvalue('list_name'))\n+    user_group = funct.checkAjaxInput(funct.get_user_group(id=1))\n     cmd = \"sed -i 's!%s$!!' %s/%s/%s/%s\" % (ip, lib_path, lists_path, user_group, list_name)\n     cmd1 = \"sed -i '/^$/d' %s/%s/%s/%s\" % (lib_path, lists_path, user_group, list_name)\n     output, stderr = funct.subprocess_execute(cmd)\n@@ -392,14 +353,9 @@\n     ip = form.getvalue('list_ip_for_add')\n     ip = ip.strip()\n     ip = funct.is_ip_or_dns(ip)\n-    list_id = form.getvalue('list_id_for_add')\n-    list_name = form.getvalue('list_name')\n-    user_group = funct.get_user_group(id=1)\n-\n-    if any((funct.checkAjaxInput(lists_path), funct.checkAjaxInput(list_id), funct.checkAjaxInput(list_name))):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    list_id = funct.checkAjaxInput(form.getvalue('list_id_for_add'))\n+    list_name = funct.checkAjaxInput(form.getvalue('list_name'))\n+    user_group = funct.checkAjaxInput(funct.get_user_group(id=1))\n     cmd = 'echo \"add acl #%s %s\" |nc %s %s' % (list_id, ip, serv, haproxy_sock_port)\n     output, stderr = funct.subprocess_execute(cmd)\n     if output[0]:\n@@ -423,15 +379,7 @@\n \n     env = Environment(loader=FileSystemLoader('templates'), autoescape=True,\n                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)\n-    serv = form.getvalue('sessions_select')\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n+    serv = funct.checkAjaxInput(form.getvalue('sessions_select'))\n \n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n \n@@ -444,16 +392,11 @@\n     print(template)\n \n if form.getvalue('sessions_select_show') is not None:\n-    serv = form.getvalue('sessions_select_show')\n-    sess_id = form.getvalue('sessions_select_id')\n-\n-    if funct.checkAjaxInput(serv) or funct.checkAjaxInput(sess_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    serv = funct.checkAjaxInput(form.getvalue('sessions_select_show'))\n+    sess_id = funct.checkAjaxInput(form.getvalue('sessions_select_id'))\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n-\n     cmd = 'echo \"show sess %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)\n+\n     output, stderr = funct.subprocess_execute(cmd)\n \n     if stderr:\n@@ -464,16 +407,7 @@\n \n if form.getvalue('session_delete_id') is not None:\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n-    sess_id = form.getvalue('session_delete_id')\n-\n-    if funct.checkAjaxInput(sess_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(sess_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    sess_id = funct.checkAjaxInput(form.getvalue('session_delete_id'))\n     cmd = 'echo \"shutdown session %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)\n     output, stderr = funct.subprocess_execute(cmd)\n     if output[0] != '':\n@@ -597,15 +531,7 @@\n     print(\"success: Apache has been %s\" % action)\n \n if form.getvalue('action_service') is not None:\n-    action = form.getvalue('action_service')\n-\n-    if funct.checkAjaxInput(action):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(action):\n-        print('error: Nice try')\n-        sys.exit()\n+    action = funct.checkAjaxInput(form.getvalue('action_service'))\n \n     if action not in ('start', 'stop', 'restart'):\n         print('error: wrong action')\n@@ -1233,12 +1159,8 @@ async def get_runner_overviewServers(**kwargs):\n if form.getvalue('servaction') is not None:\n     server_state_file = sql.get_setting('server_state_file')\n     haproxy_sock = sql.get_setting('haproxy_sock')\n-    enable = form.getvalue('servaction')\n-    backend = form.getvalue('servbackend')\n-\n-    if funct.checkAjaxInput(enable) or funct.checkAjaxInput(backend):\n-        print('error: Nice try')\n-        sys.exit()\n+    enable = funct.checkAjaxInput(form.getvalue('servaction'))\n+    backend = funct.checkAjaxInput(form.getvalue('servbackend'))\n \n     cmd = 'echo \"{} {}\" |sudo socat stdio {}'.format(enable, backend, haproxy_sock)\n \n@@ -1281,12 +1203,8 @@ async def get_runner_overviewServers(**kwargs):\n if serv is not None and form.getvalue('right') is not None:\n     from jinja2 import Environment, FileSystemLoader\n \n-    left = form.getvalue('left')\n-    right = form.getvalue('right')\n-\n-    if funct.checkAjaxInput(left) or funct.checkAjaxInput(right):\n-        print('error: Nice try')\n-        sys.exit()\n+    left = funct.checkAjaxInput(form.getvalue('left'))\n+    right = funct.checkAjaxInput(form.getvalue('right'))\n \n     if form.getvalue('service') == 'nginx':\n         configs_dir = funct.get_config_var('configs', 'nginx_save_configs_dir')\n@@ -2554,15 +2472,7 @@ async def get_runner_overviewServers(**kwargs):\n \n if form.getvalue('sshdel') is not None:\n     lib_path = funct.get_config_var('main', 'lib_path')\n-    sshdel = form.getvalue('sshdel')\n-\n-    if funct.checkAjaxInput(sshdel):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(sshdel):\n-        print('error: Nice try')\n-        sys.exit()\n+    sshdel = funct.checkAjaxInput(form.getvalue('sshdel'))\n \n     for sshs in sql.select_ssh(id=sshdel):\n         ssh_enable = sshs.enable\n@@ -2612,11 +2522,7 @@ async def get_runner_overviewServers(**kwargs):\n     import paramiko\n \n     user_group = funct.get_user_group()\n-    name = form.getvalue('name')\n-\n-    if funct.checkAjaxInput(name):\n-        print('error: Nice try')\n-        sys.exit()\n+    name = funct.checkAjaxInput(form.getvalue('name'))\n \n     try:\n         key = paramiko.pkey.load_private_key(form.getvalue('ssh_cert'))\n@@ -2913,11 +2819,7 @@ async def get_runner_overviewServers(**kwargs):\n         funct.logging('SMON', ' Has been update the server ' + ip + ' to SMON ', haproxywi=1, login=1)\n \n if form.getvalue('showBytes') is not None:\n-    serv = form.getvalue('showBytes')\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n+    serv = funct.checkAjaxInput(form.getvalue('showBytes'))\n \n     port = sql.get_setting('haproxy_sock_port')\n     bin_bout = []\n@@ -2970,12 +2872,8 @@ async def get_runner_overviewServers(**kwargs):\n         print('error: cannot connect to Nginx stat page')\n \n if form.getvalue('waf_rule_id'):\n-    enable = form.getvalue('waf_en')\n-    rule_id = form.getvalue('waf_rule_id')\n-\n-    if funct.checkAjaxInput(enable) or funct.checkAjaxInput(rule_id):\n-        print('error: Nice try')\n-        sys.exit()\n+    enable = funct.checkAjaxInput(form.getvalue('waf_en'))\n+    rule_id = funct.checkAjaxInput(form.getvalue('waf_rule_id'))\n \n     haproxy_path = sql.get_setting('haproxy_dir')\n     rule_file = sql.select_waf_rule_by_id(rule_id)\n@@ -3051,15 +2949,7 @@ async def get_runner_overviewServers(**kwargs):\n     os.system(\"rm -f %s\" % script)\n \n if form.getvalue('uploadovpn'):\n-    name = form.getvalue('ovpnname')\n-\n-    if funct.checkAjaxInput(name):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(name):\n-        print('error: Nice try')\n-        sys.exit()\n+    name = funct.checkAjaxInput(form.getvalue('ovpnname'))\n \n     ovpn_file = os.path.dirname('/tmp/') + \"/\" + name + '.ovpn'\n \n@@ -3087,11 +2977,7 @@ async def get_runner_overviewServers(**kwargs):\n     funct.logging(\"localhost\", \" has been uploaded a new ovpn file %s\" % ovpn_file, haproxywi=1, login=1)\n \n if form.getvalue('openvpndel') is not None:\n-    openvpndel = form.getvalue('openvpndel')\n-\n-    if funct.checkAjaxInput(openvpndel):\n-        print('error: Nice try')\n-        sys.exit()\n+    openvpndel = funct.checkAjaxInput(form.getvalue('openvpndel'))\n \n     cmd = 'sudo openvpn3 config-remove --config /tmp/%s.ovpn --force' % openvpndel\n     try:\n@@ -3103,12 +2989,8 @@ async def get_runner_overviewServers(**kwargs):\n         funct.logging('localhost', e.args[0], haproxywi=1)\n \n if form.getvalue('actionvpn') is not None:\n-    openvpn = form.getvalue('openvpnprofile')\n-    action = form.getvalue('actionvpn')\n-\n-    if funct.checkAjaxInput(openvpn) or funct.checkAjaxInput(action):\n-        print('error: Nice try')\n-        sys.exit()\n+    openvpn = funct.checkAjaxInput(form.getvalue('openvpnprofile'))\n+    action = funct.checkAjaxInput(form.getvalue('actionvpn'))\n \n     if action == 'start':\n         cmd = 'sudo openvpn3 session-start --config /tmp/%s.ovpn' % openvpn\n@@ -3125,12 +3007,7 @@ async def get_runner_overviewServers(**kwargs):\n         funct.logging('localhost', e.args[0], haproxywi=1)\n \n if form.getvalue('scan_ports') is not None:\n-    serv_id = form.getvalue('scan_ports')\n-\n-    if funct.checkAjaxInput(serv_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    serv_id = funct.checkAjaxInput(form.getvalue('scan_ports'))\n     server = sql.select_servers(id=serv_id)\n     ip = ''\n \n@@ -3154,11 +3031,7 @@ async def get_runner_overviewServers(**kwargs):\n         print(template)\n \n if form.getvalue('viewFirewallRules') is not None:\n-    serv = form.getvalue('viewFirewallRules')\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n+    serv = funct.checkAjaxInput(form.getvalue('viewFirewallRules'))\n \n     cmd = [\"sudo iptables -L INPUT -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"]\n     cmd1 = [\"sudo iptables -L IN_public_allow -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"]\n@@ -3186,11 +3059,6 @@ async def get_runner_overviewServers(**kwargs):\n \n if form.getvalue('geoipserv') is not None:\n     serv = form.getvalue('geoipserv')\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n-\n     haproxy_dir = sql.get_setting('haproxy_dir')\n \n     cmd = [\"ls \" + haproxy_dir + \"/geoip/\"]\n@@ -4531,12 +4399,8 @@ async def get_runner_overviewServers(**kwargs):\n     user_uuid = cookie.get('uuid')\n     user_id = sql.get_user_id_by_uuid(user_uuid.value)\n     user_services = sql.select_user_services(user_id)\n-    server_id = form.getvalue('server_id')\n-    service = form.getvalue('service')\n-\n-    if funct.checkAjaxInput(server_id) or funct.checkAjaxInput(service):\n-        print('error: Nice try')\n-        sys.exit()\n+    server_id = funct.checkAjaxInput(form.getvalue('server_id'))\n+    service = funct.checkAjaxInput(form.getvalue('service'))\n \n     if '1' in user_services:\n         if service == 'haproxy':"}}, "prior_version": "         print(e)  if form.getvalue('getcert') is not None and serv is not None:     cert_id = form.getvalue('getcert')     if funct.checkAjaxInput(cert_id):         print('error: Nice try')         sys.exit()      cert_path = sql.get_setting('cert_path')     commands = [\"openssl x509 -in \" + cert_path + \"/\" + cert_id + \" -text\"]         print('error: Cannot connect to the server ' + e.args[0])  if form.getvalue('delcert') is not None and serv is not None:     if funct.checkAjaxInput(cert_id):         print('error: Nice try')         sys.exit()      cert_path = sql.get_setting('cert_path')     commands = [\"sudo rm -f \" + cert_path + \"/\" + cert_id]     try:     if form.getvalue('ssl_name') is None:         print('error: Please enter a desired name')     else:         name = form.getvalue('ssl_name')         if funct.checkAjaxInput(name):             print('error: Nice try')             sys.exit()      try:         with open(name, \"w\") as ssl_cert:  if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is None:     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))     backend = form.getvalue('ipbackend')     if funct.checkAjaxInput(backend):         print('error: Nice try')         sys.exit()     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |awk \\'{print $4}\\'' % (serv, haproxy_sock_port, backend)     output, stderr = funct.subprocess_execute(cmd)     for i in output:  if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is not None:     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))     backend = form.getvalue('ipbackend')     backend_server = form.getvalue('backend_server')     if funct.checkAjaxInput(backend) or funct.checkAjaxInput(backend_server):         print('error: Nice try')         sys.exit()     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |grep \"%s\" |awk \\'{print $5\":\"$19}\\' |head -1' % (serv, haproxy_sock_port, backend, backend_server)     output, stderr = funct.subprocess_execute(cmd)     print(output[0])  if form.getvalue('backend_ip') is not None:     backend_backend = form.getvalue('backend_backend')     backend_server = form.getvalue('backend_server')     backend_ip = form.getvalue('backend_ip')     backend_port = form.getvalue('backend_port')     if any((funct.checkAjaxInput(backend_backend), funct.checkAjaxInput(backend_server), funct.checkAjaxInput(backend_ip), funct.checkAjaxInput(backend_port))):         print('error: Nice try')         sys.exit()     if form.getvalue('backend_ip') is None:         print('error: Backend IP must be IP and not 0')         sys.exit()         stderr = funct.master_slave_upload_and_restart(serv, cfg, just_save='save')  if form.getvalue('maxconn_select') is not None:     serv = form.getvalue('maxconn_select')     if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()     funct.get_backends_from_config(serv, backends='frontend')  if form.getvalue('maxconn_frontend') is not None:     frontend = form.getvalue('maxconn_frontend')     maxconn = form.getvalue('maxconn_int')      if funct.checkAjaxInput(frontend) or funct.checkAjaxInput(maxconn):         print('error: Nice try')         sys.exit()     if form.getvalue('maxconn_int') is None:         print('error: Maxconn must be integer and not 0')         sys.exit()  if form.getvalue('ip_for_delete') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     ip = form.getvalue('ip_for_delete')     table = form.getvalue('table_for_delete')      if funct.checkAjaxInput(ip) or funct.checkAjaxInput(table):         print('error: Nice try')         sys.exit()      cmd = 'echo \"clear table %s key %s\" |nc %s %s' % (table, ip, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)  if form.getvalue('table_for_clear') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     table = form.getvalue('table_for_clear')      if funct.checkAjaxInput(table):         print('error: Nice try')         sys.exit()      cmd = 'echo \"clear table %s \" |nc %s %s' % (table, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     env = Environment(loader=FileSystemLoader('templates/'), autoescape=True,                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)     template = env.get_template('ajax/list.html')     list_id = form.getvalue('list_select_id')     list_name = form.getvalue('list_select_name')      if funct.checkAjaxInput(list_id) or funct.checkAjaxInput(list_name):         print('error: Nice try')         sys.exit()      haproxy_sock_port = sql.get_setting('haproxy_sock_port')     cmd = 'echo \"show acl #%s\"|nc %s %s' % (list_id, serv, haproxy_sock_port) if form.getvalue('list_id_for_delete') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     lists_path = sql.get_setting('lists_path')     lib_path = funct.get_config_var('main', 'lib_path')     ip_id = form.getvalue('list_ip_id_for_delete')     ip = form.getvalue('list_ip_for_delete')     list_id = form.getvalue('list_id_for_delete')     list_name = form.getvalue('list_name')     user_group = funct.get_user_group(id=1)      if any((funct.checkAjaxInput(ip_id), funct.checkAjaxInput(ip), funct.checkAjaxInput(list_id), funct.checkAjaxInput(list_name))):         print('error: Nice try')         sys.exit()      cmd = \"sed -i 's!%s$!!' %s/%s/%s/%s\" % (ip, lib_path, lists_path, user_group, list_name)     cmd1 = \"sed -i '/^$/d' %s/%s/%s/%s\" % (lib_path, lists_path, user_group, list_name)     output, stderr = funct.subprocess_execute(cmd)     ip = form.getvalue('list_ip_for_add')     ip = ip.strip()     ip = funct.is_ip_or_dns(ip)     list_id = form.getvalue('list_id_for_add')     list_name = form.getvalue('list_name')     user_group = funct.get_user_group(id=1)      if any((funct.checkAjaxInput(lists_path), funct.checkAjaxInput(list_id), funct.checkAjaxInput(list_name))):         print('error: Nice try')         sys.exit()      cmd = 'echo \"add acl #%s %s\" |nc %s %s' % (list_id, ip, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     if output[0]:      env = Environment(loader=FileSystemLoader('templates'), autoescape=True,                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)     serv = form.getvalue('sessions_select')      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      haproxy_sock_port = sql.get_setting('haproxy_sock_port')      print(template)  if form.getvalue('sessions_select_show') is not None:     serv = form.getvalue('sessions_select_show')     sess_id = form.getvalue('sessions_select_id')      if funct.checkAjaxInput(serv) or funct.checkAjaxInput(sess_id):         print('error: Nice try')         sys.exit()      haproxy_sock_port = sql.get_setting('haproxy_sock_port')      cmd = 'echo \"show sess %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)      if stderr:  if form.getvalue('session_delete_id') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     sess_id = form.getvalue('session_delete_id')      if funct.checkAjaxInput(sess_id):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(sess_id):         print('error: Nice try')         sys.exit()      cmd = 'echo \"shutdown session %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     if output[0] != '':     print(\"success: Apache has been %s\" % action)  if form.getvalue('action_service') is not None:     action = form.getvalue('action_service')      if funct.checkAjaxInput(action):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(action):         print('error: Nice try')         sys.exit()      if action not in ('start', 'stop', 'restart'):         print('error: wrong action') async def get_runner_overviewServers(**kwargs): if form.getvalue('servaction') is not None:     server_state_file = sql.get_setting('server_state_file')     haproxy_sock = sql.get_setting('haproxy_sock')     enable = form.getvalue('servaction')     backend = form.getvalue('servbackend')      if funct.checkAjaxInput(enable) or funct.checkAjaxInput(backend):         print('error: Nice try')         sys.exit()      cmd = 'echo \"{} {}\" |sudo socat stdio {}'.format(enable, backend, haproxy_sock)  async def get_runner_overviewServers(**kwargs): if serv is not None and form.getvalue('right') is not None:     from jinja2 import Environment, FileSystemLoader      left = form.getvalue('left')     right = form.getvalue('right')      if funct.checkAjaxInput(left) or funct.checkAjaxInput(right):         print('error: Nice try')         sys.exit()      if form.getvalue('service') == 'nginx':         configs_dir = funct.get_config_var('configs', 'nginx_save_configs_dir') async def get_runner_overviewServers(**kwargs):  if form.getvalue('sshdel') is not None:     lib_path = funct.get_config_var('main', 'lib_path')     sshdel = form.getvalue('sshdel')      if funct.checkAjaxInput(sshdel):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(sshdel):         print('error: Nice try')         sys.exit()      for sshs in sql.select_ssh(id=sshdel):         ssh_enable = sshs.enable async def get_runner_overviewServers(**kwargs):     import paramiko      user_group = funct.get_user_group()     name = form.getvalue('name')      if funct.checkAjaxInput(name):         print('error: Nice try')         sys.exit()      try:         key = paramiko.pkey.load_private_key(form.getvalue('ssh_cert')) async def get_runner_overviewServers(**kwargs):         funct.logging('SMON', ' Has been update the server ' + ip + ' to SMON ', haproxywi=1, login=1)  if form.getvalue('showBytes') is not None:     serv = form.getvalue('showBytes')      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      port = sql.get_setting('haproxy_sock_port')     bin_bout = [] async def get_runner_overviewServers(**kwargs):         print('error: cannot connect to Nginx stat page')  if form.getvalue('waf_rule_id'):     enable = form.getvalue('waf_en')     rule_id = form.getvalue('waf_rule_id')      if funct.checkAjaxInput(enable) or funct.checkAjaxInput(rule_id):         print('error: Nice try')         sys.exit()      haproxy_path = sql.get_setting('haproxy_dir')     rule_file = sql.select_waf_rule_by_id(rule_id) async def get_runner_overviewServers(**kwargs):     os.system(\"rm -f %s\" % script)  if form.getvalue('uploadovpn'):     name = form.getvalue('ovpnname')      if funct.checkAjaxInput(name):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(name):         print('error: Nice try')         sys.exit()      ovpn_file = os.path.dirname('/tmp/') + \"/\" + name + '.ovpn'  async def get_runner_overviewServers(**kwargs):     funct.logging(\"localhost\", \" has been uploaded a new ovpn file %s\" % ovpn_file, haproxywi=1, login=1)  if form.getvalue('openvpndel') is not None:     openvpndel = form.getvalue('openvpndel')      if funct.checkAjaxInput(openvpndel):         print('error: Nice try')         sys.exit()      cmd = 'sudo openvpn3 config-remove --config /tmp/%s.ovpn --force' % openvpndel     try: async def get_runner_overviewServers(**kwargs):         funct.logging('localhost', e.args[0], haproxywi=1)  if form.getvalue('actionvpn') is not None:     openvpn = form.getvalue('openvpnprofile')     action = form.getvalue('actionvpn')      if funct.checkAjaxInput(openvpn) or funct.checkAjaxInput(action):         print('error: Nice try')         sys.exit()      if action == 'start':         cmd = 'sudo openvpn3 session-start --config /tmp/%s.ovpn' % openvpn async def get_runner_overviewServers(**kwargs):         funct.logging('localhost', e.args[0], haproxywi=1)  if form.getvalue('scan_ports') is not None:     serv_id = form.getvalue('scan_ports')      if funct.checkAjaxInput(serv_id):         print('error: Nice try')         sys.exit()      server = sql.select_servers(id=serv_id)     ip = ''  async def get_runner_overviewServers(**kwargs):         print(template)  if form.getvalue('viewFirewallRules') is not None:     serv = form.getvalue('viewFirewallRules')      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      cmd = [\"sudo iptables -L INPUT -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"]     cmd1 = [\"sudo iptables -L IN_public_allow -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"] async def get_runner_overviewServers(**kwargs):  if form.getvalue('geoipserv') is not None:     serv = form.getvalue('geoipserv')      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      haproxy_dir = sql.get_setting('haproxy_dir')      cmd = [\"ls \" + haproxy_dir + \"/geoip/\"] async def get_runner_overviewServers(**kwargs):     user_uuid = cookie.get('uuid')     user_id = sql.get_user_id_by_uuid(user_uuid.value)     user_services = sql.select_user_services(user_id)     server_id = form.getvalue('server_id')     service = form.getvalue('service')      if funct.checkAjaxInput(server_id) or funct.checkAjaxInput(service):         print('error: Nice try')         sys.exit()      if '1' in user_services:         if service == 'haproxy':", "after_version": "         print(e)  if form.getvalue('getcert') is not None and serv is not None:     cert_id = funct.checkAjaxInput(form.getvalue('getcert'))      cert_path = sql.get_setting('cert_path')     commands = [\"openssl x509 -in \" + cert_path + \"/\" + cert_id + \" -text\"]         print('error: Cannot connect to the server ' + e.args[0])  if form.getvalue('delcert') is not None and serv is not None:     cert_id = form.getvalue('delcert')     cert_id = funct.checkAjaxInput(cert_id)     cert_path = sql.get_setting('cert_path')     commands = [\"sudo rm -f \" + cert_path + \"/\" + cert_id]     try:     if form.getvalue('ssl_name') is None:         print('error: Please enter a desired name')     else:         name = funct.checkAjaxInput(form.getvalue('ssl_name'))      try:         with open(name, \"w\") as ssl_cert:  if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is None:     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))     backend = funct.checkAjaxInput(form.getvalue('ipbackend'))     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |awk \\'{print $4}\\'' % (serv, haproxy_sock_port, backend)     output, stderr = funct.subprocess_execute(cmd)     for i in output:  if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is not None:     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))     backend = funct.checkAjaxInput(form.getvalue('ipbackend'))     backend_server = funct.checkAjaxInput(form.getvalue('backend_server'))     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |grep \"%s\" |awk \\'{print $5\":\"$19}\\' |head -1' % (serv, haproxy_sock_port, backend, backend_server)     output, stderr = funct.subprocess_execute(cmd)     print(output[0])  if form.getvalue('backend_ip') is not None:     backend_backend = funct.checkAjaxInput(form.getvalue('backend_backend'))     backend_server = funct.checkAjaxInput(form.getvalue('backend_server'))     backend_ip = funct.checkAjaxInput(form.getvalue('backend_ip'))     backend_port = funct.checkAjaxInput(form.getvalue('backend_port'))      if form.getvalue('backend_ip') is None:         print('error: Backend IP must be IP and not 0')         sys.exit()         stderr = funct.master_slave_upload_and_restart(serv, cfg, just_save='save')  if form.getvalue('maxconn_select') is not None:     serv = funct.checkAjaxInput(form.getvalue('maxconn_select'))     funct.get_backends_from_config(serv, backends='frontend')  if form.getvalue('maxconn_frontend') is not None:     frontend = funct.checkAjaxInput(form.getvalue('maxconn_frontend'))     maxconn = funct.checkAjaxInput(form.getvalue('maxconn_int'))      if form.getvalue('maxconn_int') is None:         print('error: Maxconn must be integer and not 0')         sys.exit()  if form.getvalue('ip_for_delete') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     ip = funct.checkAjaxInput(form.getvalue('ip_for_delete'))     table = funct.checkAjaxInput(form.getvalue('table_for_delete'))      cmd = 'echo \"clear table %s key %s\" |nc %s %s' % (table, ip, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)  if form.getvalue('table_for_clear') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     table = funct.checkAjaxInput(form.getvalue('table_for_clear'))      cmd = 'echo \"clear table %s \" |nc %s %s' % (table, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     env = Environment(loader=FileSystemLoader('templates/'), autoescape=True,                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)     template = env.get_template('ajax/list.html')     list_id = funct.checkAjaxInput(form.getvalue('list_select_id'))     list_name = funct.checkAjaxInput(form.getvalue('list_select_name'))      haproxy_sock_port = sql.get_setting('haproxy_sock_port')     cmd = 'echo \"show acl #%s\"|nc %s %s' % (list_id, serv, haproxy_sock_port) if form.getvalue('list_id_for_delete') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     lists_path = sql.get_setting('lists_path')     lib_path = funct.checkAjaxInput(funct.get_config_var('main', 'lib_path'))     ip_id = funct.checkAjaxInput(form.getvalue('list_ip_id_for_delete'))     ip = funct.checkAjaxInput(form.getvalue('list_ip_for_delete'))     list_id = funct.checkAjaxInput(form.getvalue('list_id_for_delete'))     list_name = funct.checkAjaxInput(form.getvalue('list_name'))     user_group = funct.checkAjaxInput(funct.get_user_group(id=1))     cmd = \"sed -i 's!%s$!!' %s/%s/%s/%s\" % (ip, lib_path, lists_path, user_group, list_name)     cmd1 = \"sed -i '/^$/d' %s/%s/%s/%s\" % (lib_path, lists_path, user_group, list_name)     output, stderr = funct.subprocess_execute(cmd)     ip = form.getvalue('list_ip_for_add')     ip = ip.strip()     ip = funct.is_ip_or_dns(ip)     list_id = funct.checkAjaxInput(form.getvalue('list_id_for_add'))     list_name = funct.checkAjaxInput(form.getvalue('list_name'))     user_group = funct.checkAjaxInput(funct.get_user_group(id=1))     cmd = 'echo \"add acl #%s %s\" |nc %s %s' % (list_id, ip, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     if output[0]:      env = Environment(loader=FileSystemLoader('templates'), autoescape=True,                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)     serv = funct.checkAjaxInput(form.getvalue('sessions_select'))      haproxy_sock_port = sql.get_setting('haproxy_sock_port')      print(template)  if form.getvalue('sessions_select_show') is not None:     serv = funct.checkAjaxInput(form.getvalue('sessions_select_show'))     sess_id = funct.checkAjaxInput(form.getvalue('sessions_select_id'))     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     cmd = 'echo \"show sess %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)      output, stderr = funct.subprocess_execute(cmd)      if stderr:  if form.getvalue('session_delete_id') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     sess_id = funct.checkAjaxInput(form.getvalue('session_delete_id'))     cmd = 'echo \"shutdown session %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     if output[0] != '':     print(\"success: Apache has been %s\" % action)  if form.getvalue('action_service') is not None:     action = funct.checkAjaxInput(form.getvalue('action_service'))      if action not in ('start', 'stop', 'restart'):         print('error: wrong action') async def get_runner_overviewServers(**kwargs): if form.getvalue('servaction') is not None:     server_state_file = sql.get_setting('server_state_file')     haproxy_sock = sql.get_setting('haproxy_sock')     enable = funct.checkAjaxInput(form.getvalue('servaction'))     backend = funct.checkAjaxInput(form.getvalue('servbackend'))      cmd = 'echo \"{} {}\" |sudo socat stdio {}'.format(enable, backend, haproxy_sock)  async def get_runner_overviewServers(**kwargs): if serv is not None and form.getvalue('right') is not None:     from jinja2 import Environment, FileSystemLoader      left = funct.checkAjaxInput(form.getvalue('left'))     right = funct.checkAjaxInput(form.getvalue('right'))      if form.getvalue('service') == 'nginx':         configs_dir = funct.get_config_var('configs', 'nginx_save_configs_dir') async def get_runner_overviewServers(**kwargs):  if form.getvalue('sshdel') is not None:     lib_path = funct.get_config_var('main', 'lib_path')     sshdel = funct.checkAjaxInput(form.getvalue('sshdel'))      for sshs in sql.select_ssh(id=sshdel):         ssh_enable = sshs.enable async def get_runner_overviewServers(**kwargs):     import paramiko      user_group = funct.get_user_group()     name = funct.checkAjaxInput(form.getvalue('name'))      try:         key = paramiko.pkey.load_private_key(form.getvalue('ssh_cert')) async def get_runner_overviewServers(**kwargs):         funct.logging('SMON', ' Has been update the server ' + ip + ' to SMON ', haproxywi=1, login=1)  if form.getvalue('showBytes') is not None:     serv = funct.checkAjaxInput(form.getvalue('showBytes'))      port = sql.get_setting('haproxy_sock_port')     bin_bout = [] async def get_runner_overviewServers(**kwargs):         print('error: cannot connect to Nginx stat page')  if form.getvalue('waf_rule_id'):     enable = funct.checkAjaxInput(form.getvalue('waf_en'))     rule_id = funct.checkAjaxInput(form.getvalue('waf_rule_id'))      haproxy_path = sql.get_setting('haproxy_dir')     rule_file = sql.select_waf_rule_by_id(rule_id) async def get_runner_overviewServers(**kwargs):     os.system(\"rm -f %s\" % script)  if form.getvalue('uploadovpn'):     name = funct.checkAjaxInput(form.getvalue('ovpnname'))      ovpn_file = os.path.dirname('/tmp/') + \"/\" + name + '.ovpn'  async def get_runner_overviewServers(**kwargs):     funct.logging(\"localhost\", \" has been uploaded a new ovpn file %s\" % ovpn_file, haproxywi=1, login=1)  if form.getvalue('openvpndel') is not None:     openvpndel = funct.checkAjaxInput(form.getvalue('openvpndel'))      cmd = 'sudo openvpn3 config-remove --config /tmp/%s.ovpn --force' % openvpndel     try: async def get_runner_overviewServers(**kwargs):         funct.logging('localhost', e.args[0], haproxywi=1)  if form.getvalue('actionvpn') is not None:     openvpn = funct.checkAjaxInput(form.getvalue('openvpnprofile'))     action = funct.checkAjaxInput(form.getvalue('actionvpn'))      if action == 'start':         cmd = 'sudo openvpn3 session-start --config /tmp/%s.ovpn' % openvpn async def get_runner_overviewServers(**kwargs):         funct.logging('localhost', e.args[0], haproxywi=1)  if form.getvalue('scan_ports') is not None:     serv_id = funct.checkAjaxInput(form.getvalue('scan_ports'))     server = sql.select_servers(id=serv_id)     ip = ''  async def get_runner_overviewServers(**kwargs):         print(template)  if form.getvalue('viewFirewallRules') is not None:     serv = funct.checkAjaxInput(form.getvalue('viewFirewallRules'))      cmd = [\"sudo iptables -L INPUT -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"]     cmd1 = [\"sudo iptables -L IN_public_allow -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"] async def get_runner_overviewServers(**kwargs):  if form.getvalue('geoipserv') is not None:     serv = form.getvalue('geoipserv')     haproxy_dir = sql.get_setting('haproxy_dir')      cmd = [\"ls \" + haproxy_dir + \"/geoip/\"] async def get_runner_overviewServers(**kwargs):     user_uuid = cookie.get('uuid')     user_id = sql.get_user_id_by_uuid(user_uuid.value)     user_services = sql.select_user_services(user_id)     server_id = funct.checkAjaxInput(form.getvalue('server_id'))     service = funct.checkAjaxInput(form.getvalue('service'))      if '1' in user_services:         if service == 'haproxy':", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2022-31501", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/ChaoticOnyx/OnyxForum/commit/f25543dfc62a9694d7e4f67eebfa45e3de916053'}", "dataset": "nvd", "summary": "The ChaoticOnyx/OnyxForum repository before 2022-05-04 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-11", "chain_len": 1, "project": "https://github.com/ChaoticOnyx/OnyxForum", "commit_href": "https://github.com/ChaoticOnyx/OnyxForum/commit/f25543dfc62a9694d7e4f67eebfa45e3de916053", "commit_sha": "f25543dfc62a9694d7e4f67eebfa45e3de916053", "patch": "SINGLE", "chain_ord": "['f25543dfc62a9694d7e4f67eebfa45e3de916053']", "before_first_fix_commit": "{'4077b499a1ca213f3eb55b8321a4733d83531750'}", "last_fix_commit": "f25543dfc62a9694d7e4f67eebfa45e3de916053", "chain_ord_pos": 1, "commit_datetime": "05/04/2022, 21:40:28", "message": "fix(hub): absolute Path Traversal due to incorrect use of `send_file` call\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\r\n\r\n## Root Cause Analysis\r\n\r\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\r\n```\r\n>>> import os.path\r\n>>> static = \"path/to/mySafeStaticDir\"\r\n>>> malicious = \"/../../../../../etc/passwd\"\r\n>>> os.path.join(t,malicious)\r\n'/../../../../../etc/passwd'\r\n```\r\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\r\n\r\nIn this case, the problems occurs due to the following code :\r\nhttps://github.com/ChaoticOnyx/OnyxForum/blob/4077b499a1ca213f3eb55b8321a4733d83531750/modules/hub/hub/views.py#L493\r\n\r\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\r\n\r\n## Remediation\r\n\r\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `flask.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\r\n\r\n## References\r\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\r\n* github/securitylab#669\r\n\r\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*\r\n\r\nCo-authored-by: Porcupiney Hairs <porucpiney.hairs@protonmail.com>\r\nPR #63", "author": "porcupineyhairs", "comments": null, "stats": "{'additions': 3, 'deletions': 1, 'total': 4}", "files": {"modules/hub/hub/views.py": {"additions": 3, "deletions": 1, "changes": 4, "status": "modified", "raw_url": "https://github.com/ChaoticOnyx/OnyxForum/raw/f25543dfc62a9694d7e4f67eebfa45e3de916053/modules%2Fhub%2Fhub%2Fviews.py", "patch": "@@ -19,6 +19,8 @@\n from flaskbb.extensions import allows, db, celery\n from flaskbb.user.models import User, Group\n from flaskbb.forum.models import Post\n+from werkzeug.utils import safe_join \n+\n \n from hub.forms import ConfigEditForm, BanSearchForm, ConnectionSearchForm\n from hub.permissions import CanAccessServerHub, CanAccessServerHubAdditional, CanAccessServerHubManagement\n@@ -489,7 +491,7 @@ def get(self):\n         if server is None:\n             abort(404)\n \n-        file_path = os.path.join(server.logs_path, path)\n+        file_path = safe_join(server.logs_path, path)\n         return send_file(file_path, as_attachment=True)"}}, "prior_version": " from flaskbb.extensions import allows, db, celery from flaskbb.user.models import User, Group from flaskbb.forum.models import Post  from hub.forms import ConfigEditForm, BanSearchForm, ConnectionSearchForm from hub.permissions import CanAccessServerHub, CanAccessServerHubAdditional, CanAccessServerHubManagement def get(self):         if server is None:             abort(404)          file_path = os.path.join(server.logs_path, path)         return send_file(file_path, as_attachment=True)  ", "after_version": " from flaskbb.extensions import allows, db, celery from flaskbb.user.models import User, Group from flaskbb.forum.models import Post from werkzeug.utils import safe_join    from hub.forms import ConfigEditForm, BanSearchForm, ConnectionSearchForm from hub.permissions import CanAccessServerHub, CanAccessServerHubAdditional, CanAccessServerHubManagement def get(self):         if server is None:             abort(404)          file_path = safe_join(server.logs_path, path)         return send_file(file_path, as_attachment=True)  ", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2022-31502", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/operatorequals/wormnest/commit/2dfe96fc2570586ac487b399ac20d41b3c114861'}", "dataset": "nvd", "summary": "The operatorequals/wormnest repository through 0.4.7 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-11", "chain_len": 1, "project": "https://github.com/operatorequals/wormnest", "commit_href": "https://github.com/operatorequals/wormnest/commit/2dfe96fc2570586ac487b399ac20d41b3c114861", "commit_sha": "2dfe96fc2570586ac487b399ac20d41b3c114861", "patch": "SINGLE", "chain_ord": "['2dfe96fc2570586ac487b399ac20d41b3c114861']", "before_first_fix_commit": "{'30ab2ba563a19040b07b7b8b06e97ad95c0b5793', 'dd981626b574a89939babd1246588580ecc323f9'}", "last_fix_commit": "2dfe96fc2570586ac487b399ac20d41b3c114861", "chain_ord_pos": 1, "commit_datetime": "04/29/2022, 08:37:58", "message": "Merge pull request #8 from porcupineyhairs/FixPathInjection\n\nFix Path Traversal Vulnerability", "author": "John Torakis", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"app.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/operatorequals/wormnest/raw/2dfe96fc2570586ac487b399ac20d41b3c114861/app.py", "patch": "@@ -1,6 +1,6 @@\n #!/bin/env python\n from flask import Flask\n-from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort\n+from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort, safe_join\n \n from werkzeug.utils import secure_filename\n from ipaddress import ip_address, ip_network\n@@ -116,7 +116,7 @@ def dir_listing(req_path):\n https://stackoverflow.com/questions/23718236/python-flask-browsing-through-directory-with-files\n   '''\n   # Joining the base and the requested path\n-  abs_path = os.path.join(CONFIG['SRV_DIR'], req_path)\n+  abs_path = safe_join(CONFIG['SRV_DIR'], req_path)\n \n   # Return 404 if path doesn't exist\n   if not os.path.exists(abs_path):"}}, "prior_version": " #!/bin/env python from flask import Flask from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort  from werkzeug.utils import secure_filename from ipaddress import ip_address, ip_network def dir_listing(req_path): https://stackoverflow.com/questions/23718236/python-flask-browsing-through-directory-with-files   '''   # Joining the base and the requested path   abs_path = os.path.join(CONFIG['SRV_DIR'], req_path)    # Return 404 if path doesn't exist   if not os.path.exists(abs_path):", "after_version": " #!/bin/env python from flask import Flask from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort, safe_join  from werkzeug.utils import secure_filename from ipaddress import ip_address, ip_network def dir_listing(req_path): https://stackoverflow.com/questions/23718236/python-flask-browsing-through-directory-with-files   '''   # Joining the base and the requested path   abs_path = safe_join(CONFIG['SRV_DIR'], req_path)    # Return 404 if path doesn't exist   if not os.path.exists(abs_path):", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2022-31508", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/idayrus/evoting/commit/241d92a4d68f524365a6322b5bbcfaa7d9abc8a3'}", "dataset": "nvd", "summary": "The idayrus/evoting repository before 2022-05-08 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-11", "chain_len": 1, "project": "https://github.com/idayrus/evoting", "commit_href": "https://github.com/idayrus/evoting/commit/241d92a4d68f524365a6322b5bbcfaa7d9abc8a3", "commit_sha": "241d92a4d68f524365a6322b5bbcfaa7d9abc8a3", "patch": "SINGLE", "chain_ord": "['241d92a4d68f524365a6322b5bbcfaa7d9abc8a3']", "before_first_fix_commit": "{'d9ef8c7c0343c7986fe06ff976395775d5844732', 'fefef0d06816ac2d80ed3c80df20fa5deca43a48'}", "last_fix_commit": "241d92a4d68f524365a6322b5bbcfaa7d9abc8a3", "chain_ord_pos": 1, "commit_datetime": "05/08/2022, 18:26:01", "message": "Merge pull request #2 from porcupineyhairs/FixPathInjection\n\nFix Path Traversal Vulnerability", "author": "adierebel", "comments": null, "stats": "{'additions': 2, 'deletions': 1, 'total': 3}", "files": {"app/helper/middleware.py": {"additions": 2, "deletions": 1, "changes": 3, "status": "modified", "raw_url": "https://github.com/idayrus/evoting/raw/241d92a4d68f524365a6322b5bbcfaa7d9abc8a3/app%2Fhelper%2Fmiddleware.py", "patch": "@@ -5,6 +5,7 @@\n from app.module.user.model import UserModel, UserTokenModel\n from app.module.user import UserSession\n from werkzeug.routing import BaseConverter, ValidationError\n+from werkzeug.utils import safe_join\n from bson.objectid import ObjectId\n from bson.errors import InvalidId\n from os import path\n@@ -18,7 +19,7 @@\n @login_required\n def private_static(filename):\n     # Get path\n-    filepath = path.join(app.config.get(\"PRIVATE_DIR\"), filename)\n+    filepath = safe_join(app.config.get(\"PRIVATE_DIR\"), filename)\n     if path.isfile(filepath):\n         return send_file(filepath)\n     # End"}}, "prior_version": " from app.module.user.model import UserModel, UserTokenModel from app.module.user import UserSession from werkzeug.routing import BaseConverter, ValidationError from bson.objectid import ObjectId from bson.errors import InvalidId from os import path @login_required def private_static(filename):     # Get path     filepath = path.join(app.config.get(\"PRIVATE_DIR\"), filename)     if path.isfile(filepath):         return send_file(filepath)     # End", "after_version": " from app.module.user.model import UserModel, UserTokenModel from app.module.user import UserSession from werkzeug.routing import BaseConverter, ValidationError from werkzeug.utils import safe_join from bson.objectid import ObjectId from bson.errors import InvalidId from os import path @login_required def private_static(filename):     # Get path     filepath = safe_join(app.config.get(\"PRIVATE_DIR\"), filename)     if path.isfile(filepath):         return send_file(filepath)     # End", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2022-31564", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/woduq1414/munhak-moa/commit/e8f800373b20cb22de70c7a994325b8903877da0'}", "dataset": "nvd", "summary": "The woduq1414/munhak-moa repository before 2022-05-03 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-11", "chain_len": 1, "project": "https://github.com/woduq1414/munhak-moa", "commit_href": "https://github.com/woduq1414/munhak-moa/commit/e8f800373b20cb22de70c7a994325b8903877da0", "commit_sha": "e8f800373b20cb22de70c7a994325b8903877da0", "patch": "SINGLE", "chain_ord": "['e8f800373b20cb22de70c7a994325b8903877da0']", "before_first_fix_commit": "{'cdcc98959879c2e88a89eea164e806b3b0e09972'}", "last_fix_commit": "e8f800373b20cb22de70c7a994325b8903877da0", "chain_ord_pos": 1, "commit_datetime": "05/03/2022, 11:23:52", "message": "# Absolute Path Traversal due to incorrect use of `send_file` call\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\n\n## Common Weakness Enumeration category\nCWE - 36\n\n## Root Cause Analysis\n\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\n```\n>>> import os.path\n>>> static = \"path/to/mySafeStaticDir\"\n>>> malicious = \"/../../../../../etc/passwd\"\n>>> os.path.join(t,malicious)\n'/../../../../../etc/passwd'\n```\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\n\nIn this case, the problems occurs due to the following code :\nhttps://github.com/woduq1414/munhak-moa/blob/cdcc98959879c2e88a89eea164e806b3b0e09972/app.py#L273\n\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\n\n## Proof of Concept\n\nThe bug can be verified using a proof of concept similar to the one shown below.\n\n```\ncurl --path-as-is 'http://<domain>/images//../../../../etc/passwd\"'\n```\n## Remediation\n\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\n\n## Common Vulnerability Scoring System Vector\n\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\n\n(AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L)[https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L&version=3.1]\n\nThis gives it a base score of 9.3/10 and a severity rating of critical.\n\n## References\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\n* github/securitylab#669\n\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*", "author": "Porcupiney Hairs", "comments": null, "stats": "{'additions': 2, 'deletions': 1, 'total': 3}", "files": {"app.py": {"additions": 2, "deletions": 1, "changes": 3, "status": "modified", "raw_url": "https://github.com/woduq1414/munhak-moa/raw/e8f800373b20cb22de70c7a994325b8903877da0/app.py", "patch": "@@ -1,6 +1,7 @@\n import configparser\n \n from flask import Flask, render_template, session, request, flash, redirect, url_for, Response, abort, jsonify, send_file\n+from werkzeug.utils import safe_join\n import socket\n import os\n import random\n@@ -267,7 +268,7 @@ def get_absolute_path(path):\n         import os\n         script_dir = os.path.dirname(__file__)  # <-- absolute dir the script is in\n         rel_path = path\n-        abs_file_path = os.path.join(script_dir, rel_path)\n+        abs_file_path = safe_join(script_dir, rel_path)\n         return abs_file_path\n \n     return send_file("}}, "prior_version": " import configparser  from flask import Flask, render_template, session, request, flash, redirect, url_for, Response, abort, jsonify, send_file import socket import os import random def get_absolute_path(path):         import os         script_dir = os.path.dirname(__file__)  # <-- absolute dir the script is in         rel_path = path         abs_file_path = os.path.join(script_dir, rel_path)         return abs_file_path      return send_file(", "after_version": " import configparser  from flask import Flask, render_template, session, request, flash, redirect, url_for, Response, abort, jsonify, send_file from werkzeug.utils import safe_join import socket import os import random def get_absolute_path(path):         import os         script_dir = os.path.dirname(__file__)  # <-- absolute dir the script is in         rel_path = path         abs_file_path = safe_join(script_dir, rel_path)         return abs_file_path      return send_file(", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-2v5j-q74q-r53f", "cwe_id": "{'CWE-79'}", "score": 8.8, "chain": "{'https://github.com/django-helpdesk/django-helpdesk/commit/a22eb0673fe0b7784f99c6b5fd343b64a6700f06'}", "dataset": "osv", "summary": "django-helpdesk is vulnerable to Cross-site Scripting django-helpdesk is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting').", "published_date": "2021-12-03", "chain_len": 1, "project": "https://github.com/django-helpdesk/django-helpdesk", "commit_href": "https://github.com/django-helpdesk/django-helpdesk/commit/a22eb0673fe0b7784f99c6b5fd343b64a6700f06", "commit_sha": "a22eb0673fe0b7784f99c6b5fd343b64a6700f06", "patch": "SINGLE", "chain_ord": "['a22eb0673fe0b7784f99c6b5fd343b64a6700f06']", "before_first_fix_commit": "{'7097c9c4c0b255ec1f10f3ea14fa2b9c47f6c706'}", "last_fix_commit": "a22eb0673fe0b7784f99c6b5fd343b64a6700f06", "chain_ord_pos": 1, "commit_datetime": "11/19/2021, 16:11:33", "message": "Update pattern", "author": "noobpk", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"helpdesk/models.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/django-helpdesk/django-helpdesk/raw/a22eb0673fe0b7784f99c6b5fd343b64a6700f06/helpdesk%2Fmodels.py", "patch": "@@ -56,7 +56,7 @@ def get_markdown(text):\n     if not text:\n         return \"\"\n \n-    pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\[\\s\\S\\]]*?)\\)'\n+    pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\s\\S]*?)\\)'\n     # Regex check\n     if re.match(pattern, text):\n         # get get value of group regex"}}, "prior_version": " def get_markdown(text):     if not text:         return \"\"      pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\[\\s\\S\\]]*?)\\)'     # Regex check     if re.match(pattern, text):         # get get value of group regex", "after_version": " def get_markdown(text):     if not text:         return \"\"      pattern = fr'([\\[\\s\\S\\]]*?)\\(([\\s\\S]*?):([\\s\\S]*?)\\)'     # Regex check     if re.match(pattern, text):         # get get value of group regex", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "GHSA-3q6g-vf58-7m4g", "cwe_id": "{'CWE-400'}", "score": 7.5, "chain": "{'https://github.com/python-restx/flask-restx/commit/bab31e085f355dd73858fd3715f7ed71849656da'}", "dataset": "osv", "summary": "Regular Expression Denial of Service in flask-restx Flask RESTX contains a regular expression that is vulnerable to [ReDoS](https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS) (Regular Expression Denial of Service) in `email_regex`.", "published_date": "2021-09-08", "chain_len": 1, "project": "https://github.com/python-restx/flask-restx", "commit_href": "https://github.com/python-restx/flask-restx/commit/bab31e085f355dd73858fd3715f7ed71849656da", "commit_sha": "bab31e085f355dd73858fd3715f7ed71849656da", "patch": "SINGLE", "chain_ord": "['bab31e085f355dd73858fd3715f7ed71849656da']", "before_first_fix_commit": "{'e1ab7e34a47fa8c2fd025402b9c65afbe24d5e98'}", "last_fix_commit": "bab31e085f355dd73858fd3715f7ed71849656da", "chain_ord_pos": 1, "commit_datetime": "09/01/2021, 19:53:02", "message": "optimize email regex (credits: @kevinbackhouse, fix: #372)", "author": "ziirish", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"flask_restx/inputs.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/python-restx/flask-restx/raw/bab31e085f355dd73858fd3715f7ed71849656da/flask_restx%2Finputs.py", "patch": "@@ -48,7 +48,7 @@ def my_type(value):\n \n \n email_regex = re.compile(\n-    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@]+(?:\\.[^@]+)*)\" r\"$\",\n+    r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@\\.]+(?:\\.[^@\\.]+)*)\" r\"$\",\n     re.IGNORECASE,\n )"}}, "prior_version": " def my_type(value):   email_regex = re.compile(     r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@]+(?:\\.[^@]+)*)\" r\"$\",     re.IGNORECASE, ) ", "after_version": " def my_type(value):   email_regex = re.compile(     r\"^\" \"(?P<local>[^@]*[^@.])\" r\"@\" r\"(?P<server>[^@\\.]+(?:\\.[^@\\.]+)*)\" r\"$\",     re.IGNORECASE, ) ", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-49qr-xh3w-h436", "cwe_id": "{'CWE-79'}", "score": 6.1, "chain": "{'https://github.com/jupyter/notebook/commit/107a89fce5f413fb5728c1c5d2c7788e1fb17491'}", "dataset": "osv", "summary": "Moderate severity vulnerability that affects notebook Jupyter Notebook before 5.7.1 allows XSS via an untrusted notebook because nbconvert responses are considered to have the same origin as the notebook server. In other words, nbconvert endpoints can execute JavaScript with access to the server API. In notebook/nbconvert/handlers.py, NbconvertFileHandler and NbconvertPostHandler do not set a Content Security Policy to prevent this.", "published_date": "2018-11-21", "chain_len": 1, "project": "https://github.com/jupyter/notebook", "commit_href": "https://github.com/jupyter/notebook/commit/107a89fce5f413fb5728c1c5d2c7788e1fb17491", "commit_sha": "107a89fce5f413fb5728c1c5d2c7788e1fb17491", "patch": "SINGLE", "chain_ord": "['107a89fce5f413fb5728c1c5d2c7788e1fb17491']", "before_first_fix_commit": "{'04a686dbaf9dfe553324a03cb9e6f778cf1e3da1'}", "last_fix_commit": "107a89fce5f413fb5728c1c5d2c7788e1fb17491", "chain_ord_pos": 1, "commit_datetime": "10/22/2018, 13:52:36", "message": "Apply CSP sandboxing for nbconvert responses\n\nThese may contain untrusted content, so they should be treated as being\nfrom a different domain to the notebook server.", "author": "Thomas Kluyver", "comments": null, "stats": "{'additions': 14, 'deletions': 0, 'total': 14}", "files": {"notebook/nbconvert/handlers.py": {"additions": 14, "deletions": 0, "changes": 14, "status": "modified", "raw_url": "https://github.com/jupyter/notebook/raw/107a89fce5f413fb5728c1c5d2c7788e1fb17491/notebook%2Fnbconvert%2Fhandlers.py", "patch": "@@ -78,6 +78,13 @@ class NbconvertFileHandler(IPythonHandler):\n \n     SUPPORTED_METHODS = ('GET',)\n \n+    @property\n+    def content_security_policy(self):\n+        # In case we're serving HTML/SVG, confine any Javascript to a unique\n+        # origin so it can't interact with the notebook server.\n+        return super(NbconvertFileHandler, self).content_security_policy + \\\n+               \"; sandbox allow-scripts\"\n+\n     @web.authenticated\n     def get(self, format, path):\n \n@@ -145,6 +152,13 @@ def get(self, format, path):\n class NbconvertPostHandler(IPythonHandler):\n     SUPPORTED_METHODS = ('POST',)\n \n+    @property\n+    def content_security_policy(self):\n+        # In case we're serving HTML/SVG, confine any Javascript to a unique\n+        # origin so it can't interact with the notebook server.\n+        return super(NbconvertPostHandler, self).content_security_policy + \\\n+               \"; sandbox allow-scripts\"\n+\n     @web.authenticated\n     def post(self, format):\n         exporter = get_exporter(format, config=self.config)"}}, "prior_version": " class NbconvertFileHandler(IPythonHandler):      SUPPORTED_METHODS = ('GET',)      @web.authenticated     def get(self, format, path):  def get(self, format, path): class NbconvertPostHandler(IPythonHandler):     SUPPORTED_METHODS = ('POST',)      @web.authenticated     def post(self, format):         exporter = get_exporter(format, config=self.config)", "after_version": " class NbconvertFileHandler(IPythonHandler):      SUPPORTED_METHODS = ('GET',)      @property     def content_security_policy(self):         # In case we're serving HTML/SVG, confine any Javascript to a unique         # origin so it can't interact with the notebook server.         return super(NbconvertFileHandler, self).content_security_policy + \\                \"; sandbox allow-scripts\"      @web.authenticated     def get(self, format, path):  def get(self, format, path): class NbconvertPostHandler(IPythonHandler):     SUPPORTED_METHODS = ('POST',)      @property     def content_security_policy(self):         # In case we're serving HTML/SVG, confine any Javascript to a unique         # origin so it can't interact with the notebook server.         return super(NbconvertPostHandler, self).content_security_policy + \\                \"; sandbox allow-scripts\"      @web.authenticated     def post(self, format):         exporter = get_exporter(format, config=self.config)", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "GHSA-52q8-877j-gghq", "cwe_id": "{'CWE-22'}", "score": 0.0, "chain": "{'https://github.com/moinwiki/moin-1.9/commit/6b96a9060069302996b5af47fd4a388fc80172b7'}", "dataset": "osv", "summary": "remote code execution via cache action in MoinMoin ### Impact\nThe cache action in action/cache.py allows directory traversal through a crafted HTTP request. An attacker who can upload attachments to\nthe wiki can use this to achieve remote code execution.\n\n### Patches\nUsers are strongly advised to upgrade to a patched version.\n\nMoinMoin Wiki 1.9.11 has the necessary fixes and also contains other important fixes.\n\n### Workarounds\nIt is not advised to work around this, but to upgrade MoinMoin to a patched version.\n\nThat said, a work around via disabling the `cache` or the `AttachFile` action might be possible.\n\nAlso, it is of course helpful if you give `write` permissions (which include uploading attachments) only to trusted users.\n\n### Credits\n\nThis vulnerability was discovered by Michael Chapman.\n\n### For more information\nIf you have any questions or comments about this advisory, email me at [twaldmann@thinkmo.de](mailto:twaldmann@thinkmo.de).", "published_date": "2020-11-11", "chain_len": 1, "project": "https://github.com/moinwiki/moin-1.9", "commit_href": "https://github.com/moinwiki/moin-1.9/commit/6b96a9060069302996b5af47fd4a388fc80172b7", "commit_sha": "6b96a9060069302996b5af47fd4a388fc80172b7", "patch": "SINGLE", "chain_ord": "['6b96a9060069302996b5af47fd4a388fc80172b7']", "before_first_fix_commit": "{'d1e5fc7d3708d877353ca64dd4aa7cfd1cde4cb4', '31de9139d0aabc171e94032168399b4a0b2a88a2'}", "last_fix_commit": "6b96a9060069302996b5af47fd4a388fc80172b7", "chain_ord_pos": 1, "commit_datetime": "11/08/2020, 16:21:56", "message": "Merge pull request from GHSA-52q8-877j-gghq\n\nsecurity: fix remote code execution via cache action, CVE-2020-25074", "author": "TW", "comments": null, "stats": "{'additions': 20, 'deletions': 7, 'total': 27}", "files": {"MoinMoin/action/cache.py": {"additions": 20, "deletions": 7, "changes": 27, "status": "modified", "raw_url": "https://github.com/moinwiki/moin-1.9/raw/6b96a9060069302996b5af47fd4a388fc80172b7/MoinMoin%2Faction%2Fcache.py", "patch": "@@ -103,6 +103,19 @@ def key(request, wikiname=None, itemname=None, attachname=None, content=None, se\n     return key\n \n \n+def valid_key(key):\n+    # make sure the key looks like keys generated by key()\n+    if not isinstance(key, unicode):\n+        # key is None (not given in url args) or something unexpected\n+        return False\n+    try:\n+        int(key, 16)  # try to evaluate as hex number\n+    except ValueError:\n+        # was not a hex number\n+        return False\n+    return len(key) == 40  # hmac-sha1 hexdigest == 40 hex chars\n+\n+\n def put(request, key, data,\n         filename=None,\n         content_type=None,\n@@ -234,14 +247,14 @@ def _do_remove(request, key):\n     remove(request, key)\n \n \n-def _do(request, do, key):\n-    if do == 'get':\n-        _do_get(request, key)\n-    elif do == 'remove':\n-        _do_remove(request, key)\n-\n def execute(pagename, request):\n     do = request.values.get('do')\n     key = request.values.get('key')\n-    _do(request, do, key)\n+    valid = valid_key(key)  # validate untrusted input\n+    if valid and do == 'get':\n+        _do_get(request, key)\n+    elif valid and do == 'remove':\n+        _do_remove(request, key)\n+    else:\n+        request.status_code = 404"}}, "prior_version": " def key(request, wikiname=None, itemname=None, attachname=None, content=None, se     return key   def put(request, key, data,         filename=None,         content_type=None, def _do_remove(request, key):     remove(request, key)   def _do(request, do, key):     if do == 'get':         _do_get(request, key)     elif do == 'remove':         _do_remove(request, key)  def execute(pagename, request):     do = request.values.get('do')     key = request.values.get('key')     _do(request, do, key) ", "after_version": " def key(request, wikiname=None, itemname=None, attachname=None, content=None, se     return key   def valid_key(key):     # make sure the key looks like keys generated by key()     if not isinstance(key, unicode):         # key is None (not given in url args) or something unexpected         return False     try:         int(key, 16)  # try to evaluate as hex number     except ValueError:         # was not a hex number         return False     return len(key) == 40  # hmac-sha1 hexdigest == 40 hex chars   def put(request, key, data,         filename=None,         content_type=None, def _do_remove(request, key):     remove(request, key)   def execute(pagename, request):     do = request.values.get('do')     key = request.values.get('key')     valid = valid_key(key)  # validate untrusted input     if valid and do == 'get':         _do_get(request, key)     elif valid and do == 'remove':         _do_remove(request, key)     else:         request.status_code = 404 ", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-7257-96vg-qf6x", "cwe_id": "{'CWE-74', 'CWE-94'}", "score": 8.5, "chain": "{'https://github.com/Cog-Creators/Red-DiscordBot/pull/4183/commits/e269ea0d3bc88417163c18431b1df38a9be92bfc'}", "dataset": "osv", "summary": "Remote Code Execution in Red Discord Bot ### Impact\nA RCE exploit has been discovered in the Streams module: this exploit allows Discord users with specifically crafted \"going live\" messages to inject code into the Streams module's going live message. By abusing this exploit, it's possible to perform destructive actions and/or access sensitive information.\n\n### Patches\nThis critical exploit has been fixed on version ``3.3.12`` & ``3.4``.\n\n### Workarounds\nUnloading the Streams module with ``unload streams`` can render this exploit not accessible. We still highly recommend updating to ``3.3.12`` or ``3.4`` to completely patch this issue.\n\n### References\n* https://github.com/Cog-Creators/Red-DiscordBot/pull/4183\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [Cog-Creators/Red-DiscordBot](https://github.com/Cog-Creators/Red-DiscordBot)\n* Over on our [Discord server](https://discord.gg/red)", "published_date": "2020-08-21", "chain_len": 1, "project": "https://github.com/Cog-Creators/Red-DiscordBot", "commit_href": "https://github.com/Cog-Creators/Red-DiscordBot/pull/4183/commits/e269ea0d3bc88417163c18431b1df38a9be92bfc", "commit_sha": "e269ea0d3bc88417163c18431b1df38a9be92bfc", "patch": "SINGLE", "chain_ord": "['e269ea0d3bc88417163c18431b1df38a9be92bfc']", "before_first_fix_commit": "{'9798538438ceb37c0592aa358f6f0c5784878d71'}", "last_fix_commit": "e269ea0d3bc88417163c18431b1df38a9be92bfc", "chain_ord_pos": 1, "commit_datetime": "08/11/2020, 22:40:06", "message": "Added consume all to streams.", "author": "Kowlin", "comments": null, "stats": "{'additions': 13, 'deletions': 9, 'total': 22}", "files": {"redbot/cogs/streams/streams.py": {"additions": 13, "deletions": 9, "changes": 22, "status": "modified", "raw_url": "https://github.com/Cog-Creators/Red-DiscordBot/raw/e269ea0d3bc88417163c18431b1df38a9be92bfc/redbot%2Fcogs%2Fstreams%2Fstreams.py", "patch": "@@ -497,14 +497,13 @@ async def message(self, ctx: commands.Context):\n \n     @message.command(name=\"mention\")\n     @commands.guild_only()\n-    async def with_mention(self, ctx: commands.Context, message: str = None):\n+    async def with_mention(self, ctx: commands.Context, *, message: str = None):\n         \"\"\"Set stream alert message when mentions are enabled.\n \n         Use `{mention}` in the message to insert the selected mentions.\n+        Use `{stream}` in the message to insert the channel or user name.\n \n-        Use `{stream.name}` in the message to insert the channel or user name.\n-\n-        For example: `[p]streamset message mention \"{mention}, {stream.name} is live!\"`\n+        For example: `[p]streamset message mention \"{mention}, {stream} is live!\"`\n         \"\"\"\n         if message is not None:\n             guild = ctx.guild\n@@ -515,12 +514,12 @@ async def with_mention(self, ctx: commands.Context, message: str = None):\n \n     @message.command(name=\"nomention\")\n     @commands.guild_only()\n-    async def without_mention(self, ctx: commands.Context, message: str = None):\n+    async def without_mention(self, ctx: commands.Context, *, message: str = None):\n         \"\"\"Set stream alert message when mentions are disabled.\n \n-        Use `{stream.name}` in the message to insert the channel or user name.\n+        Use `{stream}` in the message to insert the channel or user name.\n \n-        For example: `[p]streamset message nomention \"{stream.name} is live!\"`\n+        For example: `[p]streamset message nomention \"{stream} is live!\"`\n         \"\"\"\n         if message is not None:\n             guild = ctx.guild\n@@ -720,7 +719,10 @@ async def check_streams(self):\n                                 channel.guild\n                             ).live_message_mention()\n                             if alert_msg:\n-                                content = alert_msg.format(mention=mention_str, stream=stream)\n+                                content = alert_msg  # Stop bad things from happening here...\n+                                content = content.replace(\"{stream.name}\", str(stream.name))  # Backwards compatability\n+                                content = content.replace(\"{stream}\", str(stream.name))\n+                                content = content.replace(\"{mention}\", mention_str)\n                             else:\n                                 content = _(\"{mention}, {stream} is live!\").format(\n                                     mention=mention_str,\n@@ -733,7 +735,9 @@ async def check_streams(self):\n                                 channel.guild\n                             ).live_message_nomention()\n                             if alert_msg:\n-                                content = alert_msg.format(stream=stream)\n+                                content = alert_msg  # Stop bad things from happening here...\n+                                content = content.replace(\"{stream.name}\", str(stream.name))  # Backwards compatability\n+                                content = content.replace(\"{stream}\", str(stream.name))\n                             else:\n                                 content = _(\"{stream} is live!\").format(\n                                     stream=escape("}}, "prior_version": " async def message(self, ctx: commands.Context):      @message.command(name=\"mention\")     @commands.guild_only()     async def with_mention(self, ctx: commands.Context, message: str = None):         \"\"\"Set stream alert message when mentions are enabled.          Use `{mention}` in the message to insert the selected mentions.          Use `{stream.name}` in the message to insert the channel or user name.          For example: `[p]streamset message mention \"{mention}, {stream.name} is live!\"`         \"\"\"         if message is not None:             guild = ctx.guild async def with_mention(self, ctx: commands.Context, message: str = None):      @message.command(name=\"nomention\")     @commands.guild_only()     async def without_mention(self, ctx: commands.Context, message: str = None):         \"\"\"Set stream alert message when mentions are disabled.          Use `{stream.name}` in the message to insert the channel or user name.          For example: `[p]streamset message nomention \"{stream.name} is live!\"`         \"\"\"         if message is not None:             guild = ctx.guild async def check_streams(self):                                 channel.guild                             ).live_message_mention()                             if alert_msg:                                 content = alert_msg.format(mention=mention_str, stream=stream)                             else:                                 content = _(\"{mention}, {stream} is live!\").format(                                     mention=mention_str, async def check_streams(self):                                 channel.guild                             ).live_message_nomention()                             if alert_msg:                                 content = alert_msg.format(stream=stream)                             else:                                 content = _(\"{stream} is live!\").format(                                     stream=escape(", "after_version": " async def message(self, ctx: commands.Context):      @message.command(name=\"mention\")     @commands.guild_only()     async def with_mention(self, ctx: commands.Context, *, message: str = None):         \"\"\"Set stream alert message when mentions are enabled.          Use `{mention}` in the message to insert the selected mentions.         Use `{stream}` in the message to insert the channel or user name.          For example: `[p]streamset message mention \"{mention}, {stream} is live!\"`         \"\"\"         if message is not None:             guild = ctx.guild async def with_mention(self, ctx: commands.Context, message: str = None):      @message.command(name=\"nomention\")     @commands.guild_only()     async def without_mention(self, ctx: commands.Context, *, message: str = None):         \"\"\"Set stream alert message when mentions are disabled.          Use `{stream}` in the message to insert the channel or user name.          For example: `[p]streamset message nomention \"{stream} is live!\"`         \"\"\"         if message is not None:             guild = ctx.guild async def check_streams(self):                                 channel.guild                             ).live_message_mention()                             if alert_msg:                                 content = alert_msg  # Stop bad things from happening here...                                 content = content.replace(\"{stream.name}\", str(stream.name))  # Backwards compatability                                 content = content.replace(\"{stream}\", str(stream.name))                                 content = content.replace(\"{mention}\", mention_str)                             else:                                 content = _(\"{mention}, {stream} is live!\").format(                                     mention=mention_str, async def check_streams(self):                                 channel.guild                             ).live_message_nomention()                             if alert_msg:                                 content = alert_msg  # Stop bad things from happening here...                                 content = content.replace(\"{stream.name}\", str(stream.name))  # Backwards compatability                                 content = content.replace(\"{stream}\", str(stream.name))                             else:                                 content = _(\"{stream} is live!\").format(                                     stream=escape(", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "GHSA-7488-6x3r-23w5", "cwe_id": "{'CWE-22'}", "score": 9.3, "chain": "{'https://github.com/ganga-devs/ganga/commit/730e7aba192407d35eb37dd7938d49071124be8c'}", "dataset": "osv", "summary": "ganga before 8.5.10 allows absolute path traversal because the Flask send_file function is used unsafely The ganga-devs/ganga repository before 8.5.10 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-13", "chain_len": 1, "project": "https://github.com/ganga-devs/ganga", "commit_href": "https://github.com/ganga-devs/ganga/commit/730e7aba192407d35eb37dd7938d49071124be8c", "commit_sha": "730e7aba192407d35eb37dd7938d49071124be8c", "patch": "SINGLE", "chain_ord": "['730e7aba192407d35eb37dd7938d49071124be8c']", "before_first_fix_commit": "{'0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc'}", "last_fix_commit": "730e7aba192407d35eb37dd7938d49071124be8c", "chain_ord_pos": 1, "commit_datetime": "05/09/2022, 23:19:28", "message": "# Absolute Path Traversal due to incorrect use of `send_file` call (#2025)\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\r\n\r\n## Common Weakness Enumeration category\r\nCWE - 36\r\n\r\n## Root Cause Analysis\r\n\r\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\r\n```\r\n>>> import os.path\r\n>>> static = \"path/to/mySafeStaticDir\"\r\n>>> malicious = \"/../../../../../etc/passwd\"\r\n>>> os.path.join(t,malicious)\r\n'/../../../../../etc/passwd'\r\n```\r\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\r\n\r\nIn this case, the problems occurs due to the following code :\r\nhttps://github.com/ganga-devs/ganga/blob/0c0f9e33b36ee7ead0855f1464f8d4efad26bdbc/ganga/GangaGUI/gui/routes.py#L671\r\n\r\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\r\n\r\n## Proof of Concept\r\n\r\nThe bug can be verified using a proof of concept similar to the one shown below.\r\n\r\n```\r\ncurl --path-as-is 'http://<domain>/job/<int:job_id>/browse///../../../../etc/passwd\"'\r\n```\r\n## Remediation\r\n\r\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\r\n\r\n## Common Vulnerability Scoring System Vector\r\n\r\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\r\n\r\n(AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L)[https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L&version=3.1]\r\n\r\nThis gives it a base score of 9.3/10 and a severity rating of critical.\r\n\r\n## References\r\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\r\n* github/securitylab#669\r\n\r\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*\r\n\r\nCo-authored-by: Porcupiney Hairs <porucpiney.hairs@protonmail.com>", "author": "porcupineyhairs", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"ganga/GangaGUI/gui/routes.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/ganga-devs/ganga/raw/730e7aba192407d35eb37dd7938d49071124be8c/ganga%2FGangaGUI%2Fgui%2Froutes.py", "patch": "@@ -12,7 +12,7 @@\n import sys\n import datetime\n from functools import wraps\n-from werkzeug.utils import secure_filename\n+from werkzeug.utils import secure_filename, safe_join\n from werkzeug.security import generate_password_hash, check_password_hash\n from flask import Flask, request, jsonify, render_template, flash, redirect, url_for, session, send_file, make_response\n from flask_login import login_user, login_required, logout_user, current_user, UserMixin\n@@ -656,7 +656,7 @@ def job_browse(job_id: int, path):\n         return redirect(url_for(\"job_page\", job_id=job_id))\n \n     # Join the base and the requested path\n-    abs_path = os.path.join(job_base_dir, path)\n+    abs_path = safe_join(job_base_dir, path)\n \n     # URL path variable for going back\n     back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")"}}, "prior_version": " import sys import datetime from functools import wraps from werkzeug.utils import secure_filename from werkzeug.security import generate_password_hash, check_password_hash from flask import Flask, request, jsonify, render_template, flash, redirect, url_for, session, send_file, make_response from flask_login import login_user, login_required, logout_user, current_user, UserMixin def job_browse(job_id: int, path):         return redirect(url_for(\"job_page\", job_id=job_id))      # Join the base and the requested path     abs_path = os.path.join(job_base_dir, path)      # URL path variable for going back     back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")", "after_version": " import sys import datetime from functools import wraps from werkzeug.utils import secure_filename, safe_join from werkzeug.security import generate_password_hash, check_password_hash from flask import Flask, request, jsonify, render_template, flash, redirect, url_for, session, send_file, make_response from flask_login import login_user, login_required, logout_user, current_user, UserMixin def job_browse(job_id: int, path):         return redirect(url_for(\"job_page\", job_id=job_id))      # Join the base and the requested path     abs_path = safe_join(job_base_dir, path)      # URL path variable for going back     back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-8434-v7xw-8m9x", "cwe_id": "{'CWE-88', 'CWE-78'}", "score": 9.3, "chain": "{'https://github.com/dwisiswant0/apkleaks/commit/a966e781499ff6fd4eea66876d7532301b13a382'}", "dataset": "osv", "summary": "Improper Neutralization of Argument Delimiters in a Decompiling Package Process in APKLeaks APKLeaks prior to v2.0.4 allows remote authenticated attackers to execute arbitrary OS commands via package name inside the application manifest.\n\n### Impact\n\nAn authenticated attacker could include arguments that allow unintended commands or code to be executed, allow sensitive data to be read or modified, or could cause other unintended behavior through malicious package names.\n\n\n### References\n\n- a966e781499ff6fd4eea66876d7532301b13a382\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n* Email me at [me@dw1.io](mailto:me@dw1.io)", "published_date": "2022-01-21", "chain_len": 1, "project": "https://github.com/dwisiswant0/apkleaks", "commit_href": "https://github.com/dwisiswant0/apkleaks/commit/a966e781499ff6fd4eea66876d7532301b13a382", "commit_sha": "a966e781499ff6fd4eea66876d7532301b13a382", "patch": "SINGLE", "chain_ord": "['a966e781499ff6fd4eea66876d7532301b13a382']", "before_first_fix_commit": "{'8577b7af6224bf0a5455b552963c46721308d2ff'}", "last_fix_commit": "a966e781499ff6fd4eea66876d7532301b13a382", "chain_ord_pos": 1, "commit_datetime": "03/14/2021, 15:25:42", "message": "Escapes decompiling arguments", "author": "Dwi Siswanto", "comments": null, "stats": "{'additions': 4, 'deletions': 2, 'total': 6}", "files": {"apkleaks/apkleaks.py": {"additions": 4, "deletions": 2, "changes": 6, "status": "modified", "raw_url": "https://github.com/dwisiswant0/apkleaks/raw/a966e781499ff6fd4eea66876d7532301b13a382/apkleaks%2Fapkleaks.py", "patch": "@@ -2,6 +2,7 @@\n from apkleaks.colors import clr\n from contextlib import closing\n from distutils.spawn import find_executable\n+from pipes import quote\n from pyaxmlparser import APK\n from urllib.request import urlopen\n from zipfile import ZipFile\n@@ -84,8 +85,9 @@ def decompile(self):\n \t\t\t\t\tclasses.write(zipped.read(\"classes.dex\"))\n \t\t\texcept Exception as e:\n \t\t\t\tsys.exit(self.writeln(str(e), clr.WARNING))\n-\t\tdec = \"%s %s -d %s --deobf\" % (self.jadx, dex, self.tempdir)\n-\t\tos.system(dec)\n+\t\targs = [self.jadx, dex, \"-d\", self.tempdir, \"--deobf\"]\n+\t\tcomm = \"%s\" % (\" \".join(quote(arg) for arg in args))\n+\t\tos.system(comm)\n \t\treturn self.tempdir\n \n \tdef unique(self, list):"}}, "prior_version": " from apkleaks.colors import clr from contextlib import closing from distutils.spawn import find_executable from pyaxmlparser import APK from urllib.request import urlopen from zipfile import ZipFile def decompile(self): \t\t\t\t\tclasses.write(zipped.read(\"classes.dex\")) \t\t\texcept Exception as e: \t\t\t\tsys.exit(self.writeln(str(e), clr.WARNING)) \t\tdec = \"%s %s -d %s --deobf\" % (self.jadx, dex, self.tempdir) \t\tos.system(dec) \t\treturn self.tempdir  \tdef unique(self, list): ", "after_version": " from apkleaks.colors import clr from contextlib import closing from distutils.spawn import find_executable from pipes import quote from pyaxmlparser import APK from urllib.request import urlopen from zipfile import ZipFile def decompile(self): \t\t\t\t\tclasses.write(zipped.read(\"classes.dex\")) \t\t\texcept Exception as e: \t\t\t\tsys.exit(self.writeln(str(e), clr.WARNING)) \t\targs = [self.jadx, dex, \"-d\", self.tempdir, \"--deobf\"] \t\tcomm = \"%s\" % (\" \".join(quote(arg) for arg in args)) \t\tos.system(comm) \t\treturn self.tempdir  \tdef unique(self, list): ", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "GHSA-8jxq-75rw-fhj9", "cwe_id": "{'CWE-94'}", "score": 9.8, "chain": "{'https://github.com/pyeve/eve/commit/f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98'}", "dataset": "osv", "summary": "Eve allows execution of arbitrary code via Code Injection in the where parameter io/mongo/parser.py in Eve (aka pyeve) before 0.7.5 allows remote attackers to execute arbitrary code via Code Injection in the where parameter.", "published_date": "2018-07-12", "chain_len": 1, "project": "https://github.com/pyeve/eve", "commit_href": "https://github.com/pyeve/eve/commit/f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98", "commit_sha": "f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98", "patch": "SINGLE", "chain_ord": "['f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98']", "before_first_fix_commit": "{'6d1526bf8ad93a3d259b1fd357f0c40e4ed9dbf5'}", "last_fix_commit": "f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98", "chain_ord_pos": 1, "commit_datetime": "01/14/2018, 16:51:26", "message": "fix mongo visitor parser", "author": "Nicola Iarocci", "comments": null, "stats": "{'additions': 9, 'deletions': 6, 'total': 15}", "files": {"eve/io/mongo/parser.py": {"additions": 9, "deletions": 6, "changes": 15, "status": "modified", "raw_url": "https://github.com/pyeve/eve/raw/f8f7019ffdf9b4e05faf95e1f04e204aa4c91f98/eve%2Fio%2Fmongo%2Fparser.py", "patch": "@@ -122,16 +122,19 @@ def visit_Call(self, node):\n         datetime().\n         \"\"\"\n         if isinstance(node.func, ast.Name):\n-            expr = None\n             if node.func.id == 'ObjectId':\n-                expr = \"('\" + node.args[0].s + \"')\"\n+                try:\n+                    self.current_value = ObjectId(node.args[0].s)\n+                except:\n+                    pass\n             elif node.func.id == 'datetime':\n                 values = []\n                 for arg in node.args:\n-                    values.append(str(arg.n))\n-                expr = \"(\" + \", \".join(values) + \")\"\n-            if expr:\n-                self.current_value = eval(node.func.id + expr)\n+                    values.append(arg.n)\n+                try:\n+                    self.current_value = datetime(*values)\n+                except:\n+                    pass\n \n     def visit_Attribute(self, node):\n         \"\"\" Attribute handler ('Contact.Id')."}}, "prior_version": " def visit_Call(self, node):         datetime().         \"\"\"         if isinstance(node.func, ast.Name):             expr = None             if node.func.id == 'ObjectId':                 expr = \"('\" + node.args[0].s + \"')\"             elif node.func.id == 'datetime':                 values = []                 for arg in node.args:                     values.append(str(arg.n))                 expr = \"(\" + \", \".join(values) + \")\"             if expr:                 self.current_value = eval(node.func.id + expr)      def visit_Attribute(self, node):         \"\"\" Attribute handler ('Contact.Id').", "after_version": " def visit_Call(self, node):         datetime().         \"\"\"         if isinstance(node.func, ast.Name):             if node.func.id == 'ObjectId':                 try:                     self.current_value = ObjectId(node.args[0].s)                 except:                     pass             elif node.func.id == 'datetime':                 values = []                 for arg in node.args:                     values.append(arg.n)                 try:                     self.current_value = datetime(*values)                 except:                     pass      def visit_Attribute(self, node):         \"\"\" Attribute handler ('Contact.Id').", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "GHSA-8p5c-f328-9fvv", "cwe_id": "{'CWE-22'}", "score": 9.8, "chain": "{'https://github.com/anthraxx/diffoscope/commit/632a40828a54b399787c25e7fa243f732aef7e05'}", "dataset": "osv", "summary": "Diffoscope may write to arbitrary locations due to an untrusted archive diffoscope before 76 writes to arbitrary locations on disk based on the contents of an untrusted archive.", "published_date": "2018-07-13", "chain_len": 1, "project": "https://github.com/anthraxx/diffoscope", "commit_href": "https://github.com/anthraxx/diffoscope/commit/632a40828a54b399787c25e7fa243f732aef7e05", "commit_sha": "632a40828a54b399787c25e7fa243f732aef7e05", "patch": "SINGLE", "chain_ord": "['632a40828a54b399787c25e7fa243f732aef7e05']", "before_first_fix_commit": "{'b468a2840a097f4b2f7719929d690d5738dbcae4'}", "last_fix_commit": "632a40828a54b399787c25e7fa243f732aef7e05", "chain_ord_pos": 1, "commit_datetime": "02/09/2017, 21:47:05", "message": "Extract archive members using an auto-incrementing integer, avoiding the need to sanitise filenames. (Closes: #854723)\n\nSigned-off-by: Chris Lamb <lamby@debian.org>", "author": "Chris Lamb", "comments": null, "stats": "{'additions': 14, 'deletions': 27, 'total': 41}", "files": {"diffoscope/comparators/utils/libarchive.py": {"additions": 14, "deletions": 27, "changes": 41, "status": "modified", "raw_url": "https://github.com/anthraxx/diffoscope/raw/632a40828a54b399787c25e7fa243f732aef7e05/diffoscope%2Fcomparators%2Futils%2Flibarchive.py", "patch": "@@ -23,6 +23,7 @@\n import ctypes\n import logging\n import libarchive\n+import collections\n \n from diffoscope.tempfiles import get_temporary_directory\n \n@@ -168,11 +169,11 @@ def close_archive(self):\n \n     def get_member_names(self):\n         self.ensure_unpacked()\n-        return self._member_names\n+        return self._members.keys()\n \n     def extract(self, member_name, dest_dir):\n         self.ensure_unpacked()\n-        return os.path.join(self._unpacked, member_name)\n+        return self._members[member_name]\n \n     def get_member(self, member_name):\n         with libarchive.file_reader(self.source.path) as archive:\n@@ -197,45 +198,31 @@ def get_subclass(self, entry):\n         return LibarchiveMember(self, entry)\n \n     def ensure_unpacked(self):\n-        if hasattr(self, '_unpacked'):\n+        if hasattr(self, '_members'):\n             return\n \n-        self._unpacked = get_temporary_directory().name\n-        self._member_names = []\n+        tmpdir = get_temporary_directory().name\n+        self._members = collections.OrderedDict()\n \n-        logger.debug(\"Extracting %s to %s\", self.source.path, self._unpacked)\n+        logger.debug(\"Extracting %s to %s\", self.source.path, tmpdir)\n \n         with libarchive.file_reader(self.source.path) as archive:\n-            for entry in archive:\n-                self._member_names.append(entry.pathname)\n+            for idx, entry in enumerate(archive):\n+                # Maintain a mapping of archive path to the extracted path,\n+                # avoiding the need to sanitise filenames.\n+                dst = os.path.join(tmpdir, '{}'.format(idx))\n+                self._members[entry.pathname] = dst\n \n                 if entry.isdir:\n                     continue\n \n-                # All extracted locations must be underneath self._unpacked\n-                force_prefix = os.path.join(self._unpacked, \"\")\n-\n-                # Try to pick a safe and reasonable candidate name\n-                candidate_name = os.path.normpath(entry.pathname.rstrip('/' + os.sep))\n-                if os.path.isabs(candidate_name):\n-                    candidate_name = os.path.relpath(candidate_name, os.path.join(os.path.sep))\n-\n-                dst = os.path.normpath(os.path.join(self._unpacked, candidate_name))\n-                if not dst.startswith(force_prefix):\n-                    logger.warn(\"Skipping member because we could not make a safe name to extract it to: '%s'\",\n-                                entry.pathname)\n-                    continue\n-\n-                # TODO: need to fix reading these cleaned members. currently\n-                # reading will still try to use the uncleaned name.\n-                #logging.debug(\"Extracting %s to %s\", entry.pathname, dst)\n-                os.makedirs(os.path.dirname(dst), exist_ok=True)\n+                logger.debug(\"Extracting %s to %s\", entry.pathname, dst)\n \n                 with open(dst, 'wb') as f:\n                     for block in entry.get_blocks():\n                         f.write(block)\n \n         logger.debug(\n             \"Extracted %d entries from %s to %s\",\n-            len(self._member_names), self.source.path, self._unpacked,\n+            len(self._members), self.source.path, tmpdir,\n         )"}}, "prior_version": " import ctypes import logging import libarchive  from diffoscope.tempfiles import get_temporary_directory  def close_archive(self):      def get_member_names(self):         self.ensure_unpacked()         return self._member_names      def extract(self, member_name, dest_dir):         self.ensure_unpacked()         return os.path.join(self._unpacked, member_name)      def get_member(self, member_name):         with libarchive.file_reader(self.source.path) as archive: def get_subclass(self, entry):         return LibarchiveMember(self, entry)      def ensure_unpacked(self):         if hasattr(self, '_unpacked'):             return          self._unpacked = get_temporary_directory().name         self._member_names = []          logger.debug(\"Extracting %s to %s\", self.source.path, self._unpacked)          with libarchive.file_reader(self.source.path) as archive:             for entry in archive:                 self._member_names.append(entry.pathname)                  if entry.isdir:                     continue                  # All extracted locations must be underneath self._unpacked                 force_prefix = os.path.join(self._unpacked, \"\")                  # Try to pick a safe and reasonable candidate name                 candidate_name = os.path.normpath(entry.pathname.rstrip('/' + os.sep))                 if os.path.isabs(candidate_name):                     candidate_name = os.path.relpath(candidate_name, os.path.join(os.path.sep))                  dst = os.path.normpath(os.path.join(self._unpacked, candidate_name))                 if not dst.startswith(force_prefix):                     logger.warn(\"Skipping member because we could not make a safe name to extract it to: '%s'\",                                 entry.pathname)                     continue                  # TODO: need to fix reading these cleaned members. currently                 # reading will still try to use the uncleaned name.                 #logging.debug(\"Extracting %s to %s\", entry.pathname, dst)                 os.makedirs(os.path.dirname(dst), exist_ok=True)                  with open(dst, 'wb') as f:                     for block in entry.get_blocks():                         f.write(block)          logger.debug(             \"Extracted %d entries from %s to %s\",             len(self._member_names), self.source.path, self._unpacked,         )", "after_version": " import ctypes import logging import libarchive import collections  from diffoscope.tempfiles import get_temporary_directory  def close_archive(self):      def get_member_names(self):         self.ensure_unpacked()         return self._members.keys()      def extract(self, member_name, dest_dir):         self.ensure_unpacked()         return self._members[member_name]      def get_member(self, member_name):         with libarchive.file_reader(self.source.path) as archive: def get_subclass(self, entry):         return LibarchiveMember(self, entry)      def ensure_unpacked(self):         if hasattr(self, '_members'):             return          tmpdir = get_temporary_directory().name         self._members = collections.OrderedDict()          logger.debug(\"Extracting %s to %s\", self.source.path, tmpdir)          with libarchive.file_reader(self.source.path) as archive:             for idx, entry in enumerate(archive):                 # Maintain a mapping of archive path to the extracted path,                 # avoiding the need to sanitise filenames.                 dst = os.path.join(tmpdir, '{}'.format(idx))                 self._members[entry.pathname] = dst                  if entry.isdir:                     continue                  logger.debug(\"Extracting %s to %s\", entry.pathname, dst)                  with open(dst, 'wb') as f:                     for block in entry.get_blocks():                         f.write(block)          logger.debug(             \"Extracted %d entries from %s to %s\",             len(self._members), self.source.path, tmpdir,         )", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-8phj-f9w2-cjcc", "cwe_id": "{'CWE-22'}", "score": 8.6, "chain": "{'https://github.com/aimhubio/aim/pull/1003/commits/f01266a1a479ef11d7d6c539e7dd89e9d5639738'}", "dataset": "osv", "summary": "Arbitrary file reading vulnerability in Aim ### Impact\nA path traversal attack aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files.\n\nVulnerable code: https://github.com/aimhubio/aim/blob/0b99c6ca08e0ba7e7011453a2f68033e9b1d1bce/aim/web/api/views.py#L9-L16\n\n### Patches\nThe vulnerability issue is resolved in Aim v3.1.0.\n\n### References\nhttps://owasp.org/www-community/attacks/Path_Traversal", "published_date": "2021-11-23", "chain_len": 1, "project": "https://github.com/aimhubio/aim", "commit_href": "https://github.com/aimhubio/aim/pull/1003/commits/f01266a1a479ef11d7d6c539e7dd89e9d5639738", "commit_sha": "f01266a1a479ef11d7d6c539e7dd89e9d5639738", "patch": "SINGLE", "chain_ord": "['f01266a1a479ef11d7d6c539e7dd89e9d5639738']", "before_first_fix_commit": "{'0bcac8b709f9409518134b2eafee817278aca14f'}", "last_fix_commit": "f01266a1a479ef11d7d6c539e7dd89e9d5639738", "chain_ord_pos": 1, "commit_datetime": "11/12/2021, 14:03:22", "message": "Fix security issue when incorrect path is given to the endpoint that serves static files which can lead to a leak of non wanted files (e.g. /static-files/../../../../etc/passwd)", "author": "mihran113", "comments": null, "stats": "{'additions': 9, 'deletions': 1, 'total': 10}", "files": {"aim/web/api/views.py": {"additions": 9, "deletions": 1, "changes": 10, "status": "modified", "raw_url": "https://github.com/aimhubio/aim/raw/f01266a1a479ef11d7d6c539e7dd89e9d5639738/aim%2Fweb%2Fapi%2Fviews.py", "patch": "@@ -1,15 +1,23 @@\n import os\n+from pathlib import Path\n \n from aim.web.api.utils import APIRouter  # wrapper for fastapi.APIRouter\n from fastapi.responses import FileResponse\n+from fastapi import HTTPException\n \n statics_router = APIRouter()\n \n \n @statics_router.get('/static-files/{path:path}/')\n async def serve_static_files(path):\n     from aim import web\n-    static_file_name = os.path.join(os.path.dirname(web.__file__), 'ui', 'build', path)\n+    static_file_root = os.path.join(os.path.dirname(web.__file__), 'ui', 'build')\n+    static_file_name = os.path.join(static_file_root, path)\n+\n+    # check if path is leading inside ui/build directory\n+    if not Path(static_file_root) in Path(static_file_name).resolve().parents:\n+        raise HTTPException(404)\n+\n     compressed_file_name = '{}.gz'.format(static_file_name)\n     if os.path.exists(compressed_file_name):\n         return FileResponse(compressed_file_name, headers={'Content-Encoding': 'gzip'})"}}, "prior_version": " import os  from aim.web.api.utils import APIRouter  # wrapper for fastapi.APIRouter from fastapi.responses import FileResponse  statics_router = APIRouter()   @statics_router.get('/static-files/{path:path}/') async def serve_static_files(path):     from aim import web     static_file_name = os.path.join(os.path.dirname(web.__file__), 'ui', 'build', path)     compressed_file_name = '{}.gz'.format(static_file_name)     if os.path.exists(compressed_file_name):         return FileResponse(compressed_file_name, headers={'Content-Encoding': 'gzip'})", "after_version": " import os from pathlib import Path  from aim.web.api.utils import APIRouter  # wrapper for fastapi.APIRouter from fastapi.responses import FileResponse from fastapi import HTTPException  statics_router = APIRouter()   @statics_router.get('/static-files/{path:path}/') async def serve_static_files(path):     from aim import web     static_file_root = os.path.join(os.path.dirname(web.__file__), 'ui', 'build')     static_file_name = os.path.join(static_file_root, path)      # check if path is leading inside ui/build directory     if not Path(static_file_root) in Path(static_file_name).resolve().parents:         raise HTTPException(404)      compressed_file_name = '{}.gz'.format(static_file_name)     if os.path.exists(compressed_file_name):         return FileResponse(compressed_file_name, headers={'Content-Encoding': 'gzip'})", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-976r-qfjj-c24w", "cwe_id": "{'CWE-78'}", "score": 9.8, "chain": "{'https://github.com/apache/airflow/commit/afa4b11fddfdbadb048f742cf66d5c21c675a5c8'}", "dataset": "osv", "summary": "Command injection via Celery broker in Apache Airflow An issue was found in Apache Airflow versions 1.10.10 and below. When using CeleryExecutor, if an attacker can connect to the broker (Redis, RabbitMQ) directly, it is possible to inject commands, resulting in the celery worker running arbitrary commands.", "published_date": "2020-07-27", "chain_len": 1, "project": "https://github.com/apache/airflow", "commit_href": "https://github.com/apache/airflow/commit/afa4b11fddfdbadb048f742cf66d5c21c675a5c8", "commit_sha": "afa4b11fddfdbadb048f742cf66d5c21c675a5c8", "patch": "SINGLE", "chain_ord": "['afa4b11fddfdbadb048f742cf66d5c21c675a5c8']", "before_first_fix_commit": "{'63260c9955d12a60d8c143a932432013dd05eebb'}", "last_fix_commit": "afa4b11fddfdbadb048f742cf66d5c21c675a5c8", "chain_ord_pos": 1, "commit_datetime": "12/27/2019, 08:24:41", "message": "[AIRFLOW-6351] security - ui - Add Cross Site Scripting defence (#6913)", "author": "tooptoop4", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"airflow/www_rbac/views.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/apache/airflow/raw/afa4b11fddfdbadb048f742cf66d5c21c675a5c8/airflow%2Fwww_rbac%2Fviews.py", "patch": "@@ -321,7 +321,7 @@ def get_int_arg(value, default=0):\n             num_dag_to=min(end, num_of_all_dags),\n             num_of_all_dags=num_of_all_dags,\n             paging=wwwutils.generate_pages(current_page, num_of_pages,\n-                                           search=arg_search_query,\n+                                           search=escape(arg_search_query) if arg_search_query else None,\n                                            showPaused=not hide_paused),\n             num_runs=num_runs,\n             tags=tags)"}}, "prior_version": " def get_int_arg(value, default=0):             num_dag_to=min(end, num_of_all_dags),             num_of_all_dags=num_of_all_dags,             paging=wwwutils.generate_pages(current_page, num_of_pages,                                            search=arg_search_query,                                            showPaused=not hide_paused),             num_runs=num_runs,             tags=tags)", "after_version": " def get_int_arg(value, default=0):             num_dag_to=min(end, num_of_all_dags),             num_of_all_dags=num_of_all_dags,             paging=wwwutils.generate_pages(current_page, num_of_pages,                                            search=escape(arg_search_query) if arg_search_query else None,                                            showPaused=not hide_paused),             num_runs=num_runs,             tags=tags)", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "GHSA-98gj-wwxm-cj3h", "cwe_id": "{'CWE-79'}", "score": 6.1, "chain": "{'https://github.com/lepture/mistune/commit/5f06d724bc05580e7f203db2d4a4905fc1127f98'}", "dataset": "osv", "summary": "Moderate severity vulnerability that affects mistune Cross-site scripting (XSS) vulnerability in the _keyify function in mistune.py in Mistune before 0.8.1 allows remote attackers to inject arbitrary web script or HTML by leveraging failure to escape the \"key\" argument.", "published_date": "2019-01-04", "chain_len": 1, "project": "https://github.com/lepture/mistune", "commit_href": "https://github.com/lepture/mistune/commit/5f06d724bc05580e7f203db2d4a4905fc1127f98", "commit_sha": "5f06d724bc05580e7f203db2d4a4905fc1127f98", "patch": "SINGLE", "chain_ord": "['5f06d724bc05580e7f203db2d4a4905fc1127f98']", "before_first_fix_commit": "{'7f7f106a717e6cf58012304e56b41d6fb2b98e5f'}", "last_fix_commit": "5f06d724bc05580e7f203db2d4a4905fc1127f98", "chain_ord_pos": 1, "commit_datetime": "11/20/2017, 15:15:09", "message": "Fix CVE-2017-16876", "author": "Hsiaoming Yang", "comments": null, "stats": "{'additions': 5, 'deletions': 3, 'total': 8}", "files": {"mistune.py": {"additions": 5, "deletions": 3, "changes": 8, "status": "modified", "raw_url": "https://github.com/lepture/mistune/raw/5f06d724bc05580e7f203db2d4a4905fc1127f98/mistune.py", "patch": "@@ -11,7 +11,7 @@\n import re\n import inspect\n \n-__version__ = '0.8'\n+__version__ = '0.8.1'\n __author__ = 'Hsiaoming Yang <me@lepture.com>'\n __all__ = [\n     'BlockGrammar', 'BlockLexer',\n@@ -48,7 +48,8 @@ def _pure_pattern(regex):\n \n \n def _keyify(key):\n-    return _key_pattern.sub(' ', key.lower())\n+    key = escape(key.lower(), quote=True)\n+    return _key_pattern.sub(' ', key)\n \n \n def escape(text, quote=False, smart_amp=True):\n@@ -445,7 +446,8 @@ class InlineGrammar(object):\n     inline_html = re.compile(\n         r'^(?:%s|%s|%s)' % (\n             r'<!--[\\s\\S]*?-->',\n-            r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\/\\1>' % (_valid_end, _valid_attr),\n+            r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\/\\1>' % (\n+                _valid_end, _valid_attr),\n             r'<\\w+%s(?:%s)*?\\s*\\/?>' % (_valid_end, _valid_attr),\n         )\n     )"}}, "prior_version": " import re import inspect  __version__ = '0.8' __author__ = 'Hsiaoming Yang <me@lepture.com>' __all__ = [     'BlockGrammar', 'BlockLexer', def _pure_pattern(regex):   def _keyify(key):     return _key_pattern.sub(' ', key.lower())   def escape(text, quote=False, smart_amp=True): class InlineGrammar(object):     inline_html = re.compile(         r'^(?:%s|%s|%s)' % (             r'<!--[\\s\\S]*?-->',             r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\/\\1>' % (_valid_end, _valid_attr),             r'<\\w+%s(?:%s)*?\\s*\\/?>' % (_valid_end, _valid_attr),         )     )", "after_version": " import re import inspect  __version__ = '0.8.1' __author__ = 'Hsiaoming Yang <me@lepture.com>' __all__ = [     'BlockGrammar', 'BlockLexer', def _pure_pattern(regex):   def _keyify(key):     key = escape(key.lower(), quote=True)     return _key_pattern.sub(' ', key)   def escape(text, quote=False, smart_amp=True): class InlineGrammar(object):     inline_html = re.compile(         r'^(?:%s|%s|%s)' % (             r'<!--[\\s\\S]*?-->',             r'<(\\w+%s)((?:%s)*?)\\s*>([\\s\\S]*?)<\\/\\1>' % (                 _valid_end, _valid_attr),             r'<\\w+%s(?:%s)*?\\s*\\/?>' % (_valid_end, _valid_attr),         )     )", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "GHSA-9jjr-qqfp-ppwx", "cwe_id": "{'CWE-94'}", "score": 9.6, "chain": "{'https://github.com/jupyterhub/binderhub/commit/195caac172690456dcdc8cc7a6ca50e05abf8182'}", "dataset": "osv", "summary": "remote code execution via git repo provider ### Impact\n\nA remote code execution vulnerability has been identified in BinderHub, where providing BinderHub with maliciously crafted input could execute code in the BinderHub context, with the potential to egress credentials of the BinderHub deployment, including JupyterHub API tokens, kubernetes service accounts, and docker registry credentials. This may provide the ability to manipulate images and other user created pods in the deployment, with the potential to escalate to the host depending on the underlying kubernetes configuration.\n\n### Patches\n\nPatch below, or [on GitHub](https://github.com/jupyterhub/binderhub/commit/195caac172690456dcdc8cc7a6ca50e05abf8182.patch)\n\n```diff\nFrom 9f4043d9dddc1174920e687773f27b7933f48ab6 Mon Sep 17 00:00:00 2001\nFrom: Riccardo Castellotti <rcastell@cern.ch>\nDate: Thu, 19 Aug 2021 15:49:43 +0200\nSubject: [PATCH] Explicitly separate git-ls-remote options from positional\n arguments\n\n---\n binderhub/repoproviders.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a/binderhub/repoproviders.py b/binderhub/repoproviders.py\nindex f33347b..5d4b87c 100755\n--- a/binderhub/repoproviders.py\n+++ b/binderhub/repoproviders.py\n@@ -484,7 +484,7 @@ class GitRepoProvider(RepoProvider):\n             self.sha1_validate(self.unresolved_ref)\n         except ValueError:\n             # The ref is a head/tag and we resolve it using `git ls-remote`\n-            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\n+            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\n             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n             if result.returncode:\n                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))\n-- \n2.25.1\n\n```\n\n### Workarounds\n\nDisable the git repo provider by specifying the `BinderHub.repo_providers` config, e.g.:\n\n```python\nfrom binderhub.repoproviders import (GitHubRepoProvider,\n                            GitLabRepoProvider, GistRepoProvider,\n                            ZenodoProvider, FigshareProvider, HydroshareProvider,\n                            DataverseProvider)\n\nc.BinderHub.repo_providers =  {\n            'gh': GitHubRepoProvider,\n            'gist': GistRepoProvider,\n            'gl': GitLabRepoProvider,\n            'zenodo': ZenodoProvider,\n            'figshare': FigshareProvider,\n            'hydroshare': HydroshareProvider,\n            'dataverse': DataverseProvider,\n        }\n```\n\n### References\n\nCredit: Jose Carlos Luna Duran (CERN) and Riccardo Castellotti (CERN).\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Email us at [security@ipython.org](mailto:security@ipython.org)", "published_date": "2021-08-30", "chain_len": 1, "project": "https://github.com/jupyterhub/binderhub", "commit_href": "https://github.com/jupyterhub/binderhub/commit/195caac172690456dcdc8cc7a6ca50e05abf8182", "commit_sha": "195caac172690456dcdc8cc7a6ca50e05abf8182", "patch": "SINGLE", "chain_ord": "['195caac172690456dcdc8cc7a6ca50e05abf8182']", "before_first_fix_commit": "{'034430adc8ed379135f3ef46ee6ca650781ef67c'}", "last_fix_commit": "195caac172690456dcdc8cc7a6ca50e05abf8182", "chain_ord_pos": 1, "commit_datetime": "08/19/2021, 13:49:43", "message": "Explicitly separate git-ls-remote options from positional arguments", "author": "Riccardo Castellotti", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"binderhub/repoproviders.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/jupyterhub/binderhub/raw/195caac172690456dcdc8cc7a6ca50e05abf8182/binderhub%2Frepoproviders.py", "patch": "@@ -484,7 +484,7 @@ async def get_resolved_ref(self):\n             self.sha1_validate(self.unresolved_ref)\n         except ValueError:\n             # The ref is a head/tag and we resolve it using `git ls-remote`\n-            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\n+            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\n             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n             if result.returncode:\n                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))"}}, "prior_version": " async def get_resolved_ref(self):             self.sha1_validate(self.unresolved_ref)         except ValueError:             # The ref is a head/tag and we resolve it using `git ls-remote`             command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)             if result.returncode:                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))", "after_version": " async def get_resolved_ref(self):             self.sha1_validate(self.unresolved_ref)         except ValueError:             # The ref is a head/tag and we resolve it using `git ls-remote`             command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]             result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)             if result.returncode:                 raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "GHSA-cmc7-mfmr-xqrx", "cwe_id": "{'CWE-480', 'CWE-287'}", "score": 7.5, "chain": "{'https://github.com/abhinavsingh/proxy.py/pull/482/commits/9b00093288237f5073c403f2c4f62acfdfa8ed46'}", "dataset": "osv", "summary": "Logic error in authentication in proxy.py before_upstream_connection in AuthPlugin in http/proxy/auth.py in proxy.py before 2.3.1 accepts incorrect Proxy-Authorization header data because of a boolean confusion (and versus or).", "published_date": "2021-04-07", "chain_len": 1, "project": "https://github.com/abhinavsingh/proxy.py", "commit_href": "https://github.com/abhinavsingh/proxy.py/pull/482/commits/9b00093288237f5073c403f2c4f62acfdfa8ed46", "commit_sha": "9b00093288237f5073c403f2c4f62acfdfa8ed46", "patch": "SINGLE", "chain_ord": "['9b00093288237f5073c403f2c4f62acfdfa8ed46']", "before_first_fix_commit": "{'0f78e74705e295bbfccfba342bf9fd34a9aa9103'}", "last_fix_commit": "9b00093288237f5073c403f2c4f62acfdfa8ed46", "chain_ord_pos": 1, "commit_datetime": "01/10/2021, 16:30:14", "message": "Fix basic auth condition", "author": "Abhinav Singh", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"proxy/http/proxy/auth.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/abhinavsingh/proxy.py/raw/9b00093288237f5073c403f2c4f62acfdfa8ed46/proxy%2Fhttp%2Fproxy%2Fauth.py", "patch": "@@ -35,8 +35,8 @@ def before_upstream_connection(\n                 raise ProxyAuthenticationFailed()\n             parts = request.headers[b'proxy-authorization'][1].split()\n             if len(parts) != 2 \\\n-                    and parts[0].lower() != b'basic' \\\n-                    and parts[1] != self.flags.auth_code:\n+                    or parts[0].lower() != b'basic' \\\n+                    or parts[1] != self.flags.auth_code:\n                 raise ProxyAuthenticationFailed()\n         return request"}}, "prior_version": " def before_upstream_connection(                 raise ProxyAuthenticationFailed()             parts = request.headers[b'proxy-authorization'][1].split()             if len(parts) != 2 \\                     and parts[0].lower() != b'basic' \\                     and parts[1] != self.flags.auth_code:                 raise ProxyAuthenticationFailed()         return request ", "after_version": " def before_upstream_connection(                 raise ProxyAuthenticationFailed()             parts = request.headers[b'proxy-authorization'][1].split()             if len(parts) != 2 \\                     or parts[0].lower() != b'basic' \\                     or parts[1] != self.flags.auth_code:                 raise ProxyAuthenticationFailed()         return request ", "file_extension": "py", "cwe": "CWE-287"}
{"vuln_id": "GHSA-cwpm-f78v-7m5c", "cwe_id": "{'CWE-400', 'CWE-20'}", "score": 5.5, "chain": "{'https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e'}", "dataset": "osv", "summary": "Denial of service in `tf.ragged.constant` due to lack of validation ### Impact\nThe implementation of [`tf.ragged.constant`](https://github.com/tensorflow/tensorflow/blob/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python/ops/ragged/ragged_factory_ops.py#L146-L239) does not fully validate the input arguments. This results in a denial of service by consuming all available memory:\n\n```python\nimport tensorflow as tf\ntf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)\n```\n  \n### Patches\nWe have patched the issue in GitHub commit [bd4d5583ff9c8df26d47a23e508208844297310e](https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported externally via a [GitHub issue](https://github.com/tensorflow/tensorflow/issues/55199).", "published_date": "2022-05-24", "chain_len": 1, "project": "https://github.com/tensorflow/tensorflow", "commit_href": "https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e", "commit_sha": "bd4d5583ff9c8df26d47a23e508208844297310e", "patch": "SINGLE", "chain_ord": "['bd4d5583ff9c8df26d47a23e508208844297310e']", "before_first_fix_commit": "{'e74ef072ecd54ca54f3940ce9b98af796ded2a1a'}", "last_fix_commit": "bd4d5583ff9c8df26d47a23e508208844297310e", "chain_ord_pos": 1, "commit_datetime": "04/15/2022, 16:11:43", "message": "Prevent denial of service in `tf.ragged.constant`\n\nFixes #55199\n\nPiperOrigin-RevId: 442029525", "author": "Mihai Maruseac", "comments": null, "stats": "{'additions': 3, 'deletions': 0, 'total': 3}", "files": {"tensorflow/python/ops/ragged/ragged_factory_ops.py": {"additions": 3, "deletions": 0, "changes": 3, "status": "modified", "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd4d5583ff9c8df26d47a23e508208844297310e/tensorflow%2Fpython%2Fops%2Fragged%2Fragged_factory_ops.py", "patch": "@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\n     if max_depth > scalar_depth:\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\n                        \"than scalar value nesting\" % pylist)\n+    if ragged_rank is not None and max_depth < ragged_rank:\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\n+                       f\"ragged_rank={ragged_rank}\")\n \n   # If both inner_shape and ragged_rank were specified, then check that\n   # they are compatible with pylist."}}, "prior_version": " def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,     if max_depth > scalar_depth:       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"                        \"than scalar value nesting\" % pylist)    # If both inner_shape and ragged_rank were specified, then check that   # they are compatible with pylist.", "after_version": " def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,     if max_depth > scalar_depth:       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"                        \"than scalar value nesting\" % pylist)     if ragged_rank is not None and max_depth < ragged_rank:       raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"                        f\"ragged_rank={ragged_rank}\")    # If both inner_shape and ragged_rank were specified, then check that   # they are compatible with pylist.", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "GHSA-cwpm-f78v-7m5c", "cwe_id": "{'CWE-400', 'CWE-20'}", "score": 5.5, "chain": "{'https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e'}", "dataset": "osv", "summary": "Denial of service in `tf.ragged.constant` due to lack of validation ### Impact\nThe implementation of [`tf.ragged.constant`](https://github.com/tensorflow/tensorflow/blob/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python/ops/ragged/ragged_factory_ops.py#L146-L239) does not fully validate the input arguments. This results in a denial of service by consuming all available memory:\n\n```python\nimport tensorflow as tf\ntf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)\n```\n  \n### Patches\nWe have patched the issue in GitHub commit [bd4d5583ff9c8df26d47a23e508208844297310e](https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e).\n\nThe fix will be included in TensorFlow 2.9.0. We will also cherrypick this commit on TensorFlow 2.8.1, TensorFlow 2.7.2, and TensorFlow 2.6.4, as these are also affected and still in supported range.\n\n### For more information\nPlease consult [our security guide](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.\n\n### Attribution\nThis vulnerability has been reported externally via a [GitHub issue](https://github.com/tensorflow/tensorflow/issues/55199).", "published_date": "2022-05-24", "chain_len": 1, "project": "https://github.com/tensorflow/tensorflow", "commit_href": "https://github.com/tensorflow/tensorflow/commit/bd4d5583ff9c8df26d47a23e508208844297310e", "commit_sha": "bd4d5583ff9c8df26d47a23e508208844297310e", "patch": "SINGLE", "chain_ord": "['bd4d5583ff9c8df26d47a23e508208844297310e']", "before_first_fix_commit": "{'e74ef072ecd54ca54f3940ce9b98af796ded2a1a'}", "last_fix_commit": "bd4d5583ff9c8df26d47a23e508208844297310e", "chain_ord_pos": 1, "commit_datetime": "04/15/2022, 16:11:43", "message": "Prevent denial of service in `tf.ragged.constant`\n\nFixes #55199\n\nPiperOrigin-RevId: 442029525", "author": "Mihai Maruseac", "comments": null, "stats": "{'additions': 3, 'deletions': 0, 'total': 3}", "files": {"tensorflow/python/ops/ragged/ragged_factory_ops.py": {"additions": 3, "deletions": 0, "changes": 3, "status": "modified", "raw_url": "https://github.com/tensorflow/tensorflow/raw/bd4d5583ff9c8df26d47a23e508208844297310e/tensorflow%2Fpython%2Fops%2Fragged%2Fragged_factory_ops.py", "patch": "@@ -188,6 +188,9 @@ def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,\n     if max_depth > scalar_depth:\n       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"\n                        \"than scalar value nesting\" % pylist)\n+    if ragged_rank is not None and max_depth < ragged_rank:\n+      raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"\n+                       f\"ragged_rank={ragged_rank}\")\n \n   # If both inner_shape and ragged_rank were specified, then check that\n   # they are compatible with pylist."}}, "prior_version": " def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,     if max_depth > scalar_depth:       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"                        \"than scalar value nesting\" % pylist)    # If both inner_shape and ragged_rank were specified, then check that   # they are compatible with pylist.", "after_version": " def _constant_value(ragged_factory, inner_factory, pylist, dtype, ragged_rank,     if max_depth > scalar_depth:       raise ValueError(\"Invalid pylist=%r: empty list nesting is greater \"                        \"than scalar value nesting\" % pylist)     if ragged_rank is not None and max_depth < ragged_rank:       raise ValueError(f\"Invalid pylist={pylist}, max depth smaller than \"                        f\"ragged_rank={ragged_rank}\")    # If both inner_shape and ragged_rank were specified, then check that   # they are compatible with pylist.", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-f8m6-h2c7-8h9x", "cwe_id": "{'CWE-400'}", "score": 7.5, "chain": "{'https://github.com/nltk/nltk/commit/1405aad979c6b8080dbbc8e0858f89b2e3690341'}", "dataset": "osv", "summary": "Inefficient Regular Expression Complexity in nltk (word_tokenize, sent_tokenize) ### Impact\nThe vulnerability is present in [`PunktSentenceTokenizer`](https://www.nltk.org/api/nltk.tokenize.punkt.html#nltk.tokenize.punkt.PunktSentenceTokenizer), [`sent_tokenize`](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.sent_tokenize)  and [`word_tokenize`](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.word_tokenize). Any users of this class, or these two functions, are vulnerable to a Regular Expression Denial of Service (ReDoS) attack. \nIn short, a specifically crafted long input to any of these vulnerable functions will cause them to take a significant amount of execution time. The effect of this vulnerability is noticeable with the following example:\n```python\nfrom nltk.tokenize import word_tokenize\n\nn = 8\nfor length in [10**i for i in range(2, n)]:\n    # Prepare a malicious input\n    text = \"a\" * length\n    start_t = time.time()\n    # Call `word_tokenize` and naively measure the execution time\n    word_tokenize(text)\n    print(f\"A length of {length:<{n}} takes {time.time() - start_t:.4f}s\")\n```\nWhich gave the following output during testing:\n```python\nA length of 100      takes 0.0060s\nA length of 1000     takes 0.0060s\nA length of 10000    takes 0.6320s\nA length of 100000   takes 56.3322s\n...\n```\nI canceled the execution of the program after running it for several hours.\n\nIf your program relies on any of the vulnerable functions for tokenizing unpredictable user input, then we would strongly recommend upgrading to a version of NLTK without the vulnerability, or applying the workaround described below.\n\n### Patches\nThe problem has been patched in NLTK 3.6.6. After the fix, running the above program gives the following result:\n```python\nA length of 100      takes 0.0070s\nA length of 1000     takes 0.0010s\nA length of 10000    takes 0.0060s\nA length of 100000   takes 0.0400s\nA length of 1000000  takes 0.3520s\nA length of 10000000 takes 3.4641s\n```\nThis output shows a linear relationship in execution time versus input length, which is desirable for regular expressions.\nWe recommend updating to NLTK 3.6.6+ if possible.\n\n### Workarounds\nThe execution time of the vulnerable functions is exponential to the length of a malicious input. With other words, the execution time can be bounded by limiting the maximum length of an input to any of the vulnerable functions. Our recommendation is to implement such a limit.\n\n### References\n* The issue showcasing the vulnerability: https://github.com/nltk/nltk/issues/2866\n* The pull request containing considerably more information on the vulnerability, and the fix: https://github.com/nltk/nltk/pull/2869\n* The commit containing the fix: 1405aad979c6b8080dbbc8e0858f89b2e3690341\n* Information on CWE-1333: Inefficient Regular Expression Complexity: https://cwe.mitre.org/data/definitions/1333.html\n\n### For more information\nIf you have any questions or comments about this advisory:\n* Open an issue in [github.com/nltk/nltk](https://github.com/nltk/nltk)\n* Email us at [nltk.team@gmail.com](mailto:nltk.team@gmail.com)", "published_date": "2022-01-06", "chain_len": 1, "project": "https://github.com/nltk/nltk", "commit_href": "https://github.com/nltk/nltk/commit/1405aad979c6b8080dbbc8e0858f89b2e3690341", "commit_sha": "1405aad979c6b8080dbbc8e0858f89b2e3690341", "patch": "SINGLE", "chain_ord": "['1405aad979c6b8080dbbc8e0858f89b2e3690341']", "before_first_fix_commit": "{'0b7b076247ec41f9b6b8a94400d48ea299e4b507'}", "last_fix_commit": "1405aad979c6b8080dbbc8e0858f89b2e3690341", "chain_ord_pos": 1, "commit_datetime": "11/26/2021, 11:58:19", "message": "Resolved serious ReDoS in PunktSentenceTokenizer (#2869)\n\n* Resolved serious ReDOS in PunktSentenceTokenizer\r\n\r\n* Improve performance by relying on string split instead of re.search\r\n\r\n* Solved issue if sentence contains just one token", "author": "Tom Aarsen", "comments": null, "stats": "{'additions': 61, 'deletions': 5, 'total': 66}", "files": {"nltk/tokenize/punkt.py": {"additions": 61, "deletions": 5, "changes": 66, "status": "modified", "raw_url": "https://github.com/nltk/nltk/raw/1405aad979c6b8080dbbc8e0858f89b2e3690341/nltk%2Ftokenize%2Fpunkt.py", "patch": "@@ -266,7 +266,6 @@ def word_tokenize(self, s):\n         return self._word_tokenizer_re().findall(s)\n \n     _period_context_fmt = r\"\"\"\n-        \\S*                          # some word material\n         %(SentEndChars)s             # a potential sentence ending\n         (?=(?P<after_tok>\n             %(NonWord)s              # either other punctuation\n@@ -1284,8 +1283,7 @@ def debug_decisions(self, text):\n         See format_debug_decision() to help make this output readable.\n         \"\"\"\n \n-        for match in self._lang_vars.period_context_re().finditer(text):\n-            decision_text = match.group() + match.group(\"after_tok\")\n+        for match, decision_text in self._match_potential_end_contexts(text):\n             tokens = self._tokenize_words(decision_text)\n             tokens = list(self._annotate_first_pass(tokens))\n             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars):\n@@ -1333,10 +1331,68 @@ def sentences_from_text(self, text, realign_boundaries=True):\n         \"\"\"\n         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\n \n+    def _match_potential_end_contexts(self, text):\n+        \"\"\"\n+        Given a text, find the matches of potential sentence breaks,\n+        alongside the contexts surrounding these sentence breaks.\n+\n+        Since the fix for the ReDOS discovered in issue #2866, we no longer match\n+        the word before a potential end of sentence token. Instead, we use a separate\n+        regex for this. As a consequence, `finditer`'s desire to find non-overlapping\n+        matches no longer aids us in finding the single longest match.\n+        Where previously, we could use::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +SKIP\n+            [<re.Match object; span=(9, 18), match='acting!!!'>]\n+\n+        Now we have to find the word before (i.e. 'acting') separately, and `finditer`\n+        returns::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +NORMALIZE_WHITESPACE\n+            [<re.Match object; span=(15, 16), match='!'>,\n+            <re.Match object; span=(16, 17), match='!'>,\n+            <re.Match object; span=(17, 18), match='!'>]\n+\n+        So, we need to find the word before the match from right to left, and then manually remove\n+        the overlaps. That is what this method does::\n+\n+            >>> pst = PunktSentenceTokenizer()\n+            >>> text = \"Very bad acting!!! I promise.\"\n+            >>> pst._match_potential_end_contexts(text)\n+            [(<re.Match object; span=(17, 18), match='!'>, 'acting!!! I')]\n+\n+        :param text: String of one or more sentences\n+        :type text: str\n+        :return: List of match-context tuples.\n+        :rtype: List[Tuple[re.Match, str]]\n+        \"\"\"\n+        before_words = {}\n+        matches = []\n+        for match in reversed(list(self._lang_vars.period_context_re().finditer(text))):\n+            # Ignore matches that have already been captured by matches to the right of this match\n+            if matches and match.end() > before_start:\n+                continue\n+            # Find the word before the current match\n+            split = text[: match.start()].rsplit(maxsplit=1)\n+            before_start = len(split[0]) if len(split) == 2 else 0\n+            before_words[match] = split[-1]\n+            matches.append(match)\n+\n+        return [\n+            (\n+                match,\n+                before_words[match] + match.group() + match.group(\"after_tok\"),\n+            )\n+            for match in matches[::-1]\n+        ]\n+\n     def _slices_from_text(self, text):\n         last_break = 0\n-        for match in self._lang_vars.period_context_re().finditer(text):\n-            context = match.group() + match.group(\"after_tok\")\n+        for match, context in self._match_potential_end_contexts(text):\n             if self.text_contains_sentbreak(context):\n                 yield slice(last_break, match.end())\n                 if match.group(\"next_tok\"):"}}, "prior_version": " def word_tokenize(self, s):         return self._word_tokenizer_re().findall(s)      _period_context_fmt = r\"\"\"         \\S*                          # some word material         %(SentEndChars)s             # a potential sentence ending         (?=(?P<after_tok>             %(NonWord)s              # either other punctuation def debug_decisions(self, text):         See format_debug_decision() to help make this output readable.         \"\"\"          for match in self._lang_vars.period_context_re().finditer(text):             decision_text = match.group() + match.group(\"after_tok\")             tokens = self._tokenize_words(decision_text)             tokens = list(self._annotate_first_pass(tokens))             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars): def sentences_from_text(self, text, realign_boundaries=True):         \"\"\"         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]      def _slices_from_text(self, text):         last_break = 0         for match in self._lang_vars.period_context_re().finditer(text):             context = match.group() + match.group(\"after_tok\")             if self.text_contains_sentbreak(context):                 yield slice(last_break, match.end())                 if match.group(\"next_tok\"):", "after_version": " def word_tokenize(self, s):         return self._word_tokenizer_re().findall(s)      _period_context_fmt = r\"\"\"         %(SentEndChars)s             # a potential sentence ending         (?=(?P<after_tok>             %(NonWord)s              # either other punctuation def debug_decisions(self, text):         See format_debug_decision() to help make this output readable.         \"\"\"          for match, decision_text in self._match_potential_end_contexts(text):             tokens = self._tokenize_words(decision_text)             tokens = list(self._annotate_first_pass(tokens))             while tokens and not tokens[0].tok.endswith(self._lang_vars.sent_end_chars): def sentences_from_text(self, text, realign_boundaries=True):         \"\"\"         return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]      def _match_potential_end_contexts(self, text):         \"\"\"         Given a text, find the matches of potential sentence breaks,         alongside the contexts surrounding these sentence breaks.          Since the fix for the ReDOS discovered in issue #2866, we no longer match         the word before a potential end of sentence token. Instead, we use a separate         regex for this. As a consequence, `finditer`'s desire to find non-overlapping         matches no longer aids us in finding the single longest match.         Where previously, we could use::              >>> pst = PunktSentenceTokenizer()             >>> text = \"Very bad acting!!! I promise.\"             >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +SKIP             [<re.Match object; span=(9, 18), match='acting!!!'>]          Now we have to find the word before (i.e. 'acting') separately, and `finditer`         returns::              >>> pst = PunktSentenceTokenizer()             >>> text = \"Very bad acting!!! I promise.\"             >>> list(pst._lang_vars.period_context_re().finditer(text)) # doctest: +NORMALIZE_WHITESPACE             [<re.Match object; span=(15, 16), match='!'>,             <re.Match object; span=(16, 17), match='!'>,             <re.Match object; span=(17, 18), match='!'>]          So, we need to find the word before the match from right to left, and then manually remove         the overlaps. That is what this method does::              >>> pst = PunktSentenceTokenizer()             >>> text = \"Very bad acting!!! I promise.\"             >>> pst._match_potential_end_contexts(text)             [(<re.Match object; span=(17, 18), match='!'>, 'acting!!! I')]          :param text: String of one or more sentences         :type text: str         :return: List of match-context tuples.         :rtype: List[Tuple[re.Match, str]]         \"\"\"         before_words = {}         matches = []         for match in reversed(list(self._lang_vars.period_context_re().finditer(text))):             # Ignore matches that have already been captured by matches to the right of this match             if matches and match.end() > before_start:                 continue             # Find the word before the current match             split = text[: match.start()].rsplit(maxsplit=1)             before_start = len(split[0]) if len(split) == 2 else 0             before_words[match] = split[-1]             matches.append(match)          return [             (                 match,                 before_words[match] + match.group() + match.group(\"after_tok\"),             )             for match in matches[::-1]         ]      def _slices_from_text(self, text):         last_break = 0         for match, context in self._match_potential_end_contexts(text):             if self.text_contains_sentbreak(context):                 yield slice(last_break, match.end())                 if match.group(\"next_tok\"):", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-fh37-cx83-q542", "cwe_id": "{'CWE-306', 'CWE-269', 'CWE-287'}", "score": 5.3, "chain": "{'https://github.com/apache/airflow/commit/21cedff205e7d62675949fda2aa4616d77232b76'}", "dataset": "osv", "summary": "Improper Authentication in Apache Airflow The lineage endpoint of the deprecated Experimental API was not protected by authentication in Airflow 2.0.0. This allowed unauthenticated users to hit that endpoint. This is low-severity issue as the attacker needs to be aware of certain parameters to pass to that endpoint and even after can just get some metadata about a DAG and a Task. This issue only affects Apache Airflow 2.0.0.", "published_date": "2021-06-18", "chain_len": 1, "project": "https://github.com/apache/airflow", "commit_href": "https://github.com/apache/airflow/commit/21cedff205e7d62675949fda2aa4616d77232b76", "commit_sha": "21cedff205e7d62675949fda2aa4616d77232b76", "patch": "SINGLE", "chain_ord": "['21cedff205e7d62675949fda2aa4616d77232b76']", "before_first_fix_commit": "{'4b1a6f78d132e42f1c946f53eca89789d21bdc1d'}", "last_fix_commit": "21cedff205e7d62675949fda2aa4616d77232b76", "chain_ord_pos": 1, "commit_datetime": "01/27/2021, 21:47:45", "message": "Add authentication to lineage endpoint for experimental API (#13870)\n\n(cherry picked from commit 24a54242d56058846c7978130b3f37ca045d5142)", "author": "Ian Carroll", "comments": null, "stats": "{'additions': 1, 'deletions': 0, 'total': 1}", "files": {"airflow/www/api/experimental/endpoints.py": {"additions": 1, "deletions": 0, "changes": 1, "status": "modified", "raw_url": "https://github.com/apache/airflow/raw/21cedff205e7d62675949fda2aa4616d77232b76/airflow%2Fwww%2Fapi%2Fexperimental%2Fendpoints.py", "patch": "@@ -389,6 +389,7 @@ def delete_pool(name):\n \n \n @api_experimental.route('/lineage/<string:dag_id>/<string:execution_date>', methods=['GET'])\n+@requires_authentication\n def get_lineage(dag_id: str, execution_date: str):\n     \"\"\"Get Lineage details for a DagRun\"\"\"\n     # Convert string datetime into actual datetime"}}, "prior_version": " def delete_pool(name):   @api_experimental.route('/lineage/<string:dag_id>/<string:execution_date>', methods=['GET']) def get_lineage(dag_id: str, execution_date: str):     \"\"\"Get Lineage details for a DagRun\"\"\"     # Convert string datetime into actual datetime", "after_version": " def delete_pool(name):   @api_experimental.route('/lineage/<string:dag_id>/<string:execution_date>', methods=['GET']) @requires_authentication def get_lineage(dag_id: str, execution_date: str):     \"\"\"Get Lineage details for a DagRun\"\"\"     # Convert string datetime into actual datetime", "file_extension": "py", "cwe": "CWE-287"}
{"vuln_id": "GHSA-h8pj-cxx2-jfg2", "cwe_id": "{'CWE-20'}", "score": 9.1, "chain": "{'https://github.com/encode/httpx/pull/2185/commits/e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1'}", "dataset": "osv", "summary": "Improper Input Validation in httpx Encode OSS httpx <=1.0.0.beta0 is affected by improper input validation in `httpx.URL`, `httpx.Client` and some functions using `httpx.URL.copy_with`.", "published_date": "2022-04-29", "chain_len": 1, "project": "https://github.com/encode/httpx", "commit_href": "https://github.com/encode/httpx/pull/2185/commits/e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1", "commit_sha": "e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1", "patch": "SINGLE", "chain_ord": "['e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1']", "before_first_fix_commit": "{'b07fe7b0745e62be5ef9bce1bee9e7d7a8878552'}", "last_fix_commit": "e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1", "chain_ord_pos": 1, "commit_datetime": "04/21/2022, 06:22:38", "message": "Patch `copy_with`", "author": "lebr0nli", "comments": null, "stats": "{'additions': 5, 'deletions': 1, 'total': 6}", "files": {"httpx/_urls.py": {"additions": 5, "deletions": 1, "changes": 6, "status": "modified", "raw_url": "https://github.com/encode/httpx/raw/e3c495a32c63d8aa7f1bcf3b7b27ee1a0ff428e1/httpx%2F_urls.py", "patch": "@@ -484,7 +484,11 @@ def copy_with(self, **kwargs: typing.Any) -> \"URL\":\n         #  \\_/   \\______________/\\_________/ \\_________/ \\__/\n         #   |           |            |            |        |\n         # scheme     authority       path        query   fragment\n-        return URL(self._uri_reference.copy_with(**kwargs).unsplit())\n+        new_url = URL(self)\n+        new_url._uri_reference = self._uri_reference.copy_with(**kwargs)\n+        if new_url.is_absolute_url:\n+            new_url._uri_reference = new_url._uri_reference.normalize()\n+        return URL(new_url)\n \n     def copy_set_param(self, key: str, value: typing.Any = None) -> \"URL\":\n         return self.copy_with(params=self.params.set(key, value))"}}, "prior_version": " def copy_with(self, **kwargs: typing.Any) -> \"URL\":         #  \\_/   \\______________/\\_________/ \\_________/ \\__/         #   |           |            |            |        |         # scheme     authority       path        query   fragment         return URL(self._uri_reference.copy_with(**kwargs).unsplit())      def copy_set_param(self, key: str, value: typing.Any = None) -> \"URL\":         return self.copy_with(params=self.params.set(key, value))", "after_version": " def copy_with(self, **kwargs: typing.Any) -> \"URL\":         #  \\_/   \\______________/\\_________/ \\_________/ \\__/         #   |           |            |            |        |         # scheme     authority       path        query   fragment         new_url = URL(self)         new_url._uri_reference = self._uri_reference.copy_with(**kwargs)         if new_url.is_absolute_url:             new_url._uri_reference = new_url._uri_reference.normalize()         return URL(new_url)      def copy_set_param(self, key: str, value: typing.Any = None) -> \"URL\":         return self.copy_with(params=self.params.set(key, value))", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "GHSA-hj5v-574p-mj7c", "cwe_id": "{'CWE-400'}", "score": 7.5, "chain": "{'https://github.com/pytest-dev/py/pull/257/commits/4a9017dc6199d2a564b6e4b0aa39d6d8870e4144'}", "dataset": "osv", "summary": "Regular expression deinal of service in py A denial of service via regular expression in the py.path.svnwc component of py (aka python-py) through 1.9.0 could be used by attackers to cause a compute-time denial of service attack by supplying malicious input to the blame functionality.", "published_date": "2021-04-20", "chain_len": 1, "project": "https://github.com/pytest-dev/py", "commit_href": "https://github.com/pytest-dev/py/pull/257/commits/4a9017dc6199d2a564b6e4b0aa39d6d8870e4144", "commit_sha": "4a9017dc6199d2a564b6e4b0aa39d6d8870e4144", "patch": "SINGLE", "chain_ord": "['4a9017dc6199d2a564b6e4b0aa39d6d8870e4144']", "before_first_fix_commit": "{'2da2caea38812eaa3ce09dd5292e3635ce9b16c8'}", "last_fix_commit": "4a9017dc6199d2a564b6e4b0aa39d6d8870e4144", "chain_ord_pos": 1, "commit_datetime": "09/04/2020, 10:57:26", "message": "svnwc: fix regular expression vulnerable to DoS in blame functionality\n\nThe subpattern `\\d+\\s*\\S+` is ambiguous which makes the pattern subject\nto catastrophic backtracing given a string like `\"1\" * 5000`.\n\nSVN blame output seems to always have at least one space between the\nrevision number and the user name, so the ambiguity can be fixed by\nchanging the `*` to `+`.\n\nFixes #256.", "author": "Ran Benita", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"py/_path/svnwc.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/pytest-dev/py/raw/4a9017dc6199d2a564b6e4b0aa39d6d8870e4144/py%2F_path%2Fsvnwc.py", "patch": "@@ -396,7 +396,7 @@ def makecmdoptions(self):\n     def __str__(self):\n         return \"<SvnAuth username=%s ...>\" %(self.username,)\n \n-rex_blame = re.compile(r'\\s*(\\d+)\\s*(\\S+) (.*)')\n+rex_blame = re.compile(r'\\s*(\\d+)\\s+(\\S+) (.*)')\n \n class SvnWCCommandPath(common.PathBase):\n     \"\"\" path implementation offering access/modification to svn working copies."}}, "prior_version": " def makecmdoptions(self):     def __str__(self):         return \"<SvnAuth username=%s ...>\" %(self.username,)  rex_blame = re.compile(r'\\s*(\\d+)\\s*(\\S+) (.*)')  class SvnWCCommandPath(common.PathBase):     \"\"\" path implementation offering access/modification to svn working copies.", "after_version": " def makecmdoptions(self):     def __str__(self):         return \"<SvnAuth username=%s ...>\" %(self.username,)  rex_blame = re.compile(r'\\s*(\\d+)\\s+(\\S+) (.*)')  class SvnWCCommandPath(common.PathBase):     \"\"\" path implementation offering access/modification to svn working copies.", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-hq37-853p-g5cf", "cwe_id": "{'CWE-400'}", "score": 0.0, "chain": "{'https://github.com/Kozea/CairoSVG/commit/cfc9175e590531d90384aa88845052de53d94bf3'}", "dataset": "osv", "summary": "Regular Expression Denial of Service in CairoSVG # Doyensec Vulnerability Advisory \n\n* Regular Expression Denial of Service (REDoS) in cairosvg\n* Affected Product: CairoSVG v2.0.0+\n* Vendor: https://github.com/Kozea\n* Severity: Medium\n* Vulnerability Class: Denial of Service\n* Author(s): Ben Caller ([Doyensec](https://doyensec.com))\n\n## Summary\n\nWhen processing SVG files, the python package CairoSVG uses two regular expressions which are vulnerable to Regular Expression Denial of Service (REDoS).\nIf an attacker provides a malicious SVG, it can make cairosvg get stuck processing the file for a very long time.\n\n## Technical description\n\nThe vulnerable regular expressions are\n\nhttps://github.com/Kozea/CairoSVG/blob/9c4a982b9a021280ad90e89707eacc1d114e4ac4/cairosvg/colors.py#L190-L191\n\nThe section between 'rgb(' and the final ')' contains multiple overlapping groups.\n\nSince all three infinitely repeating groups accept spaces, a long string of spaces causes catastrophic backtracking when it is not followed by a closing parenthesis.\n\nThe complexity is cubic, so doubling the length of the malicious string of spaces makes processing take 8 times as long.\n\n## Reproduction steps\n\nCreate a malicious SVG of the form:\n\n    <svg width=\"1\" height=\"1\"><rect fill=\"rgb(                     ;\"/></svg>\n\nwith the following code:\n\n    '<svg width=\"1\" height=\"1\"><rect fill=\"rgb(' + (' ' * 3456) + ';\"/></svg>'\n\nNote that there is no closing parenthesis before the semi-colon.\n\nRun cairosvg e.g.:\n\n    cairosvg cairo-redos.svg -o x.png\n\nand notice that it hangs at 100% CPU. Increasing the number of spaces increases the processing time with cubic complexity.\n\n## Remediation\n\nFix the regexes to avoid overlapping parts. Perhaps remove the [ \\n\\r\\t]* groups from the regex, and use .strip() on the returned capture group.\n\n## Disclosure timeline\n\n- 2020-12-30: Vulnerability disclosed via email to CourtBouillon", "published_date": "2021-01-06", "chain_len": 1, "project": "https://github.com/Kozea/CairoSVG", "commit_href": "https://github.com/Kozea/CairoSVG/commit/cfc9175e590531d90384aa88845052de53d94bf3", "commit_sha": "cfc9175e590531d90384aa88845052de53d94bf3", "patch": "SINGLE", "chain_ord": "['cfc9175e590531d90384aa88845052de53d94bf3']", "before_first_fix_commit": "{'9c4a982b9a021280ad90e89707eacc1d114e4ac4', '063185b60588a41d4df661ad70f9f7b699901abc'}", "last_fix_commit": "cfc9175e590531d90384aa88845052de53d94bf3", "chain_ord_pos": 1, "commit_datetime": "01/06/2021, 14:43:14", "message": "Merge pull request from GHSA-hq37-853p-g5cf\n\nDon\u2019t use overlapping groups for regular expressions", "author": "Guillaume Ayoub", "comments": null, "stats": "{'additions': 4, 'deletions': 4, 'total': 8}", "files": {"cairosvg/colors.py": {"additions": 4, "deletions": 4, "changes": 8, "status": "modified", "raw_url": "https://github.com/Kozea/CairoSVG/raw/cfc9175e590531d90384aa88845052de53d94bf3/cairosvg%2Fcolors.py", "patch": "@@ -187,8 +187,8 @@\n     'transparent': (0, 0, 0, 0),\n }\n \n-RGBA = re.compile(r'rgba\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)')\n-RGB = re.compile(r'rgb\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)')\n+RGBA = re.compile(r'rgba\\((.+?)\\)')\n+RGB = re.compile(r'rgb\\((.+?)\\)')\n HEX_RRGGBB = re.compile('#[0-9a-f]{6}')\n HEX_RGB = re.compile('#[0-9a-f]{3}')\n \n@@ -212,14 +212,14 @@ def color(string, opacity=1):\n     if match:\n         r, g, b, a = tuple(\n             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255\n-            for i in match.group(1).split(','))\n+            for i in match.group(1).strip().split(','))\n         return (r, g, b, a * 255 * opacity)\n \n     match = RGB.search(string)\n     if match:\n         r, g, b = tuple(\n             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255\n-            for i in match.group(1).split(','))\n+            for i in match.group(1).strip().split(','))\n         return (r, g, b, opacity)\n \n     match = HEX_RRGGBB.search(string)"}}, "prior_version": "     'transparent': (0, 0, 0, 0), }  RGBA = re.compile(r'rgba\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)') RGB = re.compile(r'rgb\\([ \\n\\r\\t]*(.+?)[ \\n\\r\\t]*\\)') HEX_RRGGBB = re.compile('#[0-9a-f]{6}') HEX_RGB = re.compile('#[0-9a-f]{3}')  def color(string, opacity=1):     if match:         r, g, b, a = tuple(             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255             for i in match.group(1).split(','))         return (r, g, b, a * 255 * opacity)      match = RGB.search(string)     if match:         r, g, b = tuple(             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255             for i in match.group(1).split(','))         return (r, g, b, opacity)      match = HEX_RRGGBB.search(string)", "after_version": "     'transparent': (0, 0, 0, 0), }  RGBA = re.compile(r'rgba\\((.+?)\\)') RGB = re.compile(r'rgb\\((.+?)\\)') HEX_RRGGBB = re.compile('#[0-9a-f]{6}') HEX_RGB = re.compile('#[0-9a-f]{3}')  def color(string, opacity=1):     if match:         r, g, b, a = tuple(             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255             for i in match.group(1).strip().split(','))         return (r, g, b, a * 255 * opacity)      match = RGB.search(string)     if match:         r, g, b = tuple(             float(i.strip(' %')) / 100 if '%' in i else float(i) / 255             for i in match.group(1).strip().split(','))         return (r, g, b, opacity)      match = HEX_RRGGBB.search(string)", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-hwv5-w8gm-fq9f", "cwe_id": "{'CWE-22'}", "score": 3.5, "chain": "{'https://github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75'}", "dataset": "osv", "summary": "Directory Traversal vulnerability in GET/PUT allows attackers to Disclose Information or Write Files via a crafted GET/PUT request ### Impact\n\n#### Information Disclosure\n\nWhen the GET method is attacked, attackers can read files which have a `.data` suffix and which are accompanied by a JSON file with the `.meta` suffix. This can lead to Information Disclosure and in some shared-hosting scenarios also to circumvention of authentication or other limitations on the outbound (GET) traffic.\n\nFor example, in a scenario where a single server has multiple instances of the application running (with separate DATA_ROOT settings), an attacker who has knowledge about the directory structure is able to read files from any other instance to which the process has read access.\n\nIf instances have individual authentication (for example, HTTP authentication via a reverse proxy, source IP based filtering) or other restrictions (such as quotas), attackers may circumvent those limits in such a scenario by using the Directory Traversal to retrieve data from the other instances.\n\n#### File Write\n\nIf the associated XMPP server (or anyone knowing the SECRET_KEY) is malicious, they can write files outside the DATA_ROOT. The files which are written are constrained to have the `.meta` and the `.data` suffixes; the `.meta` file will contain the JSON with the Content-Type of the original request and the `.data` file will contain the payload.\n\n### Patches\n\nPR #12 fixes the issue. The PR has been merged into version 0.4.0 and 0.4.0 has been released and pushed to PyPI. Users are advised to upgrade immediately.\n\n### Workarounds\n\n- Apache can apparently be configured to filter such malicious paths when reverse-proxying. \n- There are no other workarounds known.\n\n### References\n\n- [Pull Request #12](https://github.com/horazont/xmpp-http-upload/pull/12)", "published_date": "2020-10-06", "chain_len": 1, "project": "https://github.com/horazont/xmpp-http-upload", "commit_href": "https://github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75", "commit_sha": "82056540191e89f0cd697c81f57714c00962ed75", "patch": "SINGLE", "chain_ord": "['82056540191e89f0cd697c81f57714c00962ed75']", "before_first_fix_commit": "{'f0fc7443c06a0e8aecb5696fc2bd513a2cc8b611'}", "last_fix_commit": "82056540191e89f0cd697c81f57714c00962ed75", "chain_ord_pos": 1, "commit_datetime": "10/05/2020, 23:06:21", "message": "Simplify path handling, use safe_join\n\nThe current implementation of sanitized_join did not handle\n\"..\" properly. The problem is, that .absolute() does not do\nwhat .resolve() does, but .resolve() does not work on non\nexistant paths.\n\nAnyway, flask has a function exactly for this: safe_join.\n\nSo let's use that one.\n\nWhile at it, simplified the whole path handling a bit.", "author": "Christian Tacke", "comments": null, "stats": "{'additions': 15, 'deletions': 34, 'total': 49}", "files": {"xhu.py": {"additions": 15, "deletions": 34, "changes": 49, "status": "modified", "raw_url": "https://github.com/horazont/xmpp-http-upload/raw/82056540191e89f0cd697c81f57714c00962ed75/xhu.py", "patch": "@@ -29,6 +29,7 @@\n import typing\n \n import flask\n+import werkzeug.exceptions\n \n app = flask.Flask(\"xmpp-http-upload\")\n app.config.from_envvar(\"XMPP_HTTP_UPLOAD_CONFIG\")\n@@ -39,16 +40,11 @@\n     CORS(app)\n \n \n-def sanitized_join(path: str, root: pathlib.Path) -> pathlib.Path:\n-    result = (root / path).absolute()\n-    if not str(result).startswith(str(root) + \"/\"):\n-        raise ValueError(\"resulting path is outside root\")\n-    return result\n-\n-\n-def get_paths(base_path: pathlib.Path):\n-    data_file = pathlib.Path(str(base_path) + \".data\")\n-    metadata_file = pathlib.Path(str(base_path) + \".meta\")\n+def get_paths(root: str, sub_path: str) \\\n+        -> typing.Tuple[pathlib.Path, pathlib.Path]:\n+    base_path = flask.safe_join(root, sub_path)\n+    data_file = pathlib.Path(base_path + \".data\")\n+    metadata_file = pathlib.Path(base_path + \".meta\")\n \n     return data_file, metadata_file\n \n@@ -58,15 +54,10 @@ def load_metadata(metadata_file):\n         return json.load(f)\n \n \n-def get_info(path: str, root: pathlib.Path) -> typing.Tuple[\n+def get_info(path: str) -> typing.Tuple[\n         pathlib.Path,\n         dict]:\n-    dest_path = sanitized_join(\n-        path,\n-        pathlib.Path(app.config[\"DATA_ROOT\"]),\n-    )\n-\n-    data_file, metadata_file = get_paths(dest_path)\n+    data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\n \n     return data_file, load_metadata(metadata_file)\n \n@@ -104,11 +95,8 @@ def stream_file(src, dest, nbytes):\n @app.route(\"/<path:path>\", methods=[\"PUT\"])\n def put_file(path):\n     try:\n-        dest_path = sanitized_join(\n-            path,\n-            pathlib.Path(app.config[\"DATA_ROOT\"]),\n-        )\n-    except ValueError:\n+        data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\n+    except werkzeug.exceptions.NotFound:\n         return flask.Response(\n             \"Not Found\",\n             404,\n@@ -134,8 +122,7 @@ def put_file(path):\n         \"application/octet-stream\",\n     )\n \n-    dest_path.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\n-    data_file, metadata_file = get_paths(dest_path)\n+    data_file.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\n \n     try:\n         with write_file(data_file) as fout:\n@@ -189,13 +176,10 @@ def generate_headers(response_headers, metadata_headers):\n @app.route(\"/<path:path>\", methods=[\"HEAD\"])\n def head_file(path):\n     try:\n-        data_file, metadata = get_info(\n-            path,\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\n-        )\n+        data_file, metadata = get_info(path)\n \n         stat = data_file.stat()\n-    except (OSError, ValueError):\n+    except (OSError, werkzeug.exceptions.NotFound):\n         return flask.Response(\n             \"Not Found\",\n             404,\n@@ -214,11 +198,8 @@ def head_file(path):\n @app.route(\"/<path:path>\", methods=[\"GET\"])\n def get_file(path):\n     try:\n-        data_file, metadata = get_info(\n-            path,\n-            pathlib.Path(app.config[\"DATA_ROOT\"])\n-        )\n-    except (OSError, ValueError):\n+        data_file, metadata = get_info(path)\n+    except (OSError, werkzeug.exceptions.NotFound):\n         return flask.Response(\n             \"Not Found\",\n             404,"}}, "prior_version": " import typing  import flask  app = flask.Flask(\"xmpp-http-upload\") app.config.from_envvar(\"XMPP_HTTP_UPLOAD_CONFIG\")     CORS(app)   def sanitized_join(path: str, root: pathlib.Path) -> pathlib.Path:     result = (root / path).absolute()     if not str(result).startswith(str(root) + \"/\"):         raise ValueError(\"resulting path is outside root\")     return result   def get_paths(base_path: pathlib.Path):     data_file = pathlib.Path(str(base_path) + \".data\")     metadata_file = pathlib.Path(str(base_path) + \".meta\")      return data_file, metadata_file  def load_metadata(metadata_file):         return json.load(f)   def get_info(path: str, root: pathlib.Path) -> typing.Tuple[         pathlib.Path,         dict]:     dest_path = sanitized_join(         path,         pathlib.Path(app.config[\"DATA_ROOT\"]),     )      data_file, metadata_file = get_paths(dest_path)      return data_file, load_metadata(metadata_file)  def stream_file(src, dest, nbytes): @app.route(\"/<path:path>\", methods=[\"PUT\"]) def put_file(path):     try:         dest_path = sanitized_join(             path,             pathlib.Path(app.config[\"DATA_ROOT\"]),         )     except ValueError:         return flask.Response(             \"Not Found\",             404, def put_file(path):         \"application/octet-stream\",     )      dest_path.parent.mkdir(parents=True, exist_ok=True, mode=0o770)     data_file, metadata_file = get_paths(dest_path)      try:         with write_file(data_file) as fout: def generate_headers(response_headers, metadata_headers): @app.route(\"/<path:path>\", methods=[\"HEAD\"]) def head_file(path):     try:         data_file, metadata = get_info(             path,             pathlib.Path(app.config[\"DATA_ROOT\"])         )          stat = data_file.stat()     except (OSError, ValueError):         return flask.Response(             \"Not Found\",             404, def head_file(path): @app.route(\"/<path:path>\", methods=[\"GET\"]) def get_file(path):     try:         data_file, metadata = get_info(             path,             pathlib.Path(app.config[\"DATA_ROOT\"])         )     except (OSError, ValueError):         return flask.Response(             \"Not Found\",             404,", "after_version": " import typing  import flask import werkzeug.exceptions  app = flask.Flask(\"xmpp-http-upload\") app.config.from_envvar(\"XMPP_HTTP_UPLOAD_CONFIG\")     CORS(app)   def get_paths(root: str, sub_path: str) \\         -> typing.Tuple[pathlib.Path, pathlib.Path]:     base_path = flask.safe_join(root, sub_path)     data_file = pathlib.Path(base_path + \".data\")     metadata_file = pathlib.Path(base_path + \".meta\")      return data_file, metadata_file  def load_metadata(metadata_file):         return json.load(f)   def get_info(path: str) -> typing.Tuple[         pathlib.Path,         dict]:     data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)      return data_file, load_metadata(metadata_file)  def stream_file(src, dest, nbytes): @app.route(\"/<path:path>\", methods=[\"PUT\"]) def put_file(path):     try:         data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)     except werkzeug.exceptions.NotFound:         return flask.Response(             \"Not Found\",             404, def put_file(path):         \"application/octet-stream\",     )      data_file.parent.mkdir(parents=True, exist_ok=True, mode=0o770)      try:         with write_file(data_file) as fout: def generate_headers(response_headers, metadata_headers): @app.route(\"/<path:path>\", methods=[\"HEAD\"]) def head_file(path):     try:         data_file, metadata = get_info(path)          stat = data_file.stat()     except (OSError, werkzeug.exceptions.NotFound):         return flask.Response(             \"Not Found\",             404, def head_file(path): @app.route(\"/<path:path>\", methods=[\"GET\"]) def get_file(path):     try:         data_file, metadata = get_info(path)     except (OSError, werkzeug.exceptions.NotFound):         return flask.Response(             \"Not Found\",             404,", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-j7c4-2xj8-wm7r", "cwe_id": "{'CWE-20'}", "score": 7.5, "chain": "{'https://github.com/latchset/kdcproxy/commit/f274aa6787cb8b3ec1cc12c440a56665b7231882'}", "dataset": "osv", "summary": "Moderate severity vulnerability that affects kdcproxy python-kdcproxy before 0.3.2 allows remote attackers to cause a denial of service via a large POST request.", "published_date": "2018-11-01", "chain_len": 1, "project": "https://github.com/latchset/kdcproxy", "commit_href": "https://github.com/latchset/kdcproxy/commit/f274aa6787cb8b3ec1cc12c440a56665b7231882", "commit_sha": "f274aa6787cb8b3ec1cc12c440a56665b7231882", "patch": "SINGLE", "chain_ord": "['f274aa6787cb8b3ec1cc12c440a56665b7231882']", "before_first_fix_commit": "{'e4a71193099cd395578bcf32f4eb8beaa7da3e43'}", "last_fix_commit": "f274aa6787cb8b3ec1cc12c440a56665b7231882", "chain_ord_pos": 1, "commit_datetime": "08/03/2015, 18:38:49", "message": "Enforce a maximum packet length\n\nPermanently fixes CVE-2015-5159 for all applications.", "author": "Nathaniel McCallum", "comments": null, "stats": "{'additions': 6, 'deletions': 1, 'total': 7}", "files": {"kdcproxy/__init__.py": {"additions": 6, "deletions": 1, "changes": 7, "status": "modified", "raw_url": "https://github.com/latchset/kdcproxy/raw/f274aa6787cb8b3ec1cc12c440a56665b7231882/kdcproxy%2F__init__.py", "patch": "@@ -61,6 +61,7 @@ def __str__(self):\n \n \n class Application:\n+    MAX_LENGTH = 128 * 1024\n     SOCKTYPES = {\n         \"tcp\": socket.SOCK_STREAM,\n         \"udp\": socket.SOCK_DGRAM,\n@@ -180,7 +181,11 @@ def __call__(self, env, start_response):\n             try:\n                 length = int(env[\"CONTENT_LENGTH\"])\n             except AttributeError:\n-                length = -1\n+                raise HTTPException(411, \"Length required.\")\n+            if length < 0:\n+                raise HTTPException(411, \"Length required.\")\n+            if length > self.MAX_LENGTH:\n+                raise HTTPException(413, \"Request entity too large.\")\n             try:\n                 pr = codec.decode(env[\"wsgi.input\"].read(length))\n             except codec.ParsingError as e:"}}, "prior_version": " def __str__(self):   class Application:     SOCKTYPES = {         \"tcp\": socket.SOCK_STREAM,         \"udp\": socket.SOCK_DGRAM, def __call__(self, env, start_response):             try:                 length = int(env[\"CONTENT_LENGTH\"])             except AttributeError:                 length = -1             try:                 pr = codec.decode(env[\"wsgi.input\"].read(length))             except codec.ParsingError as e:", "after_version": " def __str__(self):   class Application:     MAX_LENGTH = 128 * 1024     SOCKTYPES = {         \"tcp\": socket.SOCK_STREAM,         \"udp\": socket.SOCK_DGRAM, def __call__(self, env, start_response):             try:                 length = int(env[\"CONTENT_LENGTH\"])             except AttributeError:                 raise HTTPException(411, \"Length required.\")             if length < 0:                 raise HTTPException(411, \"Length required.\")             if length > self.MAX_LENGTH:                 raise HTTPException(413, \"Request entity too large.\")             try:                 pr = codec.decode(env[\"wsgi.input\"].read(length))             except codec.ParsingError as e:", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "GHSA-mq5p-2mcr-m52j", "cwe_id": "{'CWE-94'}", "score": 0.0, "chain": "{'https://github.com/jupyterhub/nbgitpuller/commit/07690644f29a566011dd0d7ba14cae3eb0490481'}", "dataset": "osv", "summary": "Code injection in nbgitpuller ### Impact\n\nDue to an unsanitized input, visiting maliciously crafted links could result in arbitrary code execution in the user environment.\n\n### Patches\n\n0.10.2\n\n### Workarounds\n\nNone, other than upgrade to 0.10.2 or downgrade to 0.8.x.\n\n\n### For more information\n\nIf you have any questions or comments about this advisory:\n\n* Open an issue in [nbgitpuller](https://github.com/jupyterhub/nbgitpuller/issues)\n* Email our security team at [security@ipython.org](mailto:security@ipython.org)", "published_date": "2021-08-30", "chain_len": 1, "project": "https://github.com/jupyterhub/nbgitpuller", "commit_href": "https://github.com/jupyterhub/nbgitpuller/commit/07690644f29a566011dd0d7ba14cae3eb0490481", "commit_sha": "07690644f29a566011dd0d7ba14cae3eb0490481", "patch": "SINGLE", "chain_ord": "['07690644f29a566011dd0d7ba14cae3eb0490481']", "before_first_fix_commit": "{'f25d3f2685035c11bd668d48e71caf4fc245ba68', '2cad6147f1769a962f8d0733045967663add53cb'}", "last_fix_commit": "07690644f29a566011dd0d7ba14cae3eb0490481", "chain_ord_pos": 1, "commit_datetime": "08/25/2021, 12:23:02", "message": "Merge pull request from GHSA-mq5p-2mcr-m52j\n\nmake positional args explicit", "author": "Erik Sundell", "comments": null, "stats": "{'additions': 4, 'deletions': 4, 'total': 8}", "files": {"nbgitpuller/pull.py": {"additions": 4, "deletions": 4, "changes": 8, "status": "modified", "raw_url": "https://github.com/jupyterhub/nbgitpuller/raw/07690644f29a566011dd0d7ba14cae3eb0490481/nbgitpuller%2Fpull.py", "patch": "@@ -88,13 +88,13 @@ def branch_exists(self, branch):\n         \"\"\"\n         try:\n             heads = subprocess.run(\n-                [\"git\", \"ls-remote\", \"--heads\", self.git_url],\n+                [\"git\", \"ls-remote\", \"--heads\", \"--\", self.git_url],\n                 capture_output=True,\n                 text=True,\n                 check=True\n             )\n             tags = subprocess.run(\n-                [\"git\", \"ls-remote\", \"--tags\", self.git_url],\n+                [\"git\", \"ls-remote\", \"--tags\", \"--\", self.git_url],\n                 capture_output=True,\n                 text=True,\n                 check=True\n@@ -118,7 +118,7 @@ def resolve_default_branch(self):\n         \"\"\"\n         try:\n             head_branch = subprocess.run(\n-                [\"git\", \"ls-remote\", \"--symref\", self.git_url, \"HEAD\"],\n+                [\"git\", \"ls-remote\", \"--symref\", \"--\", self.git_url, \"HEAD\"],\n                 capture_output=True,\n                 text=True,\n                 check=True\n@@ -154,7 +154,7 @@ def initialize_repo(self):\n         if self.depth and self.depth > 0:\n             clone_args.extend(['--depth', str(self.depth)])\n         clone_args.extend(['--branch', self.branch_name])\n-        clone_args.extend([self.git_url, self.repo_dir])\n+        clone_args.extend([\"--\", self.git_url, self.repo_dir])\n         yield from execute_cmd(clone_args)\n         logging.info('Repo {} initialized'.format(self.repo_dir))"}}, "prior_version": " def branch_exists(self, branch):         \"\"\"         try:             heads = subprocess.run(                 [\"git\", \"ls-remote\", \"--heads\", self.git_url],                 capture_output=True,                 text=True,                 check=True             )             tags = subprocess.run(                 [\"git\", \"ls-remote\", \"--tags\", self.git_url],                 capture_output=True,                 text=True,                 check=True def resolve_default_branch(self):         \"\"\"         try:             head_branch = subprocess.run(                 [\"git\", \"ls-remote\", \"--symref\", self.git_url, \"HEAD\"],                 capture_output=True,                 text=True,                 check=True def initialize_repo(self):         if self.depth and self.depth > 0:             clone_args.extend(['--depth', str(self.depth)])         clone_args.extend(['--branch', self.branch_name])         clone_args.extend([self.git_url, self.repo_dir])         yield from execute_cmd(clone_args)         logging.info('Repo {} initialized'.format(self.repo_dir)) ", "after_version": " def branch_exists(self, branch):         \"\"\"         try:             heads = subprocess.run(                 [\"git\", \"ls-remote\", \"--heads\", \"--\", self.git_url],                 capture_output=True,                 text=True,                 check=True             )             tags = subprocess.run(                 [\"git\", \"ls-remote\", \"--tags\", \"--\", self.git_url],                 capture_output=True,                 text=True,                 check=True def resolve_default_branch(self):         \"\"\"         try:             head_branch = subprocess.run(                 [\"git\", \"ls-remote\", \"--symref\", \"--\", self.git_url, \"HEAD\"],                 capture_output=True,                 text=True,                 check=True def initialize_repo(self):         if self.depth and self.depth > 0:             clone_args.extend(['--depth', str(self.depth)])         clone_args.extend(['--branch', self.branch_name])         clone_args.extend([\"--\", self.git_url, self.repo_dir])         yield from execute_cmd(clone_args)         logging.info('Repo {} initialized'.format(self.repo_dir)) ", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "GHSA-mr7p-25v2-35wr", "cwe_id": "{'CWE-22'}", "score": 7.5, "chain": "{'https://github.com/nltk/nltk/commit/f59d7ed8df2e0e957f7f247fe218032abdbe9a10'}", "dataset": "osv", "summary": "Path Traversal in nltk NLTK Downloader before 3.4.5 is vulnerable to a directory traversal, allowing attackers to write arbitrary files via a ../ (dot dot slash) in an NLTK package (ZIP archive) that is mishandled during extraction.", "published_date": "2019-08-23", "chain_len": 1, "project": "https://github.com/nltk/nltk", "commit_href": "https://github.com/nltk/nltk/commit/f59d7ed8df2e0e957f7f247fe218032abdbe9a10", "commit_sha": "f59d7ed8df2e0e957f7f247fe218032abdbe9a10", "patch": "SINGLE", "chain_ord": "['f59d7ed8df2e0e957f7f247fe218032abdbe9a10']", "before_first_fix_commit": "{'2554ff48feed878ba7e830ada9825196f3eaa86a'}", "last_fix_commit": "f59d7ed8df2e0e957f7f247fe218032abdbe9a10", "chain_ord_pos": 1, "commit_datetime": "08/20/2019, 10:35:00", "message": "CVE-2019-14751:\nFixed security bug in downloader\n(https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-14751)", "author": "Steven Bird", "comments": "{'com_1': {'author': 'greysteil', 'datetime': '08/26/2019, 11:01:35', 'body': \"Thanks for this @stevenbird, and for all your work on `nltk`.\\r\\n\\r\\nHave you got 5 minutes to talk me through the process you went through fixing this, and any way GitHub can help? I'm on GitHub's security team and am working to make it easier for maintainers to alert users of security vulnerabilities.\\r\\n\\r\\nCurrently we have the security alert emails (which we're working to improve) and Security Advisories (the security tab on this repo). In future we're planning to make it easy for maintainers to apply for CVEs through GitHub (via creating Security Advisories).\\r\\n\\r\\nWas there any part of the flow of finding, fixing, and alerting users of this vulnerability that GitHub could have helped with? Or anything we're doing now that you'd like us to do differently?\\r\\n\\r\\nAny feedback very much appreciated. I'm on greysteil@github.com if you'd rather email it privately.\\r\\n\\r\\nThanks for all your do, and please don't hesitate to reach out if there's ever any way GitHub can help.\"}}", "stats": "{'additions': 1, 'deletions': 35, 'total': 36}", "files": {"nltk/downloader.py": {"additions": 1, "deletions": 35, "changes": 36, "status": "modified", "raw_url": "https://github.com/nltk/nltk/raw/f59d7ed8df2e0e957f7f247fe218032abdbe9a10/nltk%2Fdownloader.py", "patch": "@@ -2260,42 +2260,8 @@ def _unzip_iter(filename, root, verbose=True):\n         yield ErrorMessage(filename, e)\n         return\n \n-    # Get lists of directories & files\n-    namelist = zf.namelist()\n-    dirlist = set()\n-    for x in namelist:\n-        if x.endswith('/'):\n-            dirlist.add(x)\n-        else:\n-            dirlist.add(x.rsplit('/', 1)[0] + '/')\n-    filelist = [x for x in namelist if not x.endswith('/')]\n-\n-    # Create the target directory if it doesn't exist\n-    if not os.path.exists(root):\n-        os.mkdir(root)\n-\n-    # Create the directory structure\n-    for dirname in sorted(dirlist):\n-        pieces = dirname[:-1].split('/')\n-        for i in range(len(pieces)):\n-            dirpath = os.path.join(root, *pieces[: i + 1])\n-            if not os.path.exists(dirpath):\n-                os.mkdir(dirpath)\n-\n-    # Extract files.\n-    for i, filename in enumerate(filelist):\n-        filepath = os.path.join(root, *filename.split('/'))\n-\n-        try:\n-            with open(filepath, 'wb') as dstfile, zf.open(filename) as srcfile:\n-                shutil.copyfileobj(srcfile, dstfile)\n-        except Exception as e:\n-            yield ErrorMessage(filename, e)\n-            return\n+    zf.extractall(root)\n \n-        if verbose and (i * 10 / len(filelist) > (i - 1) * 10 / len(filelist)):\n-            sys.stdout.write('.')\n-            sys.stdout.flush()\n     if verbose:\n         print()"}}, "prior_version": " def _unzip_iter(filename, root, verbose=True):         yield ErrorMessage(filename, e)         return      # Get lists of directories & files     namelist = zf.namelist()     dirlist = set()     for x in namelist:         if x.endswith('/'):             dirlist.add(x)         else:             dirlist.add(x.rsplit('/', 1)[0] + '/')     filelist = [x for x in namelist if not x.endswith('/')]      # Create the target directory if it doesn't exist     if not os.path.exists(root):         os.mkdir(root)      # Create the directory structure     for dirname in sorted(dirlist):         pieces = dirname[:-1].split('/')         for i in range(len(pieces)):             dirpath = os.path.join(root, *pieces[: i + 1])             if not os.path.exists(dirpath):                 os.mkdir(dirpath)      # Extract files.     for i, filename in enumerate(filelist):         filepath = os.path.join(root, *filename.split('/'))          try:             with open(filepath, 'wb') as dstfile, zf.open(filename) as srcfile:                 shutil.copyfileobj(srcfile, dstfile)         except Exception as e:             yield ErrorMessage(filename, e)             return          if verbose and (i * 10 / len(filelist) > (i - 1) * 10 / len(filelist)):             sys.stdout.write('.')             sys.stdout.flush()     if verbose:         print() ", "after_version": " def _unzip_iter(filename, root, verbose=True):         yield ErrorMessage(filename, e)         return      zf.extractall(root)      if verbose:         print() ", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-qh9q-34h6-hcv9", "cwe_id": "{'CWE-12', 'CWE-22'}", "score": 7.5, "chain": "{'https://github.com/mkdocs/mkdocs/pull/2604/commits/cddc453c9d49298e60e7d56fb71130c151cbcbe5'}", "dataset": "osv", "summary": "Directory traversal in mkdocs The mkdocs 1.2.2 built-in dev-server allows directory traversal using the port 8000, enabling remote exploitation to obtain :sensitive information.", "published_date": "2021-10-12", "chain_len": 1, "project": "https://github.com/mkdocs/mkdocs", "commit_href": "https://github.com/mkdocs/mkdocs/pull/2604/commits/cddc453c9d49298e60e7d56fb71130c151cbcbe5", "commit_sha": "cddc453c9d49298e60e7d56fb71130c151cbcbe5", "patch": "SINGLE", "chain_ord": "['cddc453c9d49298e60e7d56fb71130c151cbcbe5']", "before_first_fix_commit": "{'c426455878556baa34cc829c579337236d335581'}", "last_fix_commit": "cddc453c9d49298e60e7d56fb71130c151cbcbe5", "chain_ord_pos": 1, "commit_datetime": "10/10/2021, 08:52:05", "message": "Prevent directory traversal in the dev server", "author": "Oleh Prypin", "comments": null, "stats": "{'additions': 4, 'deletions': 1, 'total': 5}", "files": {"mkdocs/livereload/__init__.py": {"additions": 4, "deletions": 1, "changes": 5, "status": "modified", "raw_url": "https://github.com/mkdocs/mkdocs/raw/cddc453c9d49298e60e7d56fb71130c151cbcbe5/mkdocs%2Flivereload%2F__init__.py", "patch": "@@ -4,6 +4,7 @@\n import mimetypes\n import os\n import os.path\n+import posixpath\n import re\n import socketserver\n import threading\n@@ -183,9 +184,11 @@ def condition():\n         if path == \"/js/livereload.js\":\n             file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"livereload.js\")\n         elif path.startswith(self.mount_path):\n-            rel_file_path = path[len(self.mount_path):].lstrip(\"/\")\n+            rel_file_path = path[len(self.mount_path):]\n             if path.endswith(\"/\"):\n                 rel_file_path += \"index.html\"\n+            # Prevent directory traversal - normalize the path.\n+            rel_file_path = posixpath.normpath(\"/\" + rel_file_path).lstrip(\"/\")\n             file_path = os.path.join(self.root, rel_file_path)\n         elif path == \"/\":\n             start_response(\"302 Found\", [(\"Location\", self.mount_path)])"}}, "prior_version": " import mimetypes import os import os.path import re import socketserver import threading def condition():         if path == \"/js/livereload.js\":             file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"livereload.js\")         elif path.startswith(self.mount_path):             rel_file_path = path[len(self.mount_path):].lstrip(\"/\")             if path.endswith(\"/\"):                 rel_file_path += \"index.html\"             file_path = os.path.join(self.root, rel_file_path)         elif path == \"/\":             start_response(\"302 Found\", [(\"Location\", self.mount_path)])", "after_version": " import mimetypes import os import os.path import posixpath import re import socketserver import threading def condition():         if path == \"/js/livereload.js\":             file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"livereload.js\")         elif path.startswith(self.mount_path):             rel_file_path = path[len(self.mount_path):]             if path.endswith(\"/\"):                 rel_file_path += \"index.html\"             # Prevent directory traversal - normalize the path.             rel_file_path = posixpath.normpath(\"/\" + rel_file_path).lstrip(\"/\")             file_path = os.path.join(self.root, rel_file_path)         elif path == \"/\":             start_response(\"302 Found\", [(\"Location\", self.mount_path)])", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-qhmp-h54x-38qr", "cwe_id": "{'CWE-400'}", "score": 7.5, "chain": "{'https://github.com/caronc/apprise/commit/e20fce630d55e4ca9b0a1e325a5fea6997489831'}", "dataset": "osv", "summary": "CWE-730 Regex injection with IFTTT Plugin ### Impact\r\nAnyone _publicly_ hosting the Apprise library and granting them access to the IFTTT notification service.\r\n\r\n### Patches\r\nUpdate to Apprise v0.9.5.1\r\n   ```bash\r\n   # Install Apprise v0.9.5.1 from PyPI\r\n   pip install apprise==0.9.5.1\r\n   ```\r\n\r\nThe patch to the problem was performed [here](https://github.com/caronc/apprise/pull/436/files).\r\n\r\n### Workarounds\r\nAlternatively, if upgrading is not an option, you can safely remove the following file:\r\n- `apprise/plugins/NotifyIFTTT.py` \r\n\r\nThe above will eliminate the ability to use IFTTT, but everything else will work smoothly.\r\n\r\n### For more information\r\nIf you have any questions or comments about this advisory:\r\n* Open an issue in [Apprise](https://github.com/caronc/apprise/issues)\r\n* Email me at [lead2gold@gmail.com](mailto:lead2gold@gmail.com)\r\n\r\n### Additional Credit\r\nGithub would not allow me to additionally credit **Rasmus Petersen**, but I would like to put that here at the very least - thank you for finding and reporting this issue along with those already credited\r\n\r\n## Additional Notes:\r\n- Github would not allow me to add/tag the 2 CWE's this issue is applicable to (only CWE-400).  The other is: CWE-730 (placed in the title)", "published_date": "2021-09-20", "chain_len": 1, "project": "https://github.com/caronc/apprise", "commit_href": "https://github.com/caronc/apprise/commit/e20fce630d55e4ca9b0a1e325a5fea6997489831", "commit_sha": "e20fce630d55e4ca9b0a1e325a5fea6997489831", "patch": "SINGLE", "chain_ord": "['e20fce630d55e4ca9b0a1e325a5fea6997489831']", "before_first_fix_commit": "{'81d1ea72bcee4441278a809a95fc0f91dc916402'}", "last_fix_commit": "e20fce630d55e4ca9b0a1e325a5fea6997489831", "chain_ord_pos": 1, "commit_datetime": "09/06/2021, 17:51:32", "message": "Slight bulletproofing to IFTTT regex handling (#436)", "author": "Chris Caron", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"apprise/plugins/NotifyIFTTT.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/caronc/apprise/raw/e20fce630d55e4ca9b0a1e325a5fea6997489831/apprise%2Fplugins%2FNotifyIFTTT.py", "patch": "@@ -355,7 +355,7 @@ def parse_native_url(url):\n         result = re.match(\n             r'^https?://maker\\.ifttt\\.com/use/'\n             r'(?P<webhook_id>[A-Z0-9_-]+)'\n-            r'/?(?P<events>([A-Z0-9_-]+/?)+)?'\n+            r'((?P<events>(/[A-Z0-9_-]+)+))?'\n             r'/?(?P<params>\\?.+)?$', url, re.I)\n \n         if result:"}}, "prior_version": " def parse_native_url(url):         result = re.match(             r'^https?://maker\\.ifttt\\.com/use/'             r'(?P<webhook_id>[A-Z0-9_-]+)'             r'/?(?P<events>([A-Z0-9_-]+/?)+)?'             r'/?(?P<params>\\?.+)?$', url, re.I)          if result:", "after_version": " def parse_native_url(url):         result = re.match(             r'^https?://maker\\.ifttt\\.com/use/'             r'(?P<webhook_id>[A-Z0-9_-]+)'             r'((?P<events>(/[A-Z0-9_-]+)+))?'             r'/?(?P<params>\\?.+)?$', url, re.I)          if result:", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "GHSA-rhq2-3vr9-6mcr", "cwe_id": "{'CWE-22'}", "score": 8.3, "chain": "{'https://github.com/gradio-app/gradio/commit/41bd3645bdb616e1248b2167ca83636a2653f781'}", "dataset": "osv", "summary": "Files on the host computer can be accessed from the Gradio interface ### Impact\nThis is a vulnerability that affects anyone who creates and publicly shares Gradio interfaces using `gradio<2.4.8`. Because of the way that static files were being served, someone who generated a public Gradio link and shared it with others would potentially be exposing the files on the computer that generated the link, while the link was active. An attacker would be able to view the contents of a file on the computer if they knew the exact relative filepath. We do not have any evidence that this was ever exploited, but we treated the issue seriously and immediately took steps to mitigate it (see below)\n\n### Response\n1. We worked with @haby0 to immediately patch the issue and released a new version, `gradio 2.5.0`, within 24 hours of the issue being brought to our attention \n2. We enabled a notification that is printed to anyone using an older version of gradio telling them to upgrade (see screenshot below)\n3. We expanded our test suite to test for this vulnerability ensuring that our patch does not get reverted in future releases of `gradio`\n\n![image](https://user-images.githubusercontent.com/1778297/146251425-f36b519b-6d4a-4dfb-8d89-c1ed005979d3.png)\n\n### Patches\nThe problem has been patched in `gradio>=2.5.0`.", "published_date": "2022-01-21", "chain_len": 1, "project": "https://github.com/gradio-app/gradio", "commit_href": "https://github.com/gradio-app/gradio/commit/41bd3645bdb616e1248b2167ca83636a2653f781", "commit_sha": "41bd3645bdb616e1248b2167ca83636a2653f781", "patch": "SINGLE", "chain_ord": "['41bd3645bdb616e1248b2167ca83636a2653f781']", "before_first_fix_commit": "{'0b2c4901a63b2e5a7d7b3964d27b8f82d6d330e1'}", "last_fix_commit": "41bd3645bdb616e1248b2167ca83636a2653f781", "chain_ord_pos": 1, "commit_datetime": "12/14/2021, 21:01:55", "message": "secure path hotfix", "author": "Ali Abid", "comments": null, "stats": "{'additions': 2, 'deletions': 3, 'total': 5}", "files": {"gradio/networking.py": {"additions": 2, "deletions": 3, "changes": 5, "status": "modified", "raw_url": "https://github.com/gradio-app/gradio/raw/41bd3645bdb616e1248b2167ca83636a2653f781/gradio%2Fnetworking.py", "patch": "@@ -377,15 +377,14 @@ def interpret():\n @app.route(\"/file/<path:path>\", methods=[\"GET\"])\n @login_check\n def file(path):\n-    path = secure_filename(path)\n     if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):\n-        with open(os.path.join(app.cwd, path), \"rb\") as encrypted_file:\n+        with open(safe_join(app.cwd, path), \"rb\") as encrypted_file:\n             encrypted_data = encrypted_file.read()\n         file_data = encryptor.decrypt(\n             app.interface.encryption_key, encrypted_data)\n         return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))\n     else:\n-        return send_file(os.path.join(app.cwd, path))\n+        return send_file(safe_join(app.cwd, path))\n \n \n @app.route(\"/api/queue/push/\", methods=[\"POST\"])"}}, "prior_version": " def interpret(): @app.route(\"/file/<path:path>\", methods=[\"GET\"]) @login_check def file(path):     path = secure_filename(path)     if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):         with open(os.path.join(app.cwd, path), \"rb\") as encrypted_file:             encrypted_data = encrypted_file.read()         file_data = encryptor.decrypt(             app.interface.encryption_key, encrypted_data)         return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))     else:         return send_file(os.path.join(app.cwd, path))   @app.route(\"/api/queue/push/\", methods=[\"POST\"])", "after_version": " def interpret(): @app.route(\"/file/<path:path>\", methods=[\"GET\"]) @login_check def file(path):     if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):         with open(safe_join(app.cwd, path), \"rb\") as encrypted_file:             encrypted_data = encrypted_file.read()         file_data = encryptor.decrypt(             app.interface.encryption_key, encrypted_data)         return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))     else:         return send_file(safe_join(app.cwd, path))   @app.route(\"/api/queue/push/\", methods=[\"POST\"])", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "GHSA-vfrc-ggmc-5jwv", "cwe_id": "{'CWE-79'}", "score": 8.8, "chain": "{'https://github.com/django-helpdesk/django-helpdesk/commit/04483bdac3b5196737516398b5ce0383875a5c60'}", "dataset": "osv", "summary": "Cross-site Scripting in django-helpdesk django-helpdesk is vulnerable to Improper Neutralization of Input During Web Page Generation ('Cross-site Scripting')", "published_date": "2021-11-23", "chain_len": 1, "project": "https://github.com/django-helpdesk/django-helpdesk", "commit_href": "https://github.com/django-helpdesk/django-helpdesk/commit/04483bdac3b5196737516398b5ce0383875a5c60", "commit_sha": "04483bdac3b5196737516398b5ce0383875a5c60", "patch": "SINGLE", "chain_ord": "['04483bdac3b5196737516398b5ce0383875a5c60']", "before_first_fix_commit": "{'2c7065e0c4296e0c692fb4a7ee19c7357583af30'}", "last_fix_commit": "04483bdac3b5196737516398b5ce0383875a5c60", "chain_ord_pos": 1, "commit_datetime": "11/18/2021, 03:42:02", "message": "Add `att.full_clean()` before saving\n\nFix issue https://github.com/django-helpdesk/django-helpdesk/issues/983\r\nAlso, fix bug stored XSS disclosure: https://huntr.dev/bounties/4d7a5fdd-b2de-467a-ade0-3f2fb386638e/", "author": "lethanhphuc", "comments": null, "stats": "{'additions': 1, 'deletions': 0, 'total': 1}", "files": {"helpdesk/lib.py": {"additions": 1, "deletions": 0, "changes": 1, "status": "modified", "raw_url": "https://github.com/django-helpdesk/django-helpdesk/raw/04483bdac3b5196737516398b5ce0383875a5c60/helpdesk%2Flib.py", "patch": "@@ -145,6 +145,7 @@ def process_attachments(followup, attached_files):\n                 'application/octet-stream',\n                 size=attached.size,\n             )\n+            att.full_clean()\n             att.save()\n \n             if attached.size < max_email_attachment_size:"}}, "prior_version": " def process_attachments(followup, attached_files):                 'application/octet-stream',                 size=attached.size,             )             att.save()              if attached.size < max_email_attachment_size:", "after_version": " def process_attachments(followup, attached_files):                 'application/octet-stream',                 size=attached.size,             )             att.full_clean()             att.save()              if attached.size < max_email_attachment_size:", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "GHSA-x7r7-wmj8-vv5g", "cwe_id": "{'CWE-79'}", "score": 7.5, "chain": "{'https://github.com/octoprint/octoprint/commit/8087528e4a7ddd15c7d95ff662deb5ef7de90045'}", "dataset": "osv", "summary": "Cross-site Scripting in OctoPrint Cross-site Scripting (XSS) - DOM in GitHub repository octoprint/octoprint prior to 1.8.0. The login endpoint allows for javascript injection which may lead to account takeover in a phishing scenario.", "published_date": "2022-05-19", "chain_len": 1, "project": "https://github.com/octoprint/octoprint", "commit_href": "https://github.com/octoprint/octoprint/commit/8087528e4a7ddd15c7d95ff662deb5ef7de90045", "commit_sha": "8087528e4a7ddd15c7d95ff662deb5ef7de90045", "patch": "SINGLE", "chain_ord": "['8087528e4a7ddd15c7d95ff662deb5ef7de90045']", "before_first_fix_commit": "{'700034d028ff3518b563a7b4ba4dacc920142d07'}", "last_fix_commit": "8087528e4a7ddd15c7d95ff662deb5ef7de90045", "chain_ord_pos": 1, "commit_datetime": "05/11/2022, 11:02:52", "message": "\ud83d\udd12\ufe0f Sanitize and validate login redirect\n\nFixes an XSS and an open redirect issue.", "author": "Gina H\u00e4u\u00dfge", "comments": null, "stats": "{'additions': 11, 'deletions': 1, 'total': 12}", "files": {"src/octoprint/server/views.py": {"additions": 11, "deletions": 1, "changes": 12, "status": "modified", "raw_url": "https://github.com/OctoPrint/OctoPrint/raw/8087528e4a7ddd15c7d95ff662deb5ef7de90045/src%2Foctoprint%2Fserver%2Fviews.py", "patch": "@@ -8,6 +8,7 @@\n import os\n import re\n from collections import defaultdict\n+from urllib.parse import urlparse\n \n from flask import (\n     Response,\n@@ -170,7 +171,16 @@ def _add_additional_assets(hook):\n def login():\n     from flask_login import current_user\n \n-    redirect_url = request.args.get(\"redirect\", request.script_root + url_for(\"index\"))\n+    default_redirect_url = request.script_root + url_for(\"index\")\n+    redirect_url = request.args.get(\"redirect\", default_redirect_url)\n+\n+    parsed = urlparse(redirect_url)  # check if redirect url is valid\n+    if parsed.scheme != \"\" or parsed.netloc != \"\":\n+        _logger.warning(\n+            f\"Got an invalid redirect URL with the login attempt, misconfiguration or attack attempt: {redirect_url}\"\n+        )\n+        redirect_url = default_redirect_url\n+\n     permissions = sorted(\n         filter(\n             lambda x: x is not None and isinstance(x, OctoPrintPermission),"}}, "prior_version": " import os import re from collections import defaultdict  from flask import (     Response, def _add_additional_assets(hook): def login():     from flask_login import current_user      redirect_url = request.args.get(\"redirect\", request.script_root + url_for(\"index\"))     permissions = sorted(         filter(             lambda x: x is not None and isinstance(x, OctoPrintPermission),", "after_version": " import os import re from collections import defaultdict from urllib.parse import urlparse  from flask import (     Response, def _add_additional_assets(hook): def login():     from flask_login import current_user      default_redirect_url = request.script_root + url_for(\"index\")     redirect_url = request.args.get(\"redirect\", default_redirect_url)      parsed = urlparse(redirect_url)  # check if redirect url is valid     if parsed.scheme != \"\" or parsed.netloc != \"\":         _logger.warning(             f\"Got an invalid redirect URL with the login attempt, misconfiguration or attack attempt: {redirect_url}\"         )         redirect_url = default_redirect_url      permissions = sorted(         filter(             lambda x: x is not None and isinstance(x, OctoPrintPermission),", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2012-3366", "cwe_id": "{'CWE-78'}", "score": 10.0, "chain": "{'https://github.com/Bcfg2/bcfg2/commit/a524967e8d5c4c22e49cd619aed20c87a316c0be'}", "dataset": "nvd", "summary": "The Trigger plugin in bcfg2 1.2.x before 1.2.3 allows remote attackers with root access to the client to execute arbitrary commands via shell metacharacters in the UUID field to the server process (bcfg2-server).", "published_date": "2012-07-03", "chain_len": 1, "project": "https://github.com/Bcfg2/bcfg2", "commit_href": "https://github.com/Bcfg2/bcfg2/commit/a524967e8d5c4c22e49cd619aed20c87a316c0be", "commit_sha": "a524967e8d5c4c22e49cd619aed20c87a316c0be", "patch": "SINGLE", "chain_ord": "['a524967e8d5c4c22e49cd619aed20c87a316c0be']", "before_first_fix_commit": "{'503ea9de36d74ac6d7ad564d04a923a016592ccd'}", "last_fix_commit": "a524967e8d5c4c22e49cd619aed20c87a316c0be", "chain_ord_pos": 1, "commit_datetime": "06/12/2012, 13:20:10", "message": "fixed major security flaw in Trigger plugin", "author": "Chris St. Pierre", "comments": null, "stats": "{'additions': 25, 'deletions': 15, 'total': 40}", "files": {"src/lib/Server/Plugins/Trigger.py": {"additions": 25, "deletions": 15, "changes": 40, "status": "modified", "raw_url": "https://github.com/Bcfg2/bcfg2/raw/a524967e8d5c4c22e49cd619aed20c87a316c0be/src%2Flib%2FServer%2FPlugins%2FTrigger.py", "patch": "@@ -1,17 +1,7 @@\n import os\n+import pipes\n import Bcfg2.Server.Plugin\n-\n-\n-def async_run(prog, args):\n-    pid = os.fork()\n-    if pid:\n-        os.waitpid(pid, 0)\n-    else:\n-        dpid = os.fork()\n-        if not dpid:\n-            os.system(\" \".join([prog] + args))\n-        os._exit(0)\n-\n+from subprocess import Popen, PIPE\n \n class Trigger(Bcfg2.Server.Plugin.Plugin,\n               Bcfg2.Server.Plugin.Statistics):\n@@ -30,15 +20,35 @@ def __init__(self, core, datastore):\n                               \"unloading\" % self.data)\n             raise Bcfg2.Server.Plugin.PluginInitError\n \n+    def async_run(self, args):\n+        pid = os.fork()\n+        if pid:\n+            os.waitpid(pid, 0)\n+        else:\n+            dpid = os.fork()\n+            if not dpid:\n+                self.debug_log(\"Running %s\" % \" \".join(pipes.quote(a)\n+                                                       for a in args))\n+                proc = Popen(args, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n+                (out, err) = proc.communicate()\n+                rv = proc.wait()\n+                if rv != 0:\n+                    self.logger.error(\"Trigger: Error running %s (%s): %s\" %\n+                                      (args[0], rv, err))\n+                elif err:\n+                    self.debug_log(\"Trigger: Error: %s\" % err)\n+            os._exit(0)\n+\n     def process_statistics(self, metadata, _):\n         args = [metadata.hostname, '-p', metadata.profile, '-g',\n                 ':'.join([g for g in metadata.groups])]\n+        self.debug_log(\"running triggers\")\n         for notifier in os.listdir(self.data):\n+            self.debug_log(\"running %s\" % notifier)\n             if ((notifier[-1] == '~') or\n                 (notifier[:2] == '.#') or\n                 (notifier[-4:] == '.swp') or\n                 (notifier in ['SCCS', '.svn', '4913'])):\n                 continue\n-            npath = self.data + '/' + notifier\n-            self.logger.debug(\"Running %s %s\" % (npath, \" \".join(args)))\n-            async_run(npath, args)\n+            npath = os.path.join(self.data, notifier)\n+            self.async_run([npath] + args)"}}, "prior_version": " import os import Bcfg2.Server.Plugin   def async_run(prog, args):     pid = os.fork()     if pid:         os.waitpid(pid, 0)     else:         dpid = os.fork()         if not dpid:             os.system(\" \".join([prog] + args))         os._exit(0)   class Trigger(Bcfg2.Server.Plugin.Plugin,               Bcfg2.Server.Plugin.Statistics): def __init__(self, core, datastore):                               \"unloading\" % self.data)             raise Bcfg2.Server.Plugin.PluginInitError      def process_statistics(self, metadata, _):         args = [metadata.hostname, '-p', metadata.profile, '-g',                 ':'.join([g for g in metadata.groups])]         for notifier in os.listdir(self.data):             if ((notifier[-1] == '~') or                 (notifier[:2] == '.#') or                 (notifier[-4:] == '.swp') or                 (notifier in ['SCCS', '.svn', '4913'])):                 continue             npath = self.data + '/' + notifier             self.logger.debug(\"Running %s %s\" % (npath, \" \".join(args)))             async_run(npath, args)", "after_version": " import os import pipes import Bcfg2.Server.Plugin from subprocess import Popen, PIPE  class Trigger(Bcfg2.Server.Plugin.Plugin,               Bcfg2.Server.Plugin.Statistics): def __init__(self, core, datastore):                               \"unloading\" % self.data)             raise Bcfg2.Server.Plugin.PluginInitError      def async_run(self, args):         pid = os.fork()         if pid:             os.waitpid(pid, 0)         else:             dpid = os.fork()             if not dpid:                 self.debug_log(\"Running %s\" % \" \".join(pipes.quote(a)                                                        for a in args))                 proc = Popen(args, stdin=PIPE, stdout=PIPE, stderr=PIPE)                 (out, err) = proc.communicate()                 rv = proc.wait()                 if rv != 0:                     self.logger.error(\"Trigger: Error running %s (%s): %s\" %                                       (args[0], rv, err))                 elif err:                     self.debug_log(\"Trigger: Error: %s\" % err)             os._exit(0)      def process_statistics(self, metadata, _):         args = [metadata.hostname, '-p', metadata.profile, '-g',                 ':'.join([g for g in metadata.groups])]         self.debug_log(\"running triggers\")         for notifier in os.listdir(self.data):             self.debug_log(\"running %s\" % notifier)             if ((notifier[-1] == '~') or                 (notifier[:2] == '.#') or                 (notifier[-4:] == '.swp') or                 (notifier in ['SCCS', '.svn', '4913'])):                 continue             npath = os.path.join(self.data, notifier)             self.async_run([npath] + args)", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2012-3371", "cwe_id": "{'CWE-20'}", "score": 2.9, "chain": "{'https://github.com/openstack/nova/commit/034762e8060dcf0a11cb039b9d426b0d0bb1801d'}", "dataset": "nvd", "summary": "The Nova scheduler in OpenStack Compute (Nova) Folsom (2012.2) and Essex (2012.1), when DifferentHostFilter or SameHostFilter is enabled, allows remote authenticated users to cause a denial of service (excessive database lookup calls and server hang) via a request with many repeated IDs in the os:scheduler_hints section.", "published_date": "2012-07-17", "chain_len": 1, "project": "https://github.com/openstack/nova", "commit_href": "https://github.com/openstack/nova/commit/034762e8060dcf0a11cb039b9d426b0d0bb1801d", "commit_sha": "034762e8060dcf0a11cb039b9d426b0d0bb1801d", "patch": "SINGLE", "chain_ord": "['034762e8060dcf0a11cb039b9d426b0d0bb1801d']", "before_first_fix_commit": "{'b91d2fc02d927066ed0fe21439ccb7548de4138f'}", "last_fix_commit": "034762e8060dcf0a11cb039b9d426b0d0bb1801d", "chain_ord_pos": 1, "commit_datetime": "06/26/2012, 16:44:35", "message": "Use compute_api.get_all in affinity filters.\n\nUpdates the affinity filters so they make a single compute API\ncall to lookup instance host information rather than single\nlookups for each UUID.\n\nThis resolves a potential performance issue which can cause a\nscheduler to hang while processing requests which contain large numbers\nof UUID's in the scheduler_hints.\n\nFixes LP Bug #1017795.\n\nChange-Id: I30f434faf109058573ee41c4a6abce2e48939e8d", "author": "Dan Prince", "comments": null, "stats": "{'additions': 9, 'deletions': 4, 'total': 13}", "files": {"nova/scheduler/filters/affinity_filter.py": {"additions": 9, "deletions": 4, "changes": 13, "status": "modified", "raw_url": "https://github.com/openstack/nova/raw/034762e8060dcf0a11cb039b9d426b0d0bb1801d/nova%2Fscheduler%2Ffilters%2Faffinity_filter.py", "patch": "@@ -25,8 +25,11 @@ class AffinityFilter(filters.BaseHostFilter):\n     def __init__(self):\n         self.compute_api = compute.API()\n \n-    def _affinity_host(self, context, instance_id):\n-        return self.compute_api.get(context, instance_id)['host']\n+    def _all_hosts(self, context):\n+        all_hosts = {}\n+        for instance in self.compute_api.get_all(context):\n+            all_hosts[instance['uuid']] = instance['host']\n+        return all_hosts\n \n \n class DifferentHostFilter(AffinityFilter):\n@@ -41,8 +44,9 @@ def host_passes(self, host_state, filter_properties):\n         if isinstance(affinity_uuids, basestring):\n             affinity_uuids = [affinity_uuids]\n         if affinity_uuids:\n+            all_hosts = self._all_hosts(context)\n             return not any([i for i in affinity_uuids\n-                              if self._affinity_host(context, i) == me])\n+                              if all_hosts.get(i) == me])\n         # With no different_host key\n         return True\n \n@@ -61,9 +65,10 @@ def host_passes(self, host_state, filter_properties):\n         if isinstance(affinity_uuids, basestring):\n             affinity_uuids = [affinity_uuids]\n         if affinity_uuids:\n+            all_hosts = self._all_hosts(context)\n             return any([i for i\n                           in affinity_uuids\n-                          if self._affinity_host(context, i) == me])\n+                          if all_hosts.get(i) == me])\n         # With no same_host key\n         return True"}}, "prior_version": " class AffinityFilter(filters.BaseHostFilter):     def __init__(self):         self.compute_api = compute.API()      def _affinity_host(self, context, instance_id):         return self.compute_api.get(context, instance_id)['host']   class DifferentHostFilter(AffinityFilter): def host_passes(self, host_state, filter_properties):         if isinstance(affinity_uuids, basestring):             affinity_uuids = [affinity_uuids]         if affinity_uuids:             return not any([i for i in affinity_uuids                               if self._affinity_host(context, i) == me])         # With no different_host key         return True  def host_passes(self, host_state, filter_properties):         if isinstance(affinity_uuids, basestring):             affinity_uuids = [affinity_uuids]         if affinity_uuids:             return any([i for i                           in affinity_uuids                           if self._affinity_host(context, i) == me])         # With no same_host key         return True ", "after_version": " class AffinityFilter(filters.BaseHostFilter):     def __init__(self):         self.compute_api = compute.API()      def _all_hosts(self, context):         all_hosts = {}         for instance in self.compute_api.get_all(context):             all_hosts[instance['uuid']] = instance['host']         return all_hosts   class DifferentHostFilter(AffinityFilter): def host_passes(self, host_state, filter_properties):         if isinstance(affinity_uuids, basestring):             affinity_uuids = [affinity_uuids]         if affinity_uuids:             all_hosts = self._all_hosts(context)             return not any([i for i in affinity_uuids                               if all_hosts.get(i) == me])         # With no different_host key         return True  def host_passes(self, host_state, filter_properties):         if isinstance(affinity_uuids, basestring):             affinity_uuids = [affinity_uuids]         if affinity_uuids:             all_hosts = self._all_hosts(context)             return any([i for i                           in affinity_uuids                           if all_hosts.get(i) == me])         # With no same_host key         return True ", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "CVE-2012-3540", "cwe_id": "{'CWE-20'}", "score": 4.9, "chain": "{'https://github.com/openstack/horizon/commit/35eada8a27323c0f83c400177797927aba6bc99b'}", "dataset": "nvd", "summary": "Open redirect vulnerability in views/auth_forms.py in OpenStack Dashboard (Horizon) Essex (2012.1) allows remote attackers to redirect users to arbitrary web sites and conduct phishing attacks via a URL in the next parameter to auth/login/.  NOTE: this issue was originally assigned CVE-2012-3542 by mistake.", "published_date": "2012-09-05", "chain_len": 1, "project": "https://github.com/openstack/horizon", "commit_href": "https://github.com/openstack/horizon/commit/35eada8a27323c0f83c400177797927aba6bc99b", "commit_sha": "35eada8a27323c0f83c400177797927aba6bc99b", "patch": "SINGLE", "chain_ord": "['35eada8a27323c0f83c400177797927aba6bc99b']", "before_first_fix_commit": "{'648b07895c3e09218e165ec0f61bca7e3d6eb691'}", "last_fix_commit": "35eada8a27323c0f83c400177797927aba6bc99b", "chain_ord_pos": 1, "commit_datetime": "08/22/2012, 19:15:40", "message": "Fix open redirect in Horizon.\n\nLP 1039077. Disallow login redirects to anywhere other than the same origin.\n\nChange-Id: I36e8e4f30cf440ecc73534af38fcd8d2a111a603", "author": "Paul McMillan", "comments": null, "stats": "{'additions': 8, 'deletions': 1, 'total': 9}", "files": {"horizon/views/auth_forms.py": {"additions": 8, "deletions": 1, "changes": 9, "status": "modified", "raw_url": "https://github.com/openstack/horizon/raw/35eada8a27323c0f83c400177797927aba6bc99b/horizon%2Fviews%2Fauth_forms.py", "patch": "@@ -28,6 +28,7 @@\n from django.conf import settings\n from django.contrib import messages\n from django.contrib.auth import REDIRECT_FIELD_NAME\n+from django.utils.http import same_origin\n from django.utils.translation import ugettext as _\n from keystoneclient import exceptions as keystone_exceptions\n \n@@ -94,7 +95,13 @@ def handle(self, request, data):\n         request.session['region_endpoint'] = endpoint\n         request.session['region_name'] = region_name\n \n-        redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, \"\")\n+        redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, None)\n+        # Make sure the requested redirect matches the protocol,\n+        # domain, and port of this request\n+        if redirect_to and not same_origin(\n+                request.build_absolute_uri(redirect_to),\n+                request.build_absolute_uri()):\n+            redirect_to = None\n \n         if data.get('tenant', None):\n             try:"}}, "prior_version": " from django.conf import settings from django.contrib import messages from django.contrib.auth import REDIRECT_FIELD_NAME from django.utils.translation import ugettext as _ from keystoneclient import exceptions as keystone_exceptions  def handle(self, request, data):         request.session['region_endpoint'] = endpoint         request.session['region_name'] = region_name          redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, \"\")          if data.get('tenant', None):             try:", "after_version": " from django.conf import settings from django.contrib import messages from django.contrib.auth import REDIRECT_FIELD_NAME from django.utils.http import same_origin from django.utils.translation import ugettext as _ from keystoneclient import exceptions as keystone_exceptions  def handle(self, request, data):         request.session['region_endpoint'] = endpoint         request.session['region_name'] = region_name          redirect_to = request.REQUEST.get(REDIRECT_FIELD_NAME, None)         # Make sure the requested redirect matches the protocol,         # domain, and port of this request         if redirect_to and not same_origin(                 request.build_absolute_uri(redirect_to),                 request.build_absolute_uri()):             redirect_to = None          if data.get('tenant', None):             try:", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "CVE-2013-2006", "cwe_id": "{'CWE-200'}", "score": 2.9, "chain": "{'https://github.com/openstack/keystone/commit/c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd'}", "dataset": "nvd", "summary": "OpenStack Identity (Keystone) Grizzly 2013.1.1, when DEBUG mode logging is enabled, logs the (1) admin_token and (2) LDAP password in plaintext, which allows local users to obtain sensitive by reading the log file.", "published_date": "2013-05-21", "chain_len": 1, "project": "https://github.com/openstack/keystone", "commit_href": "https://github.com/openstack/keystone/commit/c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd", "commit_sha": "c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd", "patch": "SINGLE", "chain_ord": "['c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd']", "before_first_fix_commit": "{'5929850979b0ccf348c1b913961d581ccac9732c'}", "last_fix_commit": "c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd", "chain_ord_pos": 1, "commit_datetime": "04/12/2013, 08:19:37", "message": "Mark LDAP password and admin_token secret\n\nAdd secret=True to LDAP password and admin_token\nof keystone configuration.\n\nFix bug #1172195\n\nChange-Id: I8ef7f705e3f6b374ff427c20eb761892d5146a75\n(cherry picked from commit d43e2a51a1ed7adbed3c5ddf001d46bc4a824ae8)", "author": "Xuhan Peng", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"keystone/common/config.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/openstack/keystone/raw/c5037dd6b82909efaaa8720e8cfa8bdb8b4a0edd/keystone%2Fcommon%2Fconfig.py", "patch": "@@ -188,7 +188,7 @@ def configure():\n     register_cli_str('pydev-debug-host', default=None)\n     register_cli_int('pydev-debug-port', default=None)\n \n-    register_str('admin_token', default='ADMIN')\n+    register_str('admin_token', secret=True, default='ADMIN')\n     register_str('bind_host', default='0.0.0.0')\n     register_int('compute_port', default=8774)\n     register_int('admin_port', default=35357)\n@@ -271,7 +271,7 @@ def configure():\n     # ldap\n     register_str('url', group='ldap', default='ldap://localhost')\n     register_str('user', group='ldap', default=None)\n-    register_str('password', group='ldap', default=None)\n+    register_str('password', group='ldap', secret=True, default=None)\n     register_str('suffix', group='ldap', default='cn=example,cn=com')\n     register_bool('use_dumb_member', group='ldap', default=False)\n     register_str('dumb_member', group='ldap', default='cn=dumb,dc=nonexistent')"}}, "prior_version": " def configure():     register_cli_str('pydev-debug-host', default=None)     register_cli_int('pydev-debug-port', default=None)      register_str('admin_token', default='ADMIN')     register_str('bind_host', default='0.0.0.0')     register_int('compute_port', default=8774)     register_int('admin_port', default=35357) def configure():     # ldap     register_str('url', group='ldap', default='ldap://localhost')     register_str('user', group='ldap', default=None)     register_str('password', group='ldap', default=None)     register_str('suffix', group='ldap', default='cn=example,cn=com')     register_bool('use_dumb_member', group='ldap', default=False)     register_str('dumb_member', group='ldap', default='cn=dumb,dc=nonexistent')", "after_version": " def configure():     register_cli_str('pydev-debug-host', default=None)     register_cli_int('pydev-debug-port', default=None)      register_str('admin_token', secret=True, default='ADMIN')     register_str('bind_host', default='0.0.0.0')     register_int('compute_port', default=8774)     register_int('admin_port', default=35357) def configure():     # ldap     register_str('url', group='ldap', default='ldap://localhost')     register_str('user', group='ldap', default=None)     register_str('password', group='ldap', secret=True, default=None)     register_str('suffix', group='ldap', default='cn=example,cn=com')     register_bool('use_dumb_member', group='ldap', default=False)     register_str('dumb_member', group='ldap', default='cn=dumb,dc=nonexistent')", "file_extension": "py", "cwe": "CWE-200"}
{"vuln_id": "CVE-2017-5938", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad'}", "dataset": "nvd", "summary": "Cross-site scripting (XSS) vulnerability in the nav_path function in lib/viewvc.py in ViewVC before 1.0.14 and 1.1.x before 1.1.26 allows remote attackers to inject arbitrary web script or HTML via the nav_data name.", "published_date": "2017-03-15", "chain_len": 1, "project": "https://github.com/viewvc/viewvc", "commit_href": "https://github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad", "commit_sha": "9dcfc7daa4c940992920d3b2fbd317da20e44aad", "patch": "SINGLE", "chain_ord": "['9dcfc7daa4c940992920d3b2fbd317da20e44aad']", "before_first_fix_commit": "{'8507aa4e745e4cf5cac811ccb6d2fbf768bb9cba'}", "last_fix_commit": "9dcfc7daa4c940992920d3b2fbd317da20e44aad", "chain_ord_pos": 1, "commit_datetime": "01/24/2017, 20:39:56", "message": "Escape some raw path data before handing off to templates\n\n* lib/viewvc.py\n  (nav_path): Escape the 'name' property of navigation path components\n    the same way we escape that of the 'root' path component.\n\nReported by: Thomas Gerbet <thomas.gerbet@enalean.com>", "author": "C. Michael Pilato", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"lib/viewvc.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/viewvc/viewvc/raw/9dcfc7daa4c940992920d3b2fbd317da20e44aad/lib%2Fviewvc.py", "patch": "@@ -980,7 +980,7 @@ def nav_path(request):\n     path_parts.append(part)\n     is_last = len(path_parts) == len(request.path_parts)\n \n-    item = _item(name=part, href=None)\n+    item = _item(name=request.server.escape(part), href=None)\n \n     if not is_last or (is_dir and request.view_func is not view_directory):\n       item.href = request.get_url(view_func=view_directory,"}}, "prior_version": " def nav_path(request):     path_parts.append(part)     is_last = len(path_parts) == len(request.path_parts)      item = _item(name=part, href=None)      if not is_last or (is_dir and request.view_func is not view_directory):       item.href = request.get_url(view_func=view_directory,", "after_version": " def nav_path(request):     path_parts.append(part)     is_last = len(path_parts) == len(request.path_parts)      item = _item(name=request.server.escape(part), href=None)      if not is_last or (is_dir and request.view_func is not view_directory):       item.href = request.get_url(view_func=view_directory,", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2017-7572", "cwe_id": "{'CWE-362'}", "score": 10.0, "chain": "{'https://github.com/bit-team/backintime/commit/7f208dc547f569b689c888103e3b593a48cd1869'}", "dataset": "nvd", "summary": "The _checkPolkitPrivilege function in serviceHelper.py in Back In Time (aka backintime) 1.1.18 and earlier uses a deprecated polkit authorization method (unix-process) that is subject to a race condition (time of check, time of use). With this authorization method, the owner of a process requesting a polkit operation is checked by polkitd via /proc/<pid>/status, by which time the requesting process may have been replaced by a different process with the same PID that has different privileges then the original requester.", "published_date": "2017-04-06", "chain_len": 1, "project": "https://github.com/bit-team/backintime", "commit_href": "https://github.com/bit-team/backintime/commit/7f208dc547f569b689c888103e3b593a48cd1869", "commit_sha": "7f208dc547f569b689c888103e3b593a48cd1869", "patch": "SINGLE", "chain_ord": "['7f208dc547f569b689c888103e3b593a48cd1869']", "before_first_fix_commit": "{'c689a4d815ce3ba2c212a42f777a1ca4727f473b'}", "last_fix_commit": "7f208dc547f569b689c888103e3b593a48cd1869", "chain_ord_pos": 1, "commit_datetime": "04/05/2017, 11:57:59", "message": "polkit CheckAuthorization: fix race condition in privilege authorization\n\nThe unix-process authorization subject is deprecated:\n\nhttps://www.freedesktop.org/software/polkit/docs/latest/PolkitUnixProcess.html#polkit-unix-process-new\n\nas it is subject to a race condition. A client process requesting\nauthorization can replace itself by a suid or otherwise root owned\nexecutable, thus granting the original non-privileged request\nprivileges.\n\nSee also:\n\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1002375\nhttps://github.com/Kabot/Unix-Privilege-Escalation-Exploits-Pack/blob/master/2011/CVE-2011-1485/polkit-pwnage.c\n\nPolkit uses the real-uid of the process by now, thus mitigating the\nexploit using suid binaries. It is still possible, however, to exit the\nclient process and try to get a root program to get the same PID.\n\nIn worst case this would allow an unauthenticated user to get backintime\nor some other program to be executed via udev rules as root user.", "author": "Matthias Gerstner", "comments": "{'com_1': {'author': 'carnil', 'datetime': '04/07/2017, 10:33:47', 'body': '[CVE-2017-7572](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-7572)'}}", "stats": "{'additions': 1, 'deletions': 7, 'total': 8}", "files": {"qt/serviceHelper.py": {"additions": 1, "deletions": 7, "changes": 8, "status": "modified", "raw_url": "https://github.com/bit-team/backintime/raw/7f208dc547f569b689c888103e3b593a48cd1869/qt%2FserviceHelper.py", "patch": "@@ -282,18 +282,12 @@ def _checkPolkitPrivilege(self, sender, conn, privilege):\n             # bus, and it does not make sense to restrict operations here\n             return\n \n-        info = SenderInfo(sender, conn)\n-\n-        # get peer PID\n-        pid = info.connectionPid()\n-\n         # query PolicyKit\n         self._initPolkit()\n         try:\n             # we don't need is_challenge return here, since we call with AllowUserInteraction\n             (is_auth, _, details) = self.polkit.CheckAuthorization(\n-                    ('unix-process', {'pid': dbus.UInt32(pid, variant_level=1),\n-                    'start-time': dbus.UInt64(0, variant_level=1)}),\n+                    ('system-bus-name', {'name': dbus.String(sender, variant_level=1)}),\n                     privilege, {'': ''}, dbus.UInt32(1), '', timeout=3000)\n         except dbus.DBusException as e:\n             if e._dbus_error_name == 'org.freedesktop.DBus.Error.ServiceUnknown':"}}, "prior_version": " def _checkPolkitPrivilege(self, sender, conn, privilege):             # bus, and it does not make sense to restrict operations here             return          info = SenderInfo(sender, conn)          # get peer PID         pid = info.connectionPid()          # query PolicyKit         self._initPolkit()         try:             # we don't need is_challenge return here, since we call with AllowUserInteraction             (is_auth, _, details) = self.polkit.CheckAuthorization(                     ('unix-process', {'pid': dbus.UInt32(pid, variant_level=1),                     'start-time': dbus.UInt64(0, variant_level=1)}),                     privilege, {'': ''}, dbus.UInt32(1), '', timeout=3000)         except dbus.DBusException as e:             if e._dbus_error_name == 'org.freedesktop.DBus.Error.ServiceUnknown':", "after_version": " def _checkPolkitPrivilege(self, sender, conn, privilege):             # bus, and it does not make sense to restrict operations here             return          # query PolicyKit         self._initPolkit()         try:             # we don't need is_challenge return here, since we call with AllowUserInteraction             (is_auth, _, details) = self.polkit.CheckAuthorization(                     ('system-bus-name', {'name': dbus.String(sender, variant_level=1)}),                     privilege, {'': ''}, dbus.UInt32(1), '', timeout=3000)         except dbus.DBusException as e:             if e._dbus_error_name == 'org.freedesktop.DBus.Error.ServiceUnknown':", "file_extension": "py", "cwe": "CWE-362"}
{"vuln_id": "CVE-2018-1000070", "cwe_id": "{'CWE-94'}", "score": 6.4, "chain": "{'https://github.com/Bitmessage/PyBitmessage/commit/3a8016d31f517775d226aa8b902480f4a3a148a9'}", "dataset": "nvd", "summary": "Bitmessage PyBitmessage version v0.6.2 (and introduced in or after commit 8ce72d8d2d25973b7064b1cf76a6b0b3d62f0ba0) contains a Eval injection vulnerability in main program, file src/messagetypes/__init__.py function constructObject that can result in Code Execution. This attack appears to be exploitable via remote attacker using a malformed message which must be processed by the victim - e.g. arrive from any sender on bitmessage network. This vulnerability appears to have been fixed in v0.6.3.", "published_date": "2018-03-13", "chain_len": 1, "project": "https://github.com/Bitmessage/PyBitmessage", "commit_href": "https://github.com/Bitmessage/PyBitmessage/commit/3a8016d31f517775d226aa8b902480f4a3a148a9", "commit_sha": "3a8016d31f517775d226aa8b902480f4a3a148a9", "patch": "SINGLE", "chain_ord": "['3a8016d31f517775d226aa8b902480f4a3a148a9']", "before_first_fix_commit": "{'96ea36cfd245f7dc10209b01278b5fa2970f360c'}", "last_fix_commit": "3a8016d31f517775d226aa8b902480f4a3a148a9", "chain_ord_pos": 1, "commit_datetime": "02/13/2018, 15:39:35", "message": "Fix message encoding bug\n\n- prevent loading invalid message types", "author": "Peter Surda", "comments": "{'com_1': {'author': 'PeterSurda', 'datetime': '02/13/2018, 16:30:49', 'body': \"It's allows a remote execution, but it probably crashed for most people before it could execute anything. In the logs I see attempts to run a windows executable and to steal electrum wallet files.\"}, 'com_2': {'author': 'rfreemobile', 'datetime': '02/13/2018, 18:44:46', 'body': '@PeterSurda god damn. Using eval() should be illegal by law.\\r\\n\\r\\nThis is used in encode() ... but still it is called on the data coming from network then? \\r\\n\\r\\nRequesting CVE number for it? Remote arbitrary code execution in widely used application...'}, 'com_3': {'author': 'copumpkin', 'datetime': '02/13/2018, 21:07:56', 'body': \"This still doesn't feel ideal. Although it isn't arbitrary code anymore, you still let untrusted data specify which method to call on an object. Is this a temporary fix or the final one?\"}, 'com_4': {'author': 'PeterSurda', 'datetime': '02/13/2018, 21:31:49', 'body': \"I am open for suggestions on how to improve it. I haven't build the binaries yet, possibly I'll release 0.6.3.1 with an improved fix, but I had to move quickly.\"}, 'com_5': {'author': 'copumpkin', 'datetime': '02/13/2018, 21:39:16', 'body': \"I'd probably assert that `title()` is one of the known/expected values before invoking it, or something like that. In the longer run, it's probably better to make it a more formal message parser: see langsec/weird machines and so on: http://langsec.org/\"}, 'com_6': {'author': 'tintinweb', 'datetime': '02/13/2018, 21:48:30', 'body': 'yeah as @copumpkin mentioned this could need some input validation.\\r\\n\\r\\nand maybe also check the [other evals](https://github.com/Bitmessage/PyBitmessage/blob/fd1a6c1fa14ab719f43d97ad52f464826fb32b4c/src/bitmessagecli.py#L379)? Usually there is not many reasons to use eval.'}, 'com_7': {'author': 'copumpkin', 'datetime': '02/13/2018, 22:00:26', 'body': \"Yeah, `eval` is a huge no-no in security-sensitive software (so all of it, really). In some cases the input might effectively be trusted, but it's easier to just outlaw `eval` so people don't have to stare extra hard at code using it to make sure it's not stupid.\"}, 'com_8': {'author': 'g1itch', 'datetime': '02/13/2018, 22:23:43', 'body': 'Did someone used message type `Vote` ever? @copumpkin [title()](https://docs.python.org/2.7/library/stdtypes.html#str.title), if you have no such file or no such class in it - it will be ignored.'}, 'com_9': {'author': 'copumpkin', 'datetime': '02/13/2018, 22:30:43', 'body': \"Oh, I'm sorry, I misunderstood what was going on. It still seems good to explicitly validate this sort of thing. If only so that future readers can see when behavior like this changes, and can be sure that it's actually running against an explicitly defined message schema rather than relying on reflective behavior against a living codebase.\"}, 'com_10': {'author': 'PeterSurda', 'datetime': '02/13/2018, 22:37:03', 'body': '@g1itch vote doesn\\'t really do anything, it\\'s an example.\\r\\n\\r\\n@copumpkin I\\'ll restrict extended encoding to \"message\" type for the time being, it can be loosened later after a more thorough review.'}, 'com_11': {'author': 'tigusoft', 'datetime': '02/13/2018, 23:07:36', 'body': '@PeterSurda @rfree-d \\r\\napplied for CVE, seems bug was first in tagged version v0.6.2 and now fixed in v0.6.3\\r\\n\\r\\nhttps://docs.google.com/spreadsheets/d/1PlDOsZ4Q36JU4Dz9zyBB2F3814dScppCRCe1muCT7JI/edit#gid=1009122160\\r\\n\\r\\n(search \"bitmessage\")'}, 'com_12': {'author': 'PeterSurda', 'datetime': '02/13/2018, 23:20:22', 'body': 'Thank you.'}, 'com_13': {'author': 'celmar01', 'datetime': '02/15/2018, 01:33:45', 'body': '\ud83d\udc4d'}, 'com_14': {'author': 'ValdikSS', 'datetime': '02/15/2018, 07:25:25', 'body': 'To prevent serious damage from such kind of vulnerabilities, you should write SELinux/AppArmor/Firejail profiles and bundle it with the application.'}, 'com_15': {'author': 'PeterSurda', 'datetime': '02/15/2018, 10:03:26', 'body': \"I'll be happy to accept pull requests for security profiles.\"}, 'com_16': {'author': 'KOLANICH', 'datetime': '02/15/2018, 20:11:44', 'body': \"@PeterSurda, I wanna know how this have happened that such a backdory function like `eval` have appeared in such a security-critical application as bitmessage. I wanna know which measures are you going to take to make this kind of backdoors never appear again.\\r\\n\\r\\nIMHO at least we need a blacklist of functions which must not be used in bm and any of it dependencies. All the PRs using them must be automatically rejected. All the PR's introducing new dependencies must be rejected. Dependencies and all their dependencies must be checked and forked and freezed and installed only from this project's repos, not from pip. Only after creating an own fork of dependencies which involves manual checking a dependency may be used.\\r\\n\\r\\nI also have some ideas about building security into python interpreter, I'm currently trying to convert my thoughts into a document.\"}, 'com_17': {'author': 'PeterSurda', 'datetime': '02/15/2018, 21:21:26', 'body': '@KOLANICH You can apply for an audit/hardening job: #1136'}, 'com_18': {'author': 'PeterSurda', 'datetime': '02/15/2018, 21:25:42', 'body': '@KOLANICH And the bug appeared because I am a guy who decided to take care of an abandoned project that I found very important not realising the huge scope of such an endeavor. Luckily there are more contributors in the meantime who do review my code, and the workflow has slightly improved.'}, 'com_19': {'author': 'tigusoft', 'datetime': '02/25/2018, 20:17:52', 'body': 'CVE is assigned: CVE-2018-1000070 (still not published, just reserved)\\r\\n\\r\\nhttps://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-1000070'}, 'com_20': {'author': 'PeterSurda', 'datetime': '03/14/2018, 09:39:36', 'body': 'CVE published.'}, 'com_21': {'author': 'sigoa', 'datetime': '03/18/2018, 14:21:57', 'body': '>  I wanna know which measures are you going to take to make this kind of backdoors never appear again.\\r\\n\\r\\n `well,` codacy will throw **B307 alert** if   **eval()**  is being used anywhere. @KOLANICH'}, 'com_22': {'author': 'KOLANICH', 'datetime': '03/18/2018, 14:44:51', 'body': \"@sigoa not only, I'm currently working on a draft of the spec combining taint checking, mandatory access control, capability-based security and permissions into a framework enforcing that\\r\\n* no data from network and other untrusted sources will be passed into security-sensitive functions like `eval`\\r\\n* no sensitive data will be leaked into untrusted destinations like net\\r\\n* no sensitive data resulted in invocation of a privileged API will be available to any module not having a permission to read results from that API\\r\\n* every module will have to explicitly declare the API inputs to which that it controls\\r\\n* and I hope that the framework can be applied to real-world applications\\r\\n\\r\\nbut I have some problems with proofs because the functions to explicitly change taints spoil all the picture, in presence of these functions I cannot prove anything, in absence the scheme is complete garbage unusable in real world apps. For example a private key is a sensitive piece of data, that's why everything touched by it will also be marked as sensitive, even the digital signature which is in fact by default not sensitive assumming no vulnrs in crypto. To solve this issue we need to mark it as non-sensitive, but doing so spoils the whole picture, we cannot prove that the system is secure anymore. \\r\\n\\r\\nFor now I recommend to start implementing taint checking using some frameworks available for python.\"}, 'com_23': {'author': 'sigoa', 'datetime': '03/18/2018, 17:04:52', 'body': \"yeah, its tricky  :cactus: , ain't it. maybe some QUBE OS users made some progress, I don't know.\"}, 'com_24': {'author': 'sigoa', 'datetime': '03/18/2018, 17:11:58', 'body': '@PeterSurda   please add label \"**SECURITY**\" to this  ISSUE  ,  so one can find it better / sortability  , since this is no laughing matter as we know. thanks  :+1: \\r\\n... well you can\\'t , because  it is a RELEASE not an ISSUE . :ping_pong:  \\r\\n\\r\\nsee secu issues here:  https://github.com/Bitmessage/PyBitmessage/labels/security'}, 'com_25': {'author': 'PeterSurda', 'datetime': '03/18/2018, 18:11:42', 'body': \"Thank you @KOLANICH , the security audit job is still open, but contributions that either harden the code directly, or provide a framework for hardening too. Since the vulnerability was revealed, I launched a multi-pronged approach, here are some of the highlights:\\r\\n\\r\\n### Infrastructure\\r\\n\\r\\n- infrastructure (build, bootstrap, website, ...) was hardened and separated from the development environment. This way, even if I get hacked, other people can continue developing, binaries can continue to be built, people can connect to the network. I now have a separate laptop for accessing the infrastructure\\r\\n\\r\\n- my development environment was also hardened and I increased the use of smart cards for authentication and encryption\\r\\n\\r\\n### Development\\r\\n\\r\\n- all new code, including mine, has to be reviewed before being merged\\r\\n\\r\\n- better integration with codacy, and I fine-tuned some settings\\r\\n\\r\\n- existing code will have all the codacy complaints fixed before I do further development (well, maybe some can't be fixed entirely, but they will be treated)\\r\\n\\r\\n- design documentation will be reverse-enginered from the code so that it's easier for new developers/reviewers to understand what's happening\\r\\n\\r\\n- I'll do less development and work more on design/organisational layer\\r\\n\\r\\n### Other things\\r\\n\\r\\n- I spent about 2 weeks reading through CVs an interviewing developers, and recruited a company to help me with the development. This means more people fixing coding issues and reviewing the code\\r\\n\\r\\n- I sent some money to tip4commit so that contributors can be better rewarded, and I want to institute a bug bounty program\\r\\n\\r\\n- I got rid of ALL the evals in the code. There are still some `call`s, e.g. the apinotify or the `make` for autobuilding the C PoW. These are more difficult to get rid of, but at least they can be hardened somewhat\\r\\n\\r\\n@sigoa Yep, can't assign a label.\"}, 'com_26': {'author': 'KOLANICH', 'datetime': '03/18/2018, 18:20:48', 'body': \">design documentation will be reverse-enginered from the code so that it's easier for new developers/reviewers to understand what's happening\\r\\n\\r\\nCould I ask you to write the docs to the message format in Kaitai Struct language (parser can be auto-generated further from the docs, it is machine-readable formal language)? Here is my draft (I have reverse-engineered it from the code and existing docs, but have not tested it anyhow) https://github.com/KOLANICH/kaitai_struct_formats/blob/bitmessage/network/bitmessage.ksy, I expect you to check and test it and develop further. If you wanna check it against a pcap dump inthe same repo you can find a parser for [pcap](https://github.com/kaitai-io/kaitai_struct_formats/blob/pcapng/network/pcapng.ksy) and [pcapng](https://github.com/KOLANICH/kaitai_struct_formats/blob/pcapng/network/pcapng.ksy) formats and my lib https://github.com/KOLANICH/Pipeline.py (which in fact was created for the [similar task](https://github.com/KOLANICH/USBPcapOdinDumper) ) may be useful too.\\r\\n\\r\\n>increased the use of smart cards \\r\\n\\r\\nwhich ones?\\r\\n\\r\\n>I now have a separate laptop for accessing the infrastructure\\r\\n\\r\\nI hope without any backdoors by Intel/AMD/longsoon/any other chineese/taiwanese/russian company/etc?\\r\\n\\r\\n>interviewing developers, and recruited a company to help me with the development\\r\\n\\r\\nI see you are serious with it. Are you going to make business on it? But how are you going to make it sustainable? This will require money and I see no legitimate (backdors are certainly illegitimate) sources of money providing enough money for such a project (you know, most of people don't need decentralised systems, they only need fashionable centralised things: whatsapp, viber, telegram, instagram, prisma, Alexa, Cortana, Siri, iPhone, etc, and without a big market company will likely go bankrupt), maybe except a grant by Mozilla.\"}, 'com_27': {'author': 'sigoa', 'datetime': '03/18/2018, 19:59:54', 'body': 'Mozilla has kind of funny attitudes.  :clown_face:'}, 'com_28': {'author': 'sigoa', 'datetime': '03/18/2018, 20:11:42', 'body': 'could @PeterSurda  pls link  CODACY  into  wiki [here](https://github.com/Bitmessage/PyBitmessage/wiki)  ?  thx :+1:'}, 'com_29': {'author': 'PeterSurda', 'datetime': '03/21/2018, 08:42:13', 'body': \"> Could I ask you to write the docs to the message format in Kaitai Struct\\r\\n\\r\\nI'll look at it in more detail. It looks like a wire protocol specification, which is fine, but I want specification of both the Bitmessage system design as well as how PyBitmessage is put together (like what are the threads, what are they doing, and so on). For example the wire protocol specification cannot specify when an inv is being sent, what the handshake sequence looks like, and so on. It's also unclear to me at this point how TLS is supposed to be specified in Kaitai Struct.\\r\\n\\r\\n> which ones? (smartcards, e.d.)\\r\\n\\r\\nSo far Yubikey and Nitrokey are being tested. I'd also consider Trezor and Nano Ledger S but they look like an overkill. I also have a separate code signing card (Win/OSX), forgot who the manufacturer is, but I want to replace it as I'm not happy with it.\\r\\n\\r\\n> I hope without any backdoors by Intel/AMD/longsoon/any other chineese/taiwanese/russian company/etc?\\r\\n\\r\\nI don't know any laptops guaranteed without backdoors, apart from some very old models which aren't practically usable anymore, or they can't be bought in a physical shop in Europe. The one I bought has a CPU that according to specifications doesn't have TXE. If that means that the ME is entirely absent I don't know. The closest to what I want is probably Purism Librem (which uses Coreboot and has ME disabled) but I don't know how to get it in a physical shop in Europe.\\r\\n\\r\\n> Are you going to make business on it? But how are you going to make it sustainable? This will require money and I see no legit sources of money providing enough money for such a project, maybe except a grant by Mozilla.\\r\\n\\r\\nI've been thinking about revenue possibilities for quite some time and looking for a co-founder for about a year. I now found someone and we're investigating a particular business plan (he on the business side, me on the technical side). The details will be announced in due time. There are other possible business plans that can be investigated when we see growth. Supporting the project through grants is a possibility but I don't see it as a sustainable one.\"}, 'com_30': {'author': 'KOLANICH', 'datetime': '03/21/2018, 09:03:07', 'body': \">It looks like a wire protocol specification\\r\\n\\r\\nIt's binary formats spec, not protocol. Protocol spec is yet to be created, IMHO verilog shkuld be used for protocols specs.\\r\\n\\r\\n>but I want specification of both the Bitmessage system design as well as how PyBitmessage is put together\\r\\n\\r\\nI only advised a part suitable for describing message format.\\r\\n\\r\\n>It's also unclear to me at this point how TLS is supposed to be specified in Kaitai Struct.\\r\\n\\r\\nI have not implemented tls messages. And I guess BM has nothing to do with tls itself, tls should be managed by tls libraries, not by PBM itself.\\r\\n\\r\\n>I now found someone\\r\\n\\r\\nI hope it's not government agencies or cybercriminals.\"}}", "stats": "{'additions': 4, 'deletions': 3, 'total': 7}", "files": {"src/messagetypes/__init__.py": {"additions": 4, "deletions": 3, "changes": 7, "status": "modified", "raw_url": "https://github.com/Bitmessage/PyBitmessage/raw/3a8016d31f517775d226aa8b902480f4a3a148a9/src%2Fmessagetypes%2F__init__.py", "patch": "@@ -12,9 +12,10 @@ def encode(self):\n \n def constructObject(data):\n     try:\n-        classBase = eval(data[\"\"] + \".\" + data[\"\"].title())\n-    except NameError:\n-        logger.error(\"Don't know how to handle message type: \\\"%s\\\"\", data[\"\"])\n+        m = import_module(\"messagetypes.\" + data[\"\"])\n+        classBase = getattr(m, data[\"\"].title())\n+    except (NameError, ImportError):\n+        logger.error(\"Don't know how to handle message type: \\\"%s\\\"\", data[\"\"], exc_info=True)\n         return None\n     try:\n         returnObj = classBase()"}}, "prior_version": " def encode(self):  def constructObject(data):     try:         classBase = eval(data[\"\"] + \".\" + data[\"\"].title())     except NameError:         logger.error(\"Don't know how to handle message type: \\\"%s\\\"\", data[\"\"])         return None     try:         returnObj = classBase()", "after_version": " def encode(self):  def constructObject(data):     try:         m = import_module(\"messagetypes.\" + data[\"\"])         classBase = getattr(m, data[\"\"].title())     except (NameError, ImportError):         logger.error(\"Don't know how to handle message type: \\\"%s\\\"\", data[\"\"], exc_info=True)         return None     try:         returnObj = classBase()", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "CVE-2019-11340", "cwe_id": "{'CWE-20'}", "score": 2.9, "chain": "{'https://github.com/matrix-org/sydent/commit/4e1cfff53429c49c87d5c457a18ed435520044fc'}", "dataset": "nvd", "summary": "util/emailutils.py in Matrix Sydent before 1.0.2 mishandles registration restrictions that are based on e-mail domain, if the allowed_local_3pids option is enabled. This occurs because of potentially unwanted behavior in Python, in which an email.utils.parseaddr call on user@bad.example.net@good.example.com returns the user@bad.example.net substring.", "published_date": "2019-04-19", "chain_len": 1, "project": "https://github.com/matrix-org/sydent", "commit_href": "https://github.com/matrix-org/sydent/commit/4e1cfff53429c49c87d5c457a18ed435520044fc", "commit_sha": "4e1cfff53429c49c87d5c457a18ed435520044fc", "patch": "SINGLE", "chain_ord": "['4e1cfff53429c49c87d5c457a18ed435520044fc']", "before_first_fix_commit": "{'617ff31a52139f28e4780cb2793ddf552a1997e9'}", "last_fix_commit": "4e1cfff53429c49c87d5c457a18ed435520044fc", "chain_ord_pos": 1, "commit_datetime": "04/18/2019, 16:14:01", "message": "Require that parsed mail addresses match raw input\n\nPython's email parser turns malformed addresses into valid ones\nby removing anything after and including the second '@'. This\nmeant that sydent sent emails to the validated address but stored\nthe raw address as validated.\n\nThis rejects any requests where the parsed email address does not\nmatch the raw input.", "author": "David Baker", "comments": "{'com_1': {'author': 'myselfhimself', 'datetime': '04/23/2019, 17:40:19', 'body': \"How is this a fix... as shown also here https://bugs.python.org/msg329463 ?\\r\\nFollowing the [Python RFC here](https://docs.python.org/3/library/email.utils.html#email.utils.parseaddr) you should check for parsedFrom == ('', '') and same for parsedTo == ('', '')\"}, 'com_2': {'author': 'myselfhimself', 'datetime': '04/23/2019, 17:44:32', 'body': 'Don\\'t you want to check mailFrom != parsedFrom  and mailTo != parsedTo as stated in \"This rejects any requests where the parsed email address does not match the raw input.\" ?'}, 'com_3': {'author': 'kstefanini', 'datetime': '04/26/2019, 12:23:43', 'body': '@myselfhimself https://github.com/matrix-org/sydent/commit/3103b65dcfa37a9241dabedba560c4ded6c05ff6'}}", "stats": "{'additions': 11, 'deletions': 5, 'total': 16}", "files": {"sydent/util/emailutils.py": {"additions": 11, "deletions": 5, "changes": 16, "status": "modified", "raw_url": "https://github.com/matrix-org/sydent/raw/4e1cfff53429c49c87d5c457a18ed435520044fc/sydent%2Futil%2Femailutils.py", "patch": "@@ -55,12 +55,13 @@ def sendEmail(sydent, templateName, mailTo, substitutions):\n             allSubstitutions[k+\"_forhtml\"] = cgi.escape(v.decode('utf8'))\n             allSubstitutions[k+\"_forurl\"] = urllib.quote(v)\n \n-        mailString = open(mailTemplateFile).read() % allSubstitutions\n-        rawFrom = email.utils.parseaddr(mailFrom)[1]\n-        rawTo = email.utils.parseaddr(mailTo)[1]\n-        if rawFrom == '' or rawTo == '':\n+        mailString = open(mailTemplateFile).read().decode('utf8') % allSubstitutions\n+        parsedFrom = email.utils.parseaddr(mailFrom)[1]\n+        parsedTo = email.utils.parseaddr(mailTo)[1]\n+        if parsedFrom == '' or parsedTo == '':\n             logger.info(\"Couldn't parse from / to address %s / %s\", mailFrom, mailTo)\n             raise EmailAddressException()\n+\n         mailServer = sydent.cfg.get('email', 'email.smtphost')\n         mailPort = sydent.cfg.get('email', 'email.smtpport')\n         mailUsername = sydent.cfg.get('email', 'email.smtpusername')\n@@ -77,7 +78,12 @@ def sendEmail(sydent, templateName, mailTo, substitutions):\n                 smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n             if mailUsername != '':\n                 smtp.login(mailUsername, mailPassword)\n-            smtp.sendmail(rawFrom, rawTo, mailString.encode('utf-8'))\n+\n+            # We're using the parsing above to do basic validation, but instead of\n+            # failing it may munge the address it returns. So we should *not* use\n+            # that parsed address, as it may not match any validation done\n+            # elsewhere.\n+            smtp.sendmail(mailFrom, mailTo, mailString.encode('utf-8'))\n             smtp.quit()\n         except Exception as origException:\n             twisted.python.log.err()"}}, "prior_version": " def sendEmail(sydent, templateName, mailTo, substitutions):             allSubstitutions[k+\"_forhtml\"] = cgi.escape(v.decode('utf8'))             allSubstitutions[k+\"_forurl\"] = urllib.quote(v)          mailString = open(mailTemplateFile).read() % allSubstitutions         rawFrom = email.utils.parseaddr(mailFrom)[1]         rawTo = email.utils.parseaddr(mailTo)[1]         if rawFrom == '' or rawTo == '':             logger.info(\"Couldn't parse from / to address %s / %s\", mailFrom, mailTo)             raise EmailAddressException()         mailServer = sydent.cfg.get('email', 'email.smtphost')         mailPort = sydent.cfg.get('email', 'email.smtpport')         mailUsername = sydent.cfg.get('email', 'email.smtpusername') def sendEmail(sydent, templateName, mailTo, substitutions):                 smtp = smtplib.SMTP(mailServer, mailPort, myHostname)             if mailUsername != '':                 smtp.login(mailUsername, mailPassword)             smtp.sendmail(rawFrom, rawTo, mailString.encode('utf-8'))             smtp.quit()         except Exception as origException:             twisted.python.log.err()", "after_version": " def sendEmail(sydent, templateName, mailTo, substitutions):             allSubstitutions[k+\"_forhtml\"] = cgi.escape(v.decode('utf8'))             allSubstitutions[k+\"_forurl\"] = urllib.quote(v)          mailString = open(mailTemplateFile).read().decode('utf8') % allSubstitutions         parsedFrom = email.utils.parseaddr(mailFrom)[1]         parsedTo = email.utils.parseaddr(mailTo)[1]         if parsedFrom == '' or parsedTo == '':             logger.info(\"Couldn't parse from / to address %s / %s\", mailFrom, mailTo)             raise EmailAddressException()          mailServer = sydent.cfg.get('email', 'email.smtphost')         mailPort = sydent.cfg.get('email', 'email.smtpport')         mailUsername = sydent.cfg.get('email', 'email.smtpusername') def sendEmail(sydent, templateName, mailTo, substitutions):                 smtp = smtplib.SMTP(mailServer, mailPort, myHostname)             if mailUsername != '':                 smtp.login(mailUsername, mailPassword)              # We're using the parsing above to do basic validation, but instead of             # failing it may munge the address it returns. So we should *not* use             # that parsed address, as it may not match any validation done             # elsewhere.             smtp.sendmail(mailFrom, mailTo, mailString.encode('utf-8'))             smtp.quit()         except Exception as origException:             twisted.python.log.err()", "file_extension": "py", "cwe": "CWE-20"}
{"vuln_id": "CVE-2019-16215", "cwe_id": "{'CWE-400'}", "score": 2.9, "chain": "{'https://github.com/zulip/zulip/commit/5797f013b3be450c146a4141514bda525f2f1b51'}", "dataset": "nvd", "summary": "The Markdown parser in Zulip server before 2.0.5 used a regular expression vulnerable to exponential backtracking. A user who is logged into the server could send a crafted message causing the server to spend an effectively arbitrary amount of CPU time and stall the processing of future messages.", "published_date": "2019-09-18", "chain_len": 1, "project": "https://github.com/zulip/zulip", "commit_href": "https://github.com/zulip/zulip/commit/5797f013b3be450c146a4141514bda525f2f1b51", "commit_sha": "5797f013b3be450c146a4141514bda525f2f1b51", "patch": "SINGLE", "chain_ord": "['5797f013b3be450c146a4141514bda525f2f1b51']", "before_first_fix_commit": "{'1195841dfb9aa26b3b0dabc6f05d72e4af25be3e'}", "last_fix_commit": "5797f013b3be450c146a4141514bda525f2f1b51", "chain_ord_pos": 1, "commit_datetime": "04/05/2019, 00:31:57", "message": "CVE-2019-16215: Fix DoS vulnerability in Markdown LINK_RE.\n\nAny regex including a match-everything subpattern (.*, .*?, .+, or\n.+?) is almost automatically wrong because it fails to disambiguate\nwhen one subpattern should end and another should begin.  Among other\nbugs, these kind of regexes tend to be especially prone to denial of\nservice vulnerabilities through catastrophic backtracking on strings\nthat fail to match in a large (in this case, exponential) number of\nways.\n\nLacking a specification to say what characters should actually be\nallowed in these subpatterns (this syntax is too different from\nCommonMark to be able to precisely apply those rules), I\u2019ve tried to\nmake reasonable guesses and avoid changing much else.\n\nBecause Zulip doesn't store messages until they have successfully been\nprocessed by the Markdown processor, this is not a stored DoS issue.\n\nIn general, Zulip protects against the broad category of DoS issues in\nMarkdown rendering via a timeout managed by another thread.  However,\ndetails of Python's regular expression implementation mean that this\nparticular issue could prevent the timeout thread from being\nscheduled, resulting in this being a DoS issue.\n\nThis was fixed in master a few months ago as a side effect of\nabe2dab88ca96786bb32dea6caab873819b8c482 (#12979).\n\nSigned-off-by: Anders Kaseorg <anders@zulipchat.com>", "author": "Anders Kaseorg", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"zerver/lib/bugdown/__init__.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/zulip/zulip/raw/5797f013b3be450c146a4141514bda525f2f1b51/zerver%2Flib%2Fbugdown%2F__init__.py", "patch": "@@ -1484,7 +1484,7 @@ def get_link_re() -> str:\n \n     # [text](url) or [text](<url>) or [text](url \"title\")\n     LINK_RE = NOIMG + BRK + \\\n-        r'''\\(\\s*(<.*?>|((?:(?:\\(.*?\\))|[^\\(\\)]))*?)\\s*((['\"])(.*?)\\12\\s*)?\\)'''\n+        r'''\\(\\s*(<(?:[^<>\\\\]|\\\\.)*>|(\\([^()]*\\)|[^()])*?)\\s*(('(?:[^'\\\\]|\\\\.)*'|\"(?:[^\"\\\\]|\\\\.)*\")\\s*)?\\)'''\n     return normal_compile(LINK_RE)\n \n def prepare_realm_pattern(source: str) -> str:"}}, "prior_version": " def get_link_re() -> str:      # [text](url) or [text](<url>) or [text](url \"title\")     LINK_RE = NOIMG + BRK + \\         r'''\\(\\s*(<.*?>|((?:(?:\\(.*?\\))|[^\\(\\)]))*?)\\s*((['\"])(.*?)\\12\\s*)?\\)'''     return normal_compile(LINK_RE)  def prepare_realm_pattern(source: str) -> str:", "after_version": " def get_link_re() -> str:      # [text](url) or [text](<url>) or [text](url \"title\")     LINK_RE = NOIMG + BRK + \\         r'''\\(\\s*(<(?:[^<>\\\\]|\\\\.)*>|(\\([^()]*\\)|[^()])*?)\\s*(('(?:[^'\\\\]|\\\\.)*'|\"(?:[^\"\\\\]|\\\\.)*\")\\s*)?\\)'''     return normal_compile(LINK_RE)  def prepare_realm_pattern(source: str) -> str:", "file_extension": "py", "cwe": "CWE-400"}
{"vuln_id": "CVE-2019-25066", "cwe_id": "{'CWE-78'}", "score": 6.4, "chain": "{'https://github.com/ajenti/ajenti/commit/7aa146b724e0e20cfee2c71ca78fafbf53a8767c'}", "dataset": "nvd", "summary": "A vulnerability has been found in ajenti 2.1.31 and classified as critical. This vulnerability affects unknown code of the component API. The manipulation leads to privilege escalation. The attack can be initiated remotely. The exploit has been disclosed to the public and may be used. Upgrading to version 2.1.32 is able to address this issue. The name of the patch is 7aa146b724e0e20cfee2c71ca78fafbf53a8767c. It is recommended to upgrade the affected component.", "published_date": "2022-06-09", "chain_len": 1, "project": "https://github.com/ajenti/ajenti", "commit_href": "https://github.com/ajenti/ajenti/commit/7aa146b724e0e20cfee2c71ca78fafbf53a8767c", "commit_sha": "7aa146b724e0e20cfee2c71ca78fafbf53a8767c", "patch": "SINGLE", "chain_ord": "['7aa146b724e0e20cfee2c71ca78fafbf53a8767c']", "before_first_fix_commit": "{'ef385f96d7e9e09b81ca5e48dc4e04042d5a74a4'}", "last_fix_commit": "7aa146b724e0e20cfee2c71ca78fafbf53a8767c", "chain_ord_pos": 1, "commit_datetime": "10/05/2019, 14:06:48", "message": "fixed shell injection in os auth provider", "author": "Eugene Pankov", "comments": null, "stats": "{'additions': 8, 'deletions': 1, 'total': 9}", "files": {"ajenti-core/aj/auth.py": {"additions": 8, "deletions": 1, "changes": 9, "status": "modified", "raw_url": "https://github.com/ajenti/ajenti/raw/7aa146b724e0e20cfee2c71ca78fafbf53a8767c/ajenti-core%2Faj%2Fauth.py", "patch": "@@ -5,6 +5,7 @@\n import subprocess\n import syslog\n from jadi import component, service, interface\n+from six import PY3\n \n import aj\n from aj.api.http import BaseHttpHandler\n@@ -99,8 +100,14 @@ class OSAuthenticationProvider(AuthenticationProvider):\n \n     def authenticate(self, username, password):\n         child = None\n+\n+        if PY3:\n+            from shlex import quote\n+        else:\n+            from pipes import quote\n+\n         try:\n-            child = pexpect.spawn('/bin/sh', ['-c', '/bin/su -c \"/bin/echo SUCCESS\" - %s' % username], timeout=5)\n+            child = pexpect.spawn('/bin/sh', ['-c', '/bin/su -c \"/bin/echo SUCCESS\" - %s' % quote(username)], timeout=5)\n             child.expect('.*:')\n             child.sendline(password)\n             result = child.expect(['su: .*', 'SUCCESS'])"}}, "prior_version": " import subprocess import syslog from jadi import component, service, interface  import aj from aj.api.http import BaseHttpHandler class OSAuthenticationProvider(AuthenticationProvider):      def authenticate(self, username, password):         child = None         try:             child = pexpect.spawn('/bin/sh', ['-c', '/bin/su -c \"/bin/echo SUCCESS\" - %s' % username], timeout=5)             child.expect('.*:')             child.sendline(password)             result = child.expect(['su: .*', 'SUCCESS'])", "after_version": " import subprocess import syslog from jadi import component, service, interface from six import PY3  import aj from aj.api.http import BaseHttpHandler class OSAuthenticationProvider(AuthenticationProvider):      def authenticate(self, username, password):         child = None          if PY3:             from shlex import quote         else:             from pipes import quote          try:             child = pexpect.spawn('/bin/sh', ['-c', '/bin/su -c \"/bin/echo SUCCESS\" - %s' % quote(username)], timeout=5)             child.expect('.*:')             child.sendline(password)             result = child.expect(['su: .*', 'SUCCESS'])", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2020-23014", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/its-a-feature/Apfell/commit/5fc64502bc008388514f2b5d1160b677e3b4a7f3'}", "dataset": "nvd", "summary": "APfell 1.4 is vulnerable to authenticated reflected cross-site scripting (XSS) in /apiui/command_ through the payloadtypes_callback function, which allows an attacker to steal remote admin/user session and/or adding new users to the administration panel.", "published_date": "2021-01-26", "chain_len": 1, "project": "https://github.com/its-a-feature/Apfell", "commit_href": "https://github.com/its-a-feature/Apfell/commit/5fc64502bc008388514f2b5d1160b677e3b4a7f3", "commit_sha": "5fc64502bc008388514f2b5d1160b677e3b4a7f3", "patch": "SINGLE", "chain_ord": "['5fc64502bc008388514f2b5d1160b677e3b4a7f3']", "before_first_fix_commit": "{'f0fa9e680c9cfdd74b4f9178b0da0829ab8ea45f'}", "last_fix_commit": "5fc64502bc008388514f2b5d1160b677e3b4a7f3", "chain_ord_pos": 1, "commit_datetime": "04/19/2020, 16:58:23", "message": "fixed an 'Authenticated Cross-Site Scripting' bug on the command help page reported by 'Mohamed A. Baset' of 'Seekurity SA de C.V.' at 'Seekurity.com' on April 17,2020", "author": "Cody Thomas", "comments": null, "stats": "{'additions': 7, 'deletions': 2, 'total': 9}", "files": {"apfell-docker/app/routes/api_routes.py": {"additions": 7, "deletions": 2, "changes": 9, "status": "modified", "raw_url": "https://github.com/its-a-feature/Mythic/raw/5fc64502bc008388514f2b5d1160b677e3b4a7f3/apfell-docker%2Fapp%2Froutes%2Fapi_routes.py", "patch": "@@ -1,9 +1,10 @@\n-from app import apfell, links, use_ssl\n+from app import apfell, links, use_ssl, db_objects\n from sanic import response\n from jinja2 import Environment, PackageLoader\n from sanic_jwt.decorators import scoped, inject_user\n from app.routes.routes import respect_pivot\n import urllib.parse\n+import app.database_models.model as db_model\n \n env = Environment(loader=PackageLoader('app', 'templates'))\n \n@@ -15,7 +16,11 @@ async def apiui_command_help(request, user):\n     template = env.get_template('apiui_command_help.html')\n     if len(request.query_args) != 0:\n         data = urllib.parse.unquote(request.query_args[0][1])\n-        print(data)\n+        query = await db_model.payloadtype_query()\n+        try:\n+            payloadtype = await db_objects.get(query, ptype=data)\n+        except Exception as e:\n+            data = \"\"\n     else:\n         data = \"\"\n     if use_ssl:"}}, "prior_version": " from app import apfell, links, use_ssl from sanic import response from jinja2 import Environment, PackageLoader from sanic_jwt.decorators import scoped, inject_user from app.routes.routes import respect_pivot import urllib.parse  env = Environment(loader=PackageLoader('app', 'templates'))  async def apiui_command_help(request, user):     template = env.get_template('apiui_command_help.html')     if len(request.query_args) != 0:         data = urllib.parse.unquote(request.query_args[0][1])         print(data)     else:         data = \"\"     if use_ssl:", "after_version": " from app import apfell, links, use_ssl, db_objects from sanic import response from jinja2 import Environment, PackageLoader from sanic_jwt.decorators import scoped, inject_user from app.routes.routes import respect_pivot import urllib.parse import app.database_models.model as db_model  env = Environment(loader=PackageLoader('app', 'templates'))  async def apiui_command_help(request, user):     template = env.get_template('apiui_command_help.html')     if len(request.query_args) != 0:         data = urllib.parse.unquote(request.query_args[0][1])         query = await db_model.payloadtype_query()         try:             payloadtype = await db_objects.get(query, ptype=data)         except Exception as e:             data = \"\"     else:         data = \"\"     if use_ssl:", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2020-36324", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2'}", "dataset": "nvd", "summary": "Wikimedia Quarry analytics-quarry-web before 2020-12-15 allows Reflected XSS because app.py does not explicitly set the application/json content type.", "published_date": "2021-04-21", "chain_len": 1, "project": "https://github.com/wikimedia/analytics-quarry-web", "commit_href": "https://github.com/wikimedia/analytics-quarry-web/commit/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "commit_sha": "4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "patch": "SINGLE", "chain_ord": "['4b7e1d6a3a52ec6cf826a971135a38b0f74785d2']", "before_first_fix_commit": "{'085a51b2dee8b58882276d9fe090174252edb85e'}", "last_fix_commit": "4b7e1d6a3a52ec6cf826a971135a38b0f74785d2", "chain_ord_pos": 1, "commit_datetime": "12/15/2020, 16:55:55", "message": "SECURITY: Set correct Mime Type on /api/preferences\n\nPrevents a Reflected Cross-Site scripting (XSS) vulnerability\n\nBug: T270195\nChange-Id: I04bf53d2a939da369e54e91899615a3ffc3e5caf", "author": "Reedy", "comments": null, "stats": "{'additions': 12, 'deletions': 3, 'total': 15}", "files": {"quarry/web/app.py": {"additions": 12, "deletions": 3, "changes": 15, "status": "modified", "raw_url": "https://github.com/wikimedia/analytics-quarry-web/raw/4b7e1d6a3a52ec6cf826a971135a38b0f74785d2/quarry%2Fweb%2Fapp.py", "patch": "@@ -398,9 +398,15 @@ def pref_get(key):\n         return \"Authentication required\", 401\n \n     if key in get_preferences():\n-        return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))\n+        return Response(\n+            json.dumps({'key': key, 'value': get_preferences()[key]}),\n+            mimetype='application/json'\n+        )\n     else:\n-        return Response(json.dumps({'key': key, 'error': 'novalue'}))\n+        return Response(\n+            json.dumps({'key': key, 'error': 'novalue'}),\n+            mimetype='application/json'\n+        )\n \n \n @app.route(\"/api/preferences/set/<key>/<value>\")\n@@ -409,7 +415,10 @@ def pref_set(key, value):\n         return \"Authentication required\", 401\n \n     get_preferences()[key] = (None if value == 'null' else value)\n-    return Response(json.dumps({'key': key, 'success': ''})), 201\n+    return Response(\n+        json.dumps({'key': key, 'success': ''}),\n+        mimetype='application/json'\n+    ), 201\n \n \n if __name__ == '__main__':"}}, "prior_version": " def pref_get(key):         return \"Authentication required\", 401      if key in get_preferences():         return Response(json.dumps({'key': key, 'value': get_preferences()[key]}))     else:         return Response(json.dumps({'key': key, 'error': 'novalue'}))   @app.route(\"/api/preferences/set/<key>/<value>\") def pref_set(key, value):         return \"Authentication required\", 401      get_preferences()[key] = (None if value == 'null' else value)     return Response(json.dumps({'key': key, 'success': ''})), 201   if __name__ == '__main__':", "after_version": " def pref_get(key):         return \"Authentication required\", 401      if key in get_preferences():         return Response(             json.dumps({'key': key, 'value': get_preferences()[key]}),             mimetype='application/json'         )     else:         return Response(             json.dumps({'key': key, 'error': 'novalue'}),             mimetype='application/json'         )   @app.route(\"/api/preferences/set/<key>/<value>\") def pref_set(key, value):         return \"Authentication required\", 401      get_preferences()[key] = (None if value == 'null' else value)     return Response(         json.dumps({'key': key, 'success': ''}),         mimetype='application/json'     ), 201   if __name__ == '__main__':", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2020-5283", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/viewvc/viewvc/commit/ad0f966e9a997b17d853a6972ea283d4dcd70fa8'}", "dataset": "nvd", "summary": "ViewVC before versions 1.1.28 and 1.2.1 has a XSS vulnerability in CVS show_subdir_lastmod support. The impact of this vulnerability is mitigated by the need for an attacker to have commit privileges to a CVS repository exposed by an otherwise trusted ViewVC instance that also has the `show_subdir_lastmod` feature enabled. The attack vector involves files with unsafe names (names that, when embedded into an HTML stream, would cause the browser to run unwanted code), which themselves can be challenging to create. This vulnerability is patched in versions 1.2.1 and 1.1.28.", "published_date": "2020-04-03", "chain_len": 1, "project": "https://github.com/viewvc/viewvc", "commit_href": "https://github.com/viewvc/viewvc/commit/ad0f966e9a997b17d853a6972ea283d4dcd70fa8", "commit_sha": "ad0f966e9a997b17d853a6972ea283d4dcd70fa8", "patch": "SINGLE", "chain_ord": "['ad0f966e9a997b17d853a6972ea283d4dcd70fa8']", "before_first_fix_commit": "{'793889520509e3eaa8252965f1aeec0b64cd25e6'}", "last_fix_commit": "ad0f966e9a997b17d853a6972ea283d4dcd70fa8", "chain_ord_pos": 1, "commit_datetime": "03/26/2020, 18:11:41", "message": "issue #211: escape CVS subdir last-modified file name", "author": "C. Michael Pilato", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"lib/viewvc.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/viewvc/viewvc/raw/ad0f966e9a997b17d853a6972ea283d4dcd70fa8/lib%2Fviewvc.py", "patch": "@@ -2412,7 +2412,7 @@ def view_directory(request):\n       if request.roottype == 'cvs' and file.rev is not None:\n         row.rev = None\n         if cfg.options.show_logs:\n-          row.log_file = file.newest_file\n+          row.log_file = request.server.escape(file.newest_file)\n           row.log_rev = file.rev\n \n       if request.roottype == 'svn':"}}, "prior_version": " def view_directory(request):       if request.roottype == 'cvs' and file.rev is not None:         row.rev = None         if cfg.options.show_logs:           row.log_file = file.newest_file           row.log_rev = file.rev        if request.roottype == 'svn':", "after_version": " def view_directory(request):       if request.roottype == 'cvs' and file.rev is not None:         row.rev = None         if cfg.options.show_logs:           row.log_file = request.server.escape(file.newest_file)           row.log_rev = file.rev        if request.roottype == 'svn':", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2020-8545", "cwe_id": "{'CWE-22'}", "score": 2.9, "chain": "{'https://github.com/CIRCL/AIL-framework/commit/e808840f957c810b8e3944cba808716dc722581b'}", "dataset": "nvd", "summary": "Global.py in AIL framework 2.8 allows path traversal.", "published_date": "2020-02-03", "chain_len": 1, "project": "https://github.com/CIRCL/AIL-framework", "commit_href": "https://github.com/CIRCL/AIL-framework/commit/e808840f957c810b8e3944cba808716dc722581b", "commit_sha": "e808840f957c810b8e3944cba808716dc722581b", "patch": "SINGLE", "chain_ord": "['e808840f957c810b8e3944cba808716dc722581b']", "before_first_fix_commit": "{'e19a3b3e630ed8cacd492e5c36ffa59c3cdfac78'}", "last_fix_commit": "e808840f957c810b8e3944cba808716dc722581b", "chain_ord_pos": 1, "commit_datetime": "02/03/2020, 09:32:20", "message": "fix: [Global: filename provided by all feeders] avoid path tranversal", "author": "Terrtia", "comments": null, "stats": "{'additions': 31, 'deletions': 23, 'total': 54}", "files": {"bin/Global.py": {"additions": 31, "deletions": 23, "changes": 54, "status": "modified", "raw_url": "https://github.com/CIRCL/AIL-framework/raw/e808840f957c810b8e3944cba808716dc722581b/bin%2FGlobal.py", "patch": "@@ -45,8 +45,10 @@ def rreplace(s, old, new, occurrence):\n \n     p = Process(config_section)\n \n+    # get and sanityze PASTE DIRECTORY\n     PASTES_FOLDER = os.path.join(os.environ['AIL_HOME'], p.config.get(\"Directories\", \"pastes\"))\n     PASTES_FOLDERS = PASTES_FOLDER + '/'\n+    PASTES_FOLDERS = os.path.join(os.path.realpath(PASTES_FOLDERS), '')\n \n     # LOGGING #\n     publisher.info(\"Feed Script started to receive & publish.\")\n@@ -75,40 +77,46 @@ def rreplace(s, old, new, occurrence):\n             time.sleep(1)\n             continue\n \n+        # remove PASTES_FOLDER from item path (crawled item + submited)\n+        if PASTES_FOLDERS in paste:\n+            paste = paste.replace(PASTES_FOLDERS, '', 1)\n+\n         file_name_paste = paste.split('/')[-1]\n         if len(file_name_paste)>255:\n             new_file_name_paste = '{}{}.gz'.format(file_name_paste[:215], str(uuid.uuid4()))\n             paste = rreplace(paste, file_name_paste, new_file_name_paste, 1)\n \n         # Creating the full filepath\n         filename = os.path.join(PASTES_FOLDER, paste)\n+        filename = os.path.realpath(filename)\n \n-        dirname = os.path.dirname(filename)\n-        if not os.path.exists(dirname):\n-            os.makedirs(dirname)\n-\n-        decoded = base64.standard_b64decode(gzip64encoded)\n+        # incorrect filename\n+        if not os.path.commonprefix([filename, PASTES_FOLDER]) == PASTES_FOLDER:\n+            print('Path traversal detected {}'.format(filename))\n+            publisher.warning('Global; Path traversal detected')\n+        else:\n+            dirname = os.path.dirname(filename)\n+            if not os.path.exists(dirname):\n+                os.makedirs(dirname)\n \n-        with open(filename, 'wb') as f:\n-            f.write(decoded)\n-        '''try:\n-            decoded2 = gunzip_bytes_obj(decoded)\n-        except:\n-            decoded2 =''\n+            decoded = base64.standard_b64decode(gzip64encoded)\n \n-        type = magic.from_buffer(decoded2, mime=True)\n+            with open(filename, 'wb') as f:\n+                f.write(decoded)\n+            '''try:\n+                decoded2 = gunzip_bytes_obj(decoded)\n+            except:\n+                decoded2 =''\n \n-        if type!= 'text/x-c++' and type!= 'text/html' and type!= 'text/x-c' and type!= 'text/x-python' and type!= 'text/x-php' and type!= 'application/xml' and type!= 'text/x-shellscript' and type!= 'text/plain' and type!= 'text/x-diff' and type!= 'text/x-ruby':\n+            type = magic.from_buffer(decoded2, mime=True)\n \n-            print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n-            print(filename)\n-            print(type)\n-            print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n-        '''\n+            if type!= 'text/x-c++' and type!= 'text/html' and type!= 'text/x-c' and type!= 'text/x-python' and type!= 'text/x-php' and type!= 'application/xml' and type!= 'text/x-shellscript' and type!= 'text/plain' and type!= 'text/x-diff' and type!= 'text/x-ruby':\n \n-        # remove PASTES_FOLDER from item path (crawled item + submited)\n-        if PASTES_FOLDERS in paste:\n-            paste = paste.replace(PASTES_FOLDERS, '', 1)\n+                print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n+                print(filename)\n+                print(type)\n+                print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n+            '''\n \n-        p.populate_set_out(paste)\n-        processed_paste+=1\n+            p.populate_set_out(paste)\n+            processed_paste+=1"}}, "prior_version": " def rreplace(s, old, new, occurrence):      p = Process(config_section)      PASTES_FOLDER = os.path.join(os.environ['AIL_HOME'], p.config.get(\"Directories\", \"pastes\"))     PASTES_FOLDERS = PASTES_FOLDER + '/'      # LOGGING #     publisher.info(\"Feed Script started to receive & publish.\") def rreplace(s, old, new, occurrence):             time.sleep(1)             continue          file_name_paste = paste.split('/')[-1]         if len(file_name_paste)>255:             new_file_name_paste = '{}{}.gz'.format(file_name_paste[:215], str(uuid.uuid4()))             paste = rreplace(paste, file_name_paste, new_file_name_paste, 1)          # Creating the full filepath         filename = os.path.join(PASTES_FOLDER, paste)          dirname = os.path.dirname(filename)         if not os.path.exists(dirname):             os.makedirs(dirname)          decoded = base64.standard_b64decode(gzip64encoded)          with open(filename, 'wb') as f:             f.write(decoded)         '''try:             decoded2 = gunzip_bytes_obj(decoded)         except:             decoded2 =''          type = magic.from_buffer(decoded2, mime=True)          if type!= 'text/x-c++' and type!= 'text/html' and type!= 'text/x-c' and type!= 'text/x-python' and type!= 'text/x-php' and type!= 'application/xml' and type!= 'text/x-shellscript' and type!= 'text/plain' and type!= 'text/x-diff' and type!= 'text/x-ruby':              print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             print(filename)             print(type)             print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')         '''          # remove PASTES_FOLDER from item path (crawled item + submited)         if PASTES_FOLDERS in paste:             paste = paste.replace(PASTES_FOLDERS, '', 1)          p.populate_set_out(paste)         processed_paste+=1", "after_version": " def rreplace(s, old, new, occurrence):      p = Process(config_section)      # get and sanityze PASTE DIRECTORY     PASTES_FOLDER = os.path.join(os.environ['AIL_HOME'], p.config.get(\"Directories\", \"pastes\"))     PASTES_FOLDERS = PASTES_FOLDER + '/'     PASTES_FOLDERS = os.path.join(os.path.realpath(PASTES_FOLDERS), '')      # LOGGING #     publisher.info(\"Feed Script started to receive & publish.\") def rreplace(s, old, new, occurrence):             time.sleep(1)             continue          # remove PASTES_FOLDER from item path (crawled item + submited)         if PASTES_FOLDERS in paste:             paste = paste.replace(PASTES_FOLDERS, '', 1)          file_name_paste = paste.split('/')[-1]         if len(file_name_paste)>255:             new_file_name_paste = '{}{}.gz'.format(file_name_paste[:215], str(uuid.uuid4()))             paste = rreplace(paste, file_name_paste, new_file_name_paste, 1)          # Creating the full filepath         filename = os.path.join(PASTES_FOLDER, paste)         filename = os.path.realpath(filename)          # incorrect filename         if not os.path.commonprefix([filename, PASTES_FOLDER]) == PASTES_FOLDER:             print('Path traversal detected {}'.format(filename))             publisher.warning('Global; Path traversal detected')         else:             dirname = os.path.dirname(filename)             if not os.path.exists(dirname):                 os.makedirs(dirname)              decoded = base64.standard_b64decode(gzip64encoded)              with open(filename, 'wb') as f:                 f.write(decoded)             '''try:                 decoded2 = gunzip_bytes_obj(decoded)             except:                 decoded2 =''              type = magic.from_buffer(decoded2, mime=True)              if type!= 'text/x-c++' and type!= 'text/html' and type!= 'text/x-c' and type!= 'text/x-python' and type!= 'text/x-php' and type!= 'application/xml' and type!= 'text/x-shellscript' and type!= 'text/plain' and type!= 'text/x-diff' and type!= 'text/x-ruby':                  print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')                 print(filename)                 print(type)                 print('-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------')             '''              p.populate_set_out(paste)             processed_paste+=1", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2021-21329", "cwe_id": "{'CWE-287'}", "score": 6.4, "chain": "{'https://github.com/ractf/core/commit/cebb67bd16a8296121201805332365ffccb29638'}", "dataset": "nvd", "summary": "RATCF is an open-source framework for hosting Cyber-Security Capture the Flag events. In affected versions of RATCF users with multi factor authentication enabled are able to log in without a valid token. This is fixed in commit cebb67b.", "published_date": "2021-03-08", "chain_len": 1, "project": "https://github.com/ractf/core", "commit_href": "https://github.com/ractf/core/commit/cebb67bd16a8296121201805332365ffccb29638", "commit_sha": "cebb67bd16a8296121201805332365ffccb29638", "patch": "SINGLE", "chain_ord": "['cebb67bd16a8296121201805332365ffccb29638']", "before_first_fix_commit": "{'dc06fb425cda8e3bec271cfe98620fab493c4992'}", "last_fix_commit": "cebb67bd16a8296121201805332365ffccb29638", "chain_ord_pos": 1, "commit_datetime": "02/26/2021, 11:41:20", "message": "Merge pull request from GHSA-fw57-f7mq-9q85", "author": "David Cooke", "comments": null, "stats": "{'additions': 1, 'deletions': 1, 'total': 2}", "files": {"src/authentication/views.py": {"additions": 1, "deletions": 1, "changes": 2, "status": "modified", "raw_url": "https://github.com/ractf/core/raw/cebb67bd16a8296121201805332365ffccb29638/src%2Fauthentication%2Fviews.py", "patch": "@@ -150,7 +150,7 @@ def post(self, request, *args, **kwargs):\n                     code.delete()\n                     return self.issue_token(user)\n \n-        return self.issue_token(user)\n+        return FormattedResponse(status=HTTP_401_UNAUTHORIZED, d={'reason': 'login_failed'}, m='login_failed')\n \n \n class RegenerateBackupCodesView(APIView):"}}, "prior_version": " def post(self, request, *args, **kwargs):                     code.delete()                     return self.issue_token(user)          return self.issue_token(user)   class RegenerateBackupCodesView(APIView):", "after_version": " def post(self, request, *args, **kwargs):                     code.delete()                     return self.issue_token(user)          return FormattedResponse(status=HTTP_401_UNAUTHORIZED, d={'reason': 'login_failed'}, m='login_failed')   class RegenerateBackupCodesView(APIView):", "file_extension": "py", "cwe": "CWE-287"}
{"vuln_id": "CVE-2021-21433", "cwe_id": "{'CWE-94'}", "score": 6.4, "chain": "{'https://github.com/DEMON1A/Discord-Recon/commit/26e2a084679679cccdeeabbb6889ce120eff7e50'}", "dataset": "nvd", "summary": "Discord Recon Server is a bot that allows you to do your reconnaissance process from your Discord. Remote code execution in version 0.0.1 would allow remote users to execute commands on the server resulting in serious issues. This flaw is patched in 0.0.2.", "published_date": "2021-04-09", "chain_len": 1, "project": "https://github.com/DEMON1A/Discord-Recon", "commit_href": "https://github.com/DEMON1A/Discord-Recon/commit/26e2a084679679cccdeeabbb6889ce120eff7e50", "commit_sha": "26e2a084679679cccdeeabbb6889ce120eff7e50", "patch": "SINGLE", "chain_ord": "['26e2a084679679cccdeeabbb6889ce120eff7e50']", "before_first_fix_commit": "{'a6996fb801df313173453084525cdb3973a89c0b'}", "last_fix_commit": "26e2a084679679cccdeeabbb6889ce120eff7e50", "chain_ord_pos": 1, "commit_datetime": "02/25/2021, 10:32:33", "message": "Fixing Command Injection Issues.", "author": "Mohamed Dief", "comments": null, "stats": "{'additions': 8, 'deletions': 0, 'total': 8}", "files": {"app.py": {"additions": 8, "deletions": 0, "changes": 8, "status": "modified", "raw_url": "https://github.com/DEMON1A/Discord-Recon/raw/26e2a084679679cccdeeabbb6889ce120eff7e50/app.py", "patch": "@@ -95,6 +95,10 @@ async def ip(ctx , *, argument):\n \n @Client.command()\n async def dirsearch(ctx , *, argument):\n+    if not CommandInjection.commandInjection(argument=argument , RCE=RCE):\n+        await ctx.send(\"**Your Command Contains Unallowed Chars. Don't Try To Use It Again.**\")\n+        return\n+    \n     Path = TOOLS['dirsearch']; MainPath = getcwd(); chdir(Path)\n     await ctx.send(f\"**Running Your Dirsearch Scan, We Will Send The Results When It's Done**\")\n     Process = subprocess.Popen(f'python3 dirsearch.py -u {argument} -e * -b' , shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)\n@@ -115,6 +119,10 @@ async def dirsearch(ctx , *, argument):\n \n @Client.command()\n async def arjun(ctx , *, argument):\n+    if not CommandInjection.commandInjection(argument=argument , RCE=RCE):\n+        await ctx.send(\"**Your Command Contains Unallowed Chars. Don't Try To Use It Again.**\")\n+        return\n+    \n     Path = TOOLS['arjun']; MainPath = getcwd(); chdir(Path)\n     await ctx.send(f\"**Running Your Arjun Scan, We Will Send The Results When It's Done**\")\n     await ctx.send(f\"**Note: The Bot Won't Respond Until The Scan is Done. All Of Your Commands Now Will Be Executed After This Process is Done.\")"}}, "prior_version": " async def ip(ctx , *, argument):  @Client.command() async def dirsearch(ctx , *, argument):     Path = TOOLS['dirsearch']; MainPath = getcwd(); chdir(Path)     await ctx.send(f\"**Running Your Dirsearch Scan, We Will Send The Results When It's Done**\")     Process = subprocess.Popen(f'python3 dirsearch.py -u {argument} -e * -b' , shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT) async def dirsearch(ctx , *, argument):  @Client.command() async def arjun(ctx , *, argument):     Path = TOOLS['arjun']; MainPath = getcwd(); chdir(Path)     await ctx.send(f\"**Running Your Arjun Scan, We Will Send The Results When It's Done**\")     await ctx.send(f\"**Note: The Bot Won't Respond Until The Scan is Done. All Of Your Commands Now Will Be Executed After This Process is Done.\")", "after_version": " async def ip(ctx , *, argument):  @Client.command() async def dirsearch(ctx , *, argument):     if not CommandInjection.commandInjection(argument=argument , RCE=RCE):         await ctx.send(\"**Your Command Contains Unallowed Chars. Don't Try To Use It Again.**\")         return          Path = TOOLS['dirsearch']; MainPath = getcwd(); chdir(Path)     await ctx.send(f\"**Running Your Dirsearch Scan, We Will Send The Results When It's Done**\")     Process = subprocess.Popen(f'python3 dirsearch.py -u {argument} -e * -b' , shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT) async def dirsearch(ctx , *, argument):  @Client.command() async def arjun(ctx , *, argument):     if not CommandInjection.commandInjection(argument=argument , RCE=RCE):         await ctx.send(\"**Your Command Contains Unallowed Chars. Don't Try To Use It Again.**\")         return          Path = TOOLS['arjun']; MainPath = getcwd(); chdir(Path)     await ctx.send(f\"**Running Your Arjun Scan, We Will Send The Results When It's Done**\")     await ctx.send(f\"**Note: The Bot Won't Respond Until The Scan is Done. All Of Your Commands Now Will Be Executed After This Process is Done.\")", "file_extension": "py", "cwe": "CWE-94"}
{"vuln_id": "CVE-2022-1531", "cwe_id": "{'CWE-89'}", "score": 10.0, "chain": "{'https://github.com/rtxteam/rtx/commit/fa2797e656e3dba18f990a2db1f0f029d41f1921'}", "dataset": "nvd", "summary": "SQL injection vulnerability in ARAX-UI Synonym Lookup functionality in GitHub repository rtxteam/rtx prior to checkpoint_2022-04-20 . This vulnerability is critical as it can lead to remote code execution and thus complete server takeover.", "published_date": "2022-04-29", "chain_len": 1, "project": "https://github.com/rtxteam/rtx", "commit_href": "https://github.com/rtxteam/rtx/commit/fa2797e656e3dba18f990a2db1f0f029d41f1921", "commit_sha": "fa2797e656e3dba18f990a2db1f0f029d41f1921", "patch": "SINGLE", "chain_ord": "['fa2797e656e3dba18f990a2db1f0f029d41f1921']", "before_first_fix_commit": "{'12b9fa79bbe71299dfe3e9211239b381153014df'}", "last_fix_commit": "fa2797e656e3dba18f990a2db1f0f029d41f1921", "chain_ord_pos": 1, "commit_datetime": "04/20/2022, 18:38:35", "message": "avoid SQL injection exploits", "author": "Eric Deutsch", "comments": "{'com_1': {'author': 'dkoslicki', 'datetime': '04/20/2022, 19:34:13', 'body': 'Should we use query parameters/substitution variables instead? Since otherwise we would need to anticipate all special characters, right? (disclaimer: Not my area of expertise)'}, 'com_2': {'author': 'dkoslicki', 'datetime': '04/20/2022, 19:41:21', 'body': 'Maybe something like changing:\\r\\n```\\r\\ncursor.execute(f\"SELECT term FROM terms WHERE term > \\\\\"{floor}\\\\\" AND term < \\\\\"{ceiling}\\\\\" AND term LIKE \\\\\"{word}%%\\\\\" ORDER BY length(term),term LIMIT {requested_limit}\")\\r\\n```\\r\\nto\\r\\n```\\r\\ncursor.execute(\"SELECT term FROM terms WHERE term > %(floor)s AND term < %(ceiling)s AND term LIKE %(word)s ORDER BY length(term),term LIMIT %(requested_limit)d\", {\\'floor\\': floor, \\'ceiling\\': ceiling, \\'word\\': word, \\'requested_limit\\': requested_limit)\\r\\n```\\r\\nthat way types are respected. My VM is borked atm, otherwise I would test this out'}, 'com_3': {'author': 'edeutsch', 'datetime': '04/20/2022, 23:20:54', 'body': 'I don\\'t really know for sure, but don\\'t think your proposal solves the problem. I think it would be just as vulnerable to the exploit. But I am not certain. Using prepared statements is likely the safest way to do this. But I think stripping out all \" characters renders it safe, too. I should do some more testing.'}, 'com_4': {'author': 'saramsey', 'datetime': '04/21/2022, 16:48:35', 'body': 'Good discussion. Yes, prepared statements are _generally_ described as protecting against SQL injection but of course, would need to be tested in the context of a specific library and query.'}}", "stats": "{'additions': 10, 'deletions': 2, 'total': 12}", "files": {"code/autocomplete/rtxcomplete.py": {"additions": 10, "deletions": 2, "changes": 12, "status": "modified", "raw_url": "https://github.com/RTXteam/RTX/raw/fa2797e656e3dba18f990a2db1f0f029d41f1921/code%2Fautocomplete%2Frtxcomplete.py", "patch": "@@ -23,6 +23,7 @@ def load():\n     database_name = f\"{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}\"\n     conn = sqlite3.connect(database_name)\n     cursor = conn.cursor()\n+    #print(f\"INFO: Connected to {database_name}\",file=sys.stderr)\n     return True\n \n \n@@ -39,6 +40,9 @@ def get_nodes_like(word,requested_limit):\n     if len(word) < 2:\n         return values\n \n+    #### Try to avoid SQL injection exploits by sanitizing input #1823\n+    word = word.replace('\"','')\n+\n     floor = word[:-1]\n     ceiling = floor + 'zz'\n \n@@ -103,8 +107,12 @@ def get_nodes_like(word,requested_limit):\n         if found_fragment is None:\n \n             #### Cache this fragment in the database\n-            cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))\n-            fragment_id = cursor.lastrowid\n+            try:\n+                cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))\n+                fragment_id = cursor.lastrowid\n+            except:\n+                print(f\"ERROR: Unable to INSERT into cached_fragments(fragment)\",file=sys.stderr)\n+                fragment_id = 0\n             if debug:\n                 print(f\"fragment_id = {fragment_id}\")"}}, "prior_version": " def load():     database_name = f\"{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}\"     conn = sqlite3.connect(database_name)     cursor = conn.cursor()     return True   def get_nodes_like(word,requested_limit):     if len(word) < 2:         return values      floor = word[:-1]     ceiling = floor + 'zz'  def get_nodes_like(word,requested_limit):         if found_fragment is None:              #### Cache this fragment in the database             cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))             fragment_id = cursor.lastrowid             if debug:                 print(f\"fragment_id = {fragment_id}\") ", "after_version": " def load():     database_name = f\"{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}\"     conn = sqlite3.connect(database_name)     cursor = conn.cursor()     #print(f\"INFO: Connected to {database_name}\",file=sys.stderr)     return True   def get_nodes_like(word,requested_limit):     if len(word) < 2:         return values      #### Try to avoid SQL injection exploits by sanitizing input #1823     word = word.replace('\"','')      floor = word[:-1]     ceiling = floor + 'zz'  def get_nodes_like(word,requested_limit):         if found_fragment is None:              #### Cache this fragment in the database             try:                 cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))                 fragment_id = cursor.lastrowid             except:                 print(f\"ERROR: Unable to INSERT into cached_fragments(fragment)\",file=sys.stderr)                 fragment_id = 0             if debug:                 print(f\"fragment_id = {fragment_id}\") ", "file_extension": "py", "cwe": "CWE-89"}
{"vuln_id": "CVE-2022-1806", "cwe_id": "{'CWE-79'}", "score": 2.9, "chain": "{'https://github.com/rtxteam/rtx/commit/9bb109b0014f952f315c7b89e0f29a9ba84ee04c'}", "dataset": "nvd", "summary": "Cross-site Scripting (XSS) - Reflected in GitHub repository rtxteam/rtx prior to checkpoint_2022-05-18.", "published_date": "2022-05-20", "chain_len": 1, "project": "https://github.com/rtxteam/rtx", "commit_href": "https://github.com/rtxteam/rtx/commit/9bb109b0014f952f315c7b89e0f29a9ba84ee04c", "commit_sha": "9bb109b0014f952f315c7b89e0f29a9ba84ee04c", "patch": "SINGLE", "chain_ord": "['9bb109b0014f952f315c7b89e0f29a9ba84ee04c']", "before_first_fix_commit": "{'ebdb3856d3ce23df62fd7fc3186d3f5f13ea4337'}", "last_fix_commit": "9bb109b0014f952f315c7b89e0f29a9ba84ee04c", "chain_ord_pos": 1, "commit_datetime": "05/18/2022, 03:32:13", "message": "remove some cruft and implement a sanitizer for the client-supplied callback function name", "author": "Eric Deutsch", "comments": null, "stats": "{'additions': 25, 'deletions': 23, 'total': 48}", "files": {"code/autocomplete/server.py": {"additions": 25, "deletions": 23, "changes": 48, "status": "modified", "raw_url": "https://github.com/RTXteam/RTX/raw/9bb109b0014f952f315c7b89e0f29a9ba84ee04c/code%2Fautocomplete%2Fserver.py", "patch": "@@ -6,32 +6,35 @@\n import sys\n import rtxcomplete\n import traceback\n-\n-#class MainHandler(tornado.web.RequestHandler):\n-#    def get(self):\n-#        self.write(\"Hello, world\")\n-#print __file__\n+import re\n \n root = os.path.dirname(os.path.abspath(__file__))\n rtxcomplete.load()\n-#conn = sqlite3.connect('dict.db')\n-#conn.enable_load_extension(True)\n-#conn.load_extension(\"./spellfix\")\n-#cursor = conn.cursor()\n+\n+\n+#### Sanitize the client-provided callback function name\n+def sanitize_callback(callback):\n+    if callback is None or not isinstance(callback,str):\n+        return 'autocomplete_callback'\n+    match = re.match(r'([a-zA-Z0-9_]+).*$', callback)\n+    if match:\n+         callback = match.group(1)\n+    else:\n+         callback = 'autocomplete_callback'\n+    return callback\n+\n \n class autoSearch(tornado.web.RequestHandler):\n \n     def get(self, arg,word=None):\n-        #print \"match auto\"\n         try:\n             limit = self.get_argument(\"limit\")\n             word = self.get_argument(\"word\")\n-            callback = self.get_argument(\"callback\") #jsonp\n+            callback = sanitize_callback(self.get_argument(\"callback\"))\n \n             result = rtxcomplete.prefix(word,limit)\n-\n-            result = callback+\"(\"+json.dumps(result)+\");\" #jsonp\n-            #result = json.dumps(result) #typeahead\n+            \n+            result = callback+\"(\"+json.dumps(result)+\");\"\n             \n             self.write(result)\n             \n@@ -47,7 +50,7 @@ def get(self, arg,word=None):\n         try:\n             limit = self.get_argument(\"limit\")\n             word = self.get_argument(\"word\")\n-            callback = self.get_argument(\"callback\")\n+            callback = sanitize_callback(self.get_argument(\"callback\"))\n             #print word\n             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)\n             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit)\n@@ -73,7 +76,7 @@ def get(self, arg,word=None):\n         try:\n             limit = self.get_argument(\"limit\")\n             word = self.get_argument(\"word\")\n-            callback = self.get_argument(\"callback\")\n+            callback = sanitize_callback(self.get_argument(\"callback\"))\n             #print word\n             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)\n             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit)\n@@ -96,18 +99,17 @@ def get(self, arg,word=None):\n \n class nodesLikeSearch(tornado.web.RequestHandler):\n     def get(self, arg,word=None):\n-        #try:\n-        if 1 == 1:\n+        try:\n             limit = self.get_argument(\"limit\")\n             word = self.get_argument(\"word\")\n-            callback = self.get_argument(\"callback\")\n+            callback = sanitize_callback(self.get_argument(\"callback\"))\n             result = rtxcomplete.get_nodes_like(word,limit);\n             result = callback+\"(\"+json.dumps(result)+\");\"\n             self.write(result)\n-        #except:\n-        #    print(sys.exc_info()[:])\n-        #    traceback.print_tb(sys.exc_info()[-1])\n-        #    self.write(\"error\")\n+        except:\n+            print(sys.exc_info()[:])\n+            traceback.print_tb(sys.exc_info()[-1])\n+            self.write(\"error\")\n \n \n class defineSearch(tornado.web.RequestHandler):"}}, "prior_version": " import sys import rtxcomplete import traceback  #class MainHandler(tornado.web.RequestHandler): #    def get(self): #        self.write(\"Hello, world\") #print __file__  root = os.path.dirname(os.path.abspath(__file__)) rtxcomplete.load() #conn = sqlite3.connect('dict.db') #conn.enable_load_extension(True) #conn.load_extension(\"./spellfix\") #cursor = conn.cursor()  class autoSearch(tornado.web.RequestHandler):      def get(self, arg,word=None):         #print \"match auto\"         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = self.get_argument(\"callback\") #jsonp              result = rtxcomplete.prefix(word,limit)              result = callback+\"(\"+json.dumps(result)+\");\" #jsonp             #result = json.dumps(result) #typeahead                          self.write(result)              def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = self.get_argument(\"callback\")             #print word             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit) def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = self.get_argument(\"callback\")             #print word             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit) def get(self, arg,word=None):  class nodesLikeSearch(tornado.web.RequestHandler):     def get(self, arg,word=None):         #try:         if 1 == 1:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = self.get_argument(\"callback\")             result = rtxcomplete.get_nodes_like(word,limit);             result = callback+\"(\"+json.dumps(result)+\");\"             self.write(result)         #except:         #    print(sys.exc_info()[:])         #    traceback.print_tb(sys.exc_info()[-1])         #    self.write(\"error\")   class defineSearch(tornado.web.RequestHandler):", "after_version": " import sys import rtxcomplete import traceback import re  root = os.path.dirname(os.path.abspath(__file__)) rtxcomplete.load()   #### Sanitize the client-provided callback function name def sanitize_callback(callback):     if callback is None or not isinstance(callback,str):         return 'autocomplete_callback'     match = re.match(r'([a-zA-Z0-9_]+).*$', callback)     if match:          callback = match.group(1)     else:          callback = 'autocomplete_callback'     return callback   class autoSearch(tornado.web.RequestHandler):      def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = sanitize_callback(self.get_argument(\"callback\"))              result = rtxcomplete.prefix(word,limit)                          result = callback+\"(\"+json.dumps(result)+\");\"                          self.write(result)              def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = sanitize_callback(self.get_argument(\"callback\"))             #print word             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit) def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = sanitize_callback(self.get_argument(\"callback\"))             #print word             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"\\\" LIMIT \" + limit)             #cursor.execute(\"SELECT word FROM spell WHERE word MATCH \\\"\" + word + \"*\\\" LIMIT \" + limit) def get(self, arg,word=None):  class nodesLikeSearch(tornado.web.RequestHandler):     def get(self, arg,word=None):         try:             limit = self.get_argument(\"limit\")             word = self.get_argument(\"word\")             callback = sanitize_callback(self.get_argument(\"callback\"))             result = rtxcomplete.get_nodes_like(word,limit);             result = callback+\"(\"+json.dumps(result)+\");\"             self.write(result)         except:             print(sys.exc_info()[:])             traceback.print_tb(sys.exc_info()[-1])             self.write(\"error\")   class defineSearch(tornado.web.RequestHandler):", "file_extension": "py", "cwe": "CWE-79"}
{"vuln_id": "CVE-2022-1813", "cwe_id": "{'CWE-78'}", "score": 6.4, "chain": "{'https://github.com/yogeshojha/rengine/commit/8277cec0f008a0451371a92e7e0bf082ab3f0c34'}", "dataset": "nvd", "summary": "OS Command Injection in GitHub repository yogeshojha/rengine prior to 1.2.0.", "published_date": "2022-05-22", "chain_len": 1, "project": "https://github.com/yogeshojha/rengine", "commit_href": "https://github.com/yogeshojha/rengine/commit/8277cec0f008a0451371a92e7e0bf082ab3f0c34", "commit_sha": "8277cec0f008a0451371a92e7e0bf082ab3f0c34", "patch": "SINGLE", "chain_ord": "['8277cec0f008a0451371a92e7e0bf082ab3f0c34']", "before_first_fix_commit": "{'72a5fb2eb766c7b0334a3420af7576a60c95b182'}", "last_fix_commit": "8277cec0f008a0451371a92e7e0bf082ab3f0c34", "chain_ord_pos": 1, "commit_datetime": "05/22/2022, 15:41:29", "message": "Fix command injection issue on detect cms", "author": "Yogesh Ojha", "comments": null, "stats": "{'additions': 7, 'deletions': 2, 'total': 9}", "files": {"web/reNgine/common_func.py": {"additions": 7, "deletions": 2, "changes": 9, "status": "modified", "raw_url": "https://github.com/yogeshojha/rengine/raw/8277cec0f008a0451371a92e7e0bf082ab3f0c34/web%2FreNgine%2Fcommon_func.py", "patch": "@@ -6,6 +6,7 @@\n import tldextract\n import logging\n import shutil\n+import subprocess\n \n from threading import Thread\n \n@@ -668,8 +669,12 @@ def get_whois(ip_domain, save_db=False, fetch_from_db=True):\n def get_cms_details(url):\n     # this function will fetch cms details using cms_detector\n     response = {}\n-    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py -u {} --random-agent --batch --follow-redirect'.format(url)\n-    os.system(cms_detector_command)\n+    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py --random-agent --batch --follow-redirect'\n+    subprocess_splitted_command = cms_detector_command.split()\n+    subprocess_splitted_command.append('-u')\n+    subprocess_splitted_command.append(url)\n+    process = subprocess.Popen(subprocess_splitted_command)\n+    process.wait()\n \n     response['status'] = False\n     response['message'] = 'Could not detect CMS!'"}}, "prior_version": " import tldextract import logging import shutil  from threading import Thread  def get_whois(ip_domain, save_db=False, fetch_from_db=True): def get_cms_details(url):     # this function will fetch cms details using cms_detector     response = {}     cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py -u {} --random-agent --batch --follow-redirect'.format(url)     os.system(cms_detector_command)      response['status'] = False     response['message'] = 'Could not detect CMS!'", "after_version": " import tldextract import logging import shutil import subprocess  from threading import Thread  def get_whois(ip_domain, save_db=False, fetch_from_db=True): def get_cms_details(url):     # this function will fetch cms details using cms_detector     response = {}     cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py --random-agent --batch --follow-redirect'     subprocess_splitted_command = cms_detector_command.split()     subprocess_splitted_command.append('-u')     subprocess_splitted_command.append(url)     process = subprocess.Popen(subprocess_splitted_command)     process.wait()      response['status'] = False     response['message'] = 'Could not detect CMS!'", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2022-23609", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/bildsben/iTunesRPC-Remastered/commit/1eb1e5428f0926b2829a0bbbb65b0d946e608593'}", "dataset": "nvd", "summary": "iTunesRPC-Remastered is a Discord Rich Presence for iTunes on Windows utility. In affected versions iTunesRPC-Remastered did not properly sanitize user input used to remove files leading to file deletion only limited by the process permissions. Users are advised to upgrade as soon as possible.", "published_date": "2022-02-04", "chain_len": 1, "project": "https://github.com/bildsben/iTunesRPC-Remastered", "commit_href": "https://github.com/bildsben/iTunesRPC-Remastered/commit/1eb1e5428f0926b2829a0bbbb65b0d946e608593", "commit_sha": "1eb1e5428f0926b2829a0bbbb65b0d946e608593", "patch": "SINGLE", "chain_ord": "['1eb1e5428f0926b2829a0bbbb65b0d946e608593']", "before_first_fix_commit": "{'1bda8d191652c901613378e938775ca4717b9077'}", "last_fix_commit": "1eb1e5428f0926b2829a0bbbb65b0d946e608593", "chain_ord_pos": 1, "commit_datetime": "02/02/2022, 19:27:04", "message": "quick security fix", "author": "Ben", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"upload/server.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/bildsben/iTunesRPC-Remastered/raw/1eb1e5428f0926b2829a0bbbb65b0d946e608593/upload%2Fserver.py", "patch": "@@ -5,7 +5,7 @@\n import random\n from html import escape\n from os import remove\n-\n+import werkzeug.utils\n import magic\n from flask import Flask, abort, request\n from PIL import Image\n@@ -189,7 +189,7 @@ def uploadimage():\n     ):  # if it is not over the limit, it will skip. if it is, it does this.\n         # if we have gone over our cache limit, let's delete the first entry.\n         filename = all_files[0][1] + all_files[0][2]\n-        remove(filename)\n+        remove(werkzeug.utils.secure_filename(filename))\n         del all_files[0]\n         length = len(all_files)"}}, "prior_version": " import random from html import escape from os import remove  import magic from flask import Flask, abort, request from PIL import Image def uploadimage():     ):  # if it is not over the limit, it will skip. if it is, it does this.         # if we have gone over our cache limit, let's delete the first entry.         filename = all_files[0][1] + all_files[0][2]         remove(filename)         del all_files[0]         length = len(all_files) ", "after_version": " import random from html import escape from os import remove import werkzeug.utils import magic from flask import Flask, abort, request from PIL import Image def uploadimage():     ):  # if it is not over the limit, it will skip. if it is, it does this.         # if we have gone over our cache limit, let's delete the first entry.         filename = all_files[0][1] + all_files[0][2]         remove(werkzeug.utils.secure_filename(filename))         del all_files[0]         length = len(all_files) ", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2022-23611", "cwe_id": "{'CWE-78'}", "score": 6.4, "chain": "{'https://github.com/bildsben/iTunesRPC-Remastered/commit/cdcd48bbc44009ddcbd07a809b87376dc9ce37f4'}", "dataset": "nvd", "summary": "iTunesRPC-Remastered is a Discord Rich Presence for iTunes on Windows utility. In affected versions iTunesRPC-Remastered did not properly sanitize image file paths leading to OS level command injection. This issue has been patched in commit cdcd48b. Users are advised to upgrade.", "published_date": "2022-02-04", "chain_len": 1, "project": "https://github.com/bildsben/iTunesRPC-Remastered", "commit_href": "https://github.com/bildsben/iTunesRPC-Remastered/commit/cdcd48bbc44009ddcbd07a809b87376dc9ce37f4", "commit_sha": "cdcd48bbc44009ddcbd07a809b87376dc9ce37f4", "patch": "SINGLE", "chain_ord": "['cdcd48bbc44009ddcbd07a809b87376dc9ce37f4']", "before_first_fix_commit": "{'cbcea0a2c3e21f3a80675576792e783da59457cd'}", "last_fix_commit": "cdcd48bbc44009ddcbd07a809b87376dc9ce37f4", "chain_ord_pos": 1, "commit_datetime": "02/02/2022, 20:06:56", "message": "small fix", "author": "Ben", "comments": null, "stats": "{'additions': 3, 'deletions': 1, 'total': 4}", "files": {"module/connect_to_server.py": {"additions": 3, "deletions": 1, "changes": 4, "status": "modified", "raw_url": "https://github.com/bildsben/iTunesRPC-Remastered/raw/cdcd48bbc44009ddcbd07a809b87376dc9ce37f4/module%2Fconnect_to_server.py", "patch": "@@ -24,9 +24,11 @@ def get(image_file, domain, title, singer, album):\n     import json\n     import os\n     from html import unescape\n-\n+    import werkzeug.utils\n     import requests\n \n+    image_file = werkzeug.utils.secure_filename(ast.literal_eval(image_file))\n+\n     api = f\"http://{domain}:7873/bGVhdmVfcmlnaHRfbm93\"\n \n     with open(image_file, \"rb\") as f:"}}, "prior_version": " def get(image_file, domain, title, singer, album):     import json     import os     from html import unescape      import requests      api = f\"http://{domain}:7873/bGVhdmVfcmlnaHRfbm93\"      with open(image_file, \"rb\") as f:", "after_version": " def get(image_file, domain, title, singer, album):     import json     import os     from html import unescape     import werkzeug.utils     import requests      image_file = werkzeug.utils.secure_filename(ast.literal_eval(image_file))      api = f\"http://{domain}:7873/bGVhdmVfcmlnaHRfbm93\"      with open(image_file, \"rb\") as f:", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2022-31137", "cwe_id": "{'CWE-78'}", "score": 10.0, "chain": "{'https://github.com/hap-wi/roxy-wi/commit/82666df1e60c45dd6aa533b01a392f015d32f755'}", "dataset": "nvd", "summary": "Roxy-WI is a web interface for managing Haproxy, Nginx, Apache and Keepalived servers. Versions prior to 6.1.1.0 are subject to a remote code execution vulnerability. System commands can be run remotely via the subprocess_execute function without processing the inputs received from the user in the /app/options.py file. Attackers need not be authenticated to exploit this vulnerability. Users are advised to upgrade. There are no known workarounds for this vulnerability.", "published_date": "2022-07-08", "chain_len": 1, "project": "https://github.com/hap-wi/roxy-wi", "commit_href": "https://github.com/hap-wi/roxy-wi/commit/82666df1e60c45dd6aa533b01a392f015d32f755", "commit_sha": "82666df1e60c45dd6aa533b01a392f015d32f755", "patch": "SINGLE", "chain_ord": "['82666df1e60c45dd6aa533b01a392f015d32f755']", "before_first_fix_commit": "{'1fbcce83c0adae231f0652932757e0e3ecea033f'}", "last_fix_commit": "82666df1e60c45dd6aa533b01a392f015d32f755", "chain_ord_pos": 1, "commit_datetime": "07/08/2022, 17:43:13", "message": "v6.1.1.0\n\nChange log: https://roxy-wi.org/changelog.py#6_1_1", "author": "Pavel Loginov", "comments": null, "stats": "{'additions': 52, 'deletions': 188, 'total': 240}", "files": {"app/options.py": {"additions": 52, "deletions": 188, "changes": 240, "status": "modified", "raw_url": "https://github.com/hap-wi/roxy-wi/raw/82666df1e60c45dd6aa533b01a392f015d32f755/app%2Foptions.py", "patch": "@@ -61,10 +61,7 @@\n         print(e)\n \n if form.getvalue('getcert') is not None and serv is not None:\n-    cert_id = form.getvalue('getcert')\n-    if funct.checkAjaxInput(cert_id):\n-        print('error: Nice try')\n-        sys.exit()\n+    cert_id = funct.checkAjaxInput(form.getvalue('getcert'))\n \n     cert_path = sql.get_setting('cert_path')\n     commands = [\"openssl x509 -in \" + cert_path + \"/\" + cert_id + \" -text\"]\n@@ -74,10 +71,8 @@\n         print('error: Cannot connect to the server ' + e.args[0])\n \n if form.getvalue('delcert') is not None and serv is not None:\n-    if funct.checkAjaxInput(cert_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    cert_id = form.getvalue('delcert')\n+    cert_id = funct.checkAjaxInput(cert_id)\n     cert_path = sql.get_setting('cert_path')\n     commands = [\"sudo rm -f \" + cert_path + \"/\" + cert_id]\n     try:\n@@ -96,10 +91,7 @@\n     if form.getvalue('ssl_name') is None:\n         print('error: Please enter a desired name')\n     else:\n-        name = form.getvalue('ssl_name')\n-        if funct.checkAjaxInput(name):\n-            print('error: Nice try')\n-            sys.exit()\n+        name = funct.checkAjaxInput(form.getvalue('ssl_name'))\n \n     try:\n         with open(name, \"w\") as ssl_cert:\n@@ -132,10 +124,7 @@\n \n if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is None:\n     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))\n-    backend = form.getvalue('ipbackend')\n-    if funct.checkAjaxInput(backend):\n-        print('error: Nice try')\n-        sys.exit()\n+    backend = funct.checkAjaxInput(form.getvalue('ipbackend'))\n     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |awk \\'{print $4}\\'' % (serv, haproxy_sock_port, backend)\n     output, stderr = funct.subprocess_execute(cmd)\n     for i in output:\n@@ -146,23 +135,18 @@\n \n if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is not None:\n     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))\n-    backend = form.getvalue('ipbackend')\n-    backend_server = form.getvalue('backend_server')\n-    if funct.checkAjaxInput(backend) or funct.checkAjaxInput(backend_server):\n-        print('error: Nice try')\n-        sys.exit()\n+    backend = funct.checkAjaxInput(form.getvalue('ipbackend'))\n+    backend_server = funct.checkAjaxInput(form.getvalue('backend_server'))\n     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |grep \"%s\" |awk \\'{print $5\":\"$19}\\' |head -1' % (serv, haproxy_sock_port, backend, backend_server)\n     output, stderr = funct.subprocess_execute(cmd)\n     print(output[0])\n \n if form.getvalue('backend_ip') is not None:\n-    backend_backend = form.getvalue('backend_backend')\n-    backend_server = form.getvalue('backend_server')\n-    backend_ip = form.getvalue('backend_ip')\n-    backend_port = form.getvalue('backend_port')\n-    if any((funct.checkAjaxInput(backend_backend), funct.checkAjaxInput(backend_server), funct.checkAjaxInput(backend_ip), funct.checkAjaxInput(backend_port))):\n-        print('error: Nice try')\n-        sys.exit()\n+    backend_backend = funct.checkAjaxInput(form.getvalue('backend_backend'))\n+    backend_server = funct.checkAjaxInput(form.getvalue('backend_server'))\n+    backend_ip = funct.checkAjaxInput(form.getvalue('backend_ip'))\n+    backend_port = funct.checkAjaxInput(form.getvalue('backend_port'))\n+\n     if form.getvalue('backend_ip') is None:\n         print('error: Backend IP must be IP and not 0')\n         sys.exit()\n@@ -211,19 +195,13 @@\n         stderr = funct.master_slave_upload_and_restart(serv, cfg, just_save='save')\n \n if form.getvalue('maxconn_select') is not None:\n-    serv = form.getvalue('maxconn_select')\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n+    serv = funct.checkAjaxInput(form.getvalue('maxconn_select'))\n     funct.get_backends_from_config(serv, backends='frontend')\n \n if form.getvalue('maxconn_frontend') is not None:\n-    frontend = form.getvalue('maxconn_frontend')\n-    maxconn = form.getvalue('maxconn_int')\n+    frontend = funct.checkAjaxInput(form.getvalue('maxconn_frontend'))\n+    maxconn = funct.checkAjaxInput(form.getvalue('maxconn_int'))\n \n-    if funct.checkAjaxInput(frontend) or funct.checkAjaxInput(maxconn):\n-        print('error: Nice try')\n-        sys.exit()\n     if form.getvalue('maxconn_int') is None:\n         print('error: Maxconn must be integer and not 0')\n         sys.exit()\n@@ -297,12 +275,8 @@\n \n if form.getvalue('ip_for_delete') is not None:\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n-    ip = form.getvalue('ip_for_delete')\n-    table = form.getvalue('table_for_delete')\n-\n-    if funct.checkAjaxInput(ip) or funct.checkAjaxInput(table):\n-        print('error: Nice try')\n-        sys.exit()\n+    ip = funct.checkAjaxInput(form.getvalue('ip_for_delete'))\n+    table = funct.checkAjaxInput(form.getvalue('table_for_delete'))\n \n     cmd = 'echo \"clear table %s key %s\" |nc %s %s' % (table, ip, serv, haproxy_sock_port)\n     output, stderr = funct.subprocess_execute(cmd)\n@@ -311,11 +285,7 @@\n \n if form.getvalue('table_for_clear') is not None:\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n-    table = form.getvalue('table_for_clear')\n-\n-    if funct.checkAjaxInput(table):\n-        print('error: Nice try')\n-        sys.exit()\n+    table = funct.checkAjaxInput(form.getvalue('table_for_clear'))\n \n     cmd = 'echo \"clear table %s \" |nc %s %s' % (table, serv, haproxy_sock_port)\n     output, stderr = funct.subprocess_execute(cmd)\n@@ -334,12 +304,8 @@\n     env = Environment(loader=FileSystemLoader('templates/'), autoescape=True,\n                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)\n     template = env.get_template('ajax/list.html')\n-    list_id = form.getvalue('list_select_id')\n-    list_name = form.getvalue('list_select_name')\n-\n-    if funct.checkAjaxInput(list_id) or funct.checkAjaxInput(list_name):\n-        print('error: Nice try')\n-        sys.exit()\n+    list_id = funct.checkAjaxInput(form.getvalue('list_select_id'))\n+    list_name = funct.checkAjaxInput(form.getvalue('list_select_name'))\n \n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n     cmd = 'echo \"show acl #%s\"|nc %s %s' % (list_id, serv, haproxy_sock_port)\n@@ -351,17 +317,12 @@\n if form.getvalue('list_id_for_delete') is not None:\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n     lists_path = sql.get_setting('lists_path')\n-    lib_path = funct.get_config_var('main', 'lib_path')\n-    ip_id = form.getvalue('list_ip_id_for_delete')\n-    ip = form.getvalue('list_ip_for_delete')\n-    list_id = form.getvalue('list_id_for_delete')\n-    list_name = form.getvalue('list_name')\n-    user_group = funct.get_user_group(id=1)\n-\n-    if any((funct.checkAjaxInput(ip_id), funct.checkAjaxInput(ip), funct.checkAjaxInput(list_id), funct.checkAjaxInput(list_name))):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    lib_path = funct.checkAjaxInput(funct.get_config_var('main', 'lib_path'))\n+    ip_id = funct.checkAjaxInput(form.getvalue('list_ip_id_for_delete'))\n+    ip = funct.checkAjaxInput(form.getvalue('list_ip_for_delete'))\n+    list_id = funct.checkAjaxInput(form.getvalue('list_id_for_delete'))\n+    list_name = funct.checkAjaxInput(form.getvalue('list_name'))\n+    user_group = funct.checkAjaxInput(funct.get_user_group(id=1))\n     cmd = \"sed -i 's!%s$!!' %s/%s/%s/%s\" % (ip, lib_path, lists_path, user_group, list_name)\n     cmd1 = \"sed -i '/^$/d' %s/%s/%s/%s\" % (lib_path, lists_path, user_group, list_name)\n     output, stderr = funct.subprocess_execute(cmd)\n@@ -392,14 +353,9 @@\n     ip = form.getvalue('list_ip_for_add')\n     ip = ip.strip()\n     ip = funct.is_ip_or_dns(ip)\n-    list_id = form.getvalue('list_id_for_add')\n-    list_name = form.getvalue('list_name')\n-    user_group = funct.get_user_group(id=1)\n-\n-    if any((funct.checkAjaxInput(lists_path), funct.checkAjaxInput(list_id), funct.checkAjaxInput(list_name))):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    list_id = funct.checkAjaxInput(form.getvalue('list_id_for_add'))\n+    list_name = funct.checkAjaxInput(form.getvalue('list_name'))\n+    user_group = funct.checkAjaxInput(funct.get_user_group(id=1))\n     cmd = 'echo \"add acl #%s %s\" |nc %s %s' % (list_id, ip, serv, haproxy_sock_port)\n     output, stderr = funct.subprocess_execute(cmd)\n     if output[0]:\n@@ -423,15 +379,7 @@\n \n     env = Environment(loader=FileSystemLoader('templates'), autoescape=True,\n                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)\n-    serv = form.getvalue('sessions_select')\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n+    serv = funct.checkAjaxInput(form.getvalue('sessions_select'))\n \n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n \n@@ -444,16 +392,11 @@\n     print(template)\n \n if form.getvalue('sessions_select_show') is not None:\n-    serv = form.getvalue('sessions_select_show')\n-    sess_id = form.getvalue('sessions_select_id')\n-\n-    if funct.checkAjaxInput(serv) or funct.checkAjaxInput(sess_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    serv = funct.checkAjaxInput(form.getvalue('sessions_select_show'))\n+    sess_id = funct.checkAjaxInput(form.getvalue('sessions_select_id'))\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n-\n     cmd = 'echo \"show sess %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)\n+\n     output, stderr = funct.subprocess_execute(cmd)\n \n     if stderr:\n@@ -464,16 +407,7 @@\n \n if form.getvalue('session_delete_id') is not None:\n     haproxy_sock_port = sql.get_setting('haproxy_sock_port')\n-    sess_id = form.getvalue('session_delete_id')\n-\n-    if funct.checkAjaxInput(sess_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(sess_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    sess_id = funct.checkAjaxInput(form.getvalue('session_delete_id'))\n     cmd = 'echo \"shutdown session %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)\n     output, stderr = funct.subprocess_execute(cmd)\n     if output[0] != '':\n@@ -597,15 +531,7 @@\n     print(\"success: Apache has been %s\" % action)\n \n if form.getvalue('action_service') is not None:\n-    action = form.getvalue('action_service')\n-\n-    if funct.checkAjaxInput(action):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(action):\n-        print('error: Nice try')\n-        sys.exit()\n+    action = funct.checkAjaxInput(form.getvalue('action_service'))\n \n     if action not in ('start', 'stop', 'restart'):\n         print('error: wrong action')\n@@ -1233,12 +1159,8 @@ async def get_runner_overviewServers(**kwargs):\n if form.getvalue('servaction') is not None:\n     server_state_file = sql.get_setting('server_state_file')\n     haproxy_sock = sql.get_setting('haproxy_sock')\n-    enable = form.getvalue('servaction')\n-    backend = form.getvalue('servbackend')\n-\n-    if funct.checkAjaxInput(enable) or funct.checkAjaxInput(backend):\n-        print('error: Nice try')\n-        sys.exit()\n+    enable = funct.checkAjaxInput(form.getvalue('servaction'))\n+    backend = funct.checkAjaxInput(form.getvalue('servbackend'))\n \n     cmd = 'echo \"{} {}\" |sudo socat stdio {}'.format(enable, backend, haproxy_sock)\n \n@@ -1281,12 +1203,8 @@ async def get_runner_overviewServers(**kwargs):\n if serv is not None and form.getvalue('right') is not None:\n     from jinja2 import Environment, FileSystemLoader\n \n-    left = form.getvalue('left')\n-    right = form.getvalue('right')\n-\n-    if funct.checkAjaxInput(left) or funct.checkAjaxInput(right):\n-        print('error: Nice try')\n-        sys.exit()\n+    left = funct.checkAjaxInput(form.getvalue('left'))\n+    right = funct.checkAjaxInput(form.getvalue('right'))\n \n     if form.getvalue('service') == 'nginx':\n         configs_dir = funct.get_config_var('configs', 'nginx_save_configs_dir')\n@@ -2554,15 +2472,7 @@ async def get_runner_overviewServers(**kwargs):\n \n if form.getvalue('sshdel') is not None:\n     lib_path = funct.get_config_var('main', 'lib_path')\n-    sshdel = form.getvalue('sshdel')\n-\n-    if funct.checkAjaxInput(sshdel):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(sshdel):\n-        print('error: Nice try')\n-        sys.exit()\n+    sshdel = funct.checkAjaxInput(form.getvalue('sshdel'))\n \n     for sshs in sql.select_ssh(id=sshdel):\n         ssh_enable = sshs.enable\n@@ -2612,11 +2522,7 @@ async def get_runner_overviewServers(**kwargs):\n     import paramiko\n \n     user_group = funct.get_user_group()\n-    name = form.getvalue('name')\n-\n-    if funct.checkAjaxInput(name):\n-        print('error: Nice try')\n-        sys.exit()\n+    name = funct.checkAjaxInput(form.getvalue('name'))\n \n     try:\n         key = paramiko.pkey.load_private_key(form.getvalue('ssh_cert'))\n@@ -2913,11 +2819,7 @@ async def get_runner_overviewServers(**kwargs):\n         funct.logging('SMON', ' Has been update the server ' + ip + ' to SMON ', haproxywi=1, login=1)\n \n if form.getvalue('showBytes') is not None:\n-    serv = form.getvalue('showBytes')\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n+    serv = funct.checkAjaxInput(form.getvalue('showBytes'))\n \n     port = sql.get_setting('haproxy_sock_port')\n     bin_bout = []\n@@ -2970,12 +2872,8 @@ async def get_runner_overviewServers(**kwargs):\n         print('error: cannot connect to Nginx stat page')\n \n if form.getvalue('waf_rule_id'):\n-    enable = form.getvalue('waf_en')\n-    rule_id = form.getvalue('waf_rule_id')\n-\n-    if funct.checkAjaxInput(enable) or funct.checkAjaxInput(rule_id):\n-        print('error: Nice try')\n-        sys.exit()\n+    enable = funct.checkAjaxInput(form.getvalue('waf_en'))\n+    rule_id = funct.checkAjaxInput(form.getvalue('waf_rule_id'))\n \n     haproxy_path = sql.get_setting('haproxy_dir')\n     rule_file = sql.select_waf_rule_by_id(rule_id)\n@@ -3051,15 +2949,7 @@ async def get_runner_overviewServers(**kwargs):\n     os.system(\"rm -f %s\" % script)\n \n if form.getvalue('uploadovpn'):\n-    name = form.getvalue('ovpnname')\n-\n-    if funct.checkAjaxInput(name):\n-        print('error: Nice try')\n-        sys.exit()\n-\n-    if funct.checkAjaxInput(name):\n-        print('error: Nice try')\n-        sys.exit()\n+    name = funct.checkAjaxInput(form.getvalue('ovpnname'))\n \n     ovpn_file = os.path.dirname('/tmp/') + \"/\" + name + '.ovpn'\n \n@@ -3087,11 +2977,7 @@ async def get_runner_overviewServers(**kwargs):\n     funct.logging(\"localhost\", \" has been uploaded a new ovpn file %s\" % ovpn_file, haproxywi=1, login=1)\n \n if form.getvalue('openvpndel') is not None:\n-    openvpndel = form.getvalue('openvpndel')\n-\n-    if funct.checkAjaxInput(openvpndel):\n-        print('error: Nice try')\n-        sys.exit()\n+    openvpndel = funct.checkAjaxInput(form.getvalue('openvpndel'))\n \n     cmd = 'sudo openvpn3 config-remove --config /tmp/%s.ovpn --force' % openvpndel\n     try:\n@@ -3103,12 +2989,8 @@ async def get_runner_overviewServers(**kwargs):\n         funct.logging('localhost', e.args[0], haproxywi=1)\n \n if form.getvalue('actionvpn') is not None:\n-    openvpn = form.getvalue('openvpnprofile')\n-    action = form.getvalue('actionvpn')\n-\n-    if funct.checkAjaxInput(openvpn) or funct.checkAjaxInput(action):\n-        print('error: Nice try')\n-        sys.exit()\n+    openvpn = funct.checkAjaxInput(form.getvalue('openvpnprofile'))\n+    action = funct.checkAjaxInput(form.getvalue('actionvpn'))\n \n     if action == 'start':\n         cmd = 'sudo openvpn3 session-start --config /tmp/%s.ovpn' % openvpn\n@@ -3125,12 +3007,7 @@ async def get_runner_overviewServers(**kwargs):\n         funct.logging('localhost', e.args[0], haproxywi=1)\n \n if form.getvalue('scan_ports') is not None:\n-    serv_id = form.getvalue('scan_ports')\n-\n-    if funct.checkAjaxInput(serv_id):\n-        print('error: Nice try')\n-        sys.exit()\n-\n+    serv_id = funct.checkAjaxInput(form.getvalue('scan_ports'))\n     server = sql.select_servers(id=serv_id)\n     ip = ''\n \n@@ -3154,11 +3031,7 @@ async def get_runner_overviewServers(**kwargs):\n         print(template)\n \n if form.getvalue('viewFirewallRules') is not None:\n-    serv = form.getvalue('viewFirewallRules')\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n+    serv = funct.checkAjaxInput(form.getvalue('viewFirewallRules'))\n \n     cmd = [\"sudo iptables -L INPUT -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"]\n     cmd1 = [\"sudo iptables -L IN_public_allow -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"]\n@@ -3186,11 +3059,6 @@ async def get_runner_overviewServers(**kwargs):\n \n if form.getvalue('geoipserv') is not None:\n     serv = form.getvalue('geoipserv')\n-\n-    if funct.checkAjaxInput(serv):\n-        print('error: Nice try')\n-        sys.exit()\n-\n     haproxy_dir = sql.get_setting('haproxy_dir')\n \n     cmd = [\"ls \" + haproxy_dir + \"/geoip/\"]\n@@ -4531,12 +4399,8 @@ async def get_runner_overviewServers(**kwargs):\n     user_uuid = cookie.get('uuid')\n     user_id = sql.get_user_id_by_uuid(user_uuid.value)\n     user_services = sql.select_user_services(user_id)\n-    server_id = form.getvalue('server_id')\n-    service = form.getvalue('service')\n-\n-    if funct.checkAjaxInput(server_id) or funct.checkAjaxInput(service):\n-        print('error: Nice try')\n-        sys.exit()\n+    server_id = funct.checkAjaxInput(form.getvalue('server_id'))\n+    service = funct.checkAjaxInput(form.getvalue('service'))\n \n     if '1' in user_services:\n         if service == 'haproxy':"}}, "prior_version": "         print(e)  if form.getvalue('getcert') is not None and serv is not None:     cert_id = form.getvalue('getcert')     if funct.checkAjaxInput(cert_id):         print('error: Nice try')         sys.exit()      cert_path = sql.get_setting('cert_path')     commands = [\"openssl x509 -in \" + cert_path + \"/\" + cert_id + \" -text\"]         print('error: Cannot connect to the server ' + e.args[0])  if form.getvalue('delcert') is not None and serv is not None:     if funct.checkAjaxInput(cert_id):         print('error: Nice try')         sys.exit()      cert_path = sql.get_setting('cert_path')     commands = [\"sudo rm -f \" + cert_path + \"/\" + cert_id]     try:     if form.getvalue('ssl_name') is None:         print('error: Please enter a desired name')     else:         name = form.getvalue('ssl_name')         if funct.checkAjaxInput(name):             print('error: Nice try')             sys.exit()      try:         with open(name, \"w\") as ssl_cert:  if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is None:     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))     backend = form.getvalue('ipbackend')     if funct.checkAjaxInput(backend):         print('error: Nice try')         sys.exit()     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |awk \\'{print $4}\\'' % (serv, haproxy_sock_port, backend)     output, stderr = funct.subprocess_execute(cmd)     for i in output:  if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is not None:     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))     backend = form.getvalue('ipbackend')     backend_server = form.getvalue('backend_server')     if funct.checkAjaxInput(backend) or funct.checkAjaxInput(backend_server):         print('error: Nice try')         sys.exit()     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |grep \"%s\" |awk \\'{print $5\":\"$19}\\' |head -1' % (serv, haproxy_sock_port, backend, backend_server)     output, stderr = funct.subprocess_execute(cmd)     print(output[0])  if form.getvalue('backend_ip') is not None:     backend_backend = form.getvalue('backend_backend')     backend_server = form.getvalue('backend_server')     backend_ip = form.getvalue('backend_ip')     backend_port = form.getvalue('backend_port')     if any((funct.checkAjaxInput(backend_backend), funct.checkAjaxInput(backend_server), funct.checkAjaxInput(backend_ip), funct.checkAjaxInput(backend_port))):         print('error: Nice try')         sys.exit()     if form.getvalue('backend_ip') is None:         print('error: Backend IP must be IP and not 0')         sys.exit()         stderr = funct.master_slave_upload_and_restart(serv, cfg, just_save='save')  if form.getvalue('maxconn_select') is not None:     serv = form.getvalue('maxconn_select')     if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()     funct.get_backends_from_config(serv, backends='frontend')  if form.getvalue('maxconn_frontend') is not None:     frontend = form.getvalue('maxconn_frontend')     maxconn = form.getvalue('maxconn_int')      if funct.checkAjaxInput(frontend) or funct.checkAjaxInput(maxconn):         print('error: Nice try')         sys.exit()     if form.getvalue('maxconn_int') is None:         print('error: Maxconn must be integer and not 0')         sys.exit()  if form.getvalue('ip_for_delete') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     ip = form.getvalue('ip_for_delete')     table = form.getvalue('table_for_delete')      if funct.checkAjaxInput(ip) or funct.checkAjaxInput(table):         print('error: Nice try')         sys.exit()      cmd = 'echo \"clear table %s key %s\" |nc %s %s' % (table, ip, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)  if form.getvalue('table_for_clear') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     table = form.getvalue('table_for_clear')      if funct.checkAjaxInput(table):         print('error: Nice try')         sys.exit()      cmd = 'echo \"clear table %s \" |nc %s %s' % (table, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     env = Environment(loader=FileSystemLoader('templates/'), autoescape=True,                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)     template = env.get_template('ajax/list.html')     list_id = form.getvalue('list_select_id')     list_name = form.getvalue('list_select_name')      if funct.checkAjaxInput(list_id) or funct.checkAjaxInput(list_name):         print('error: Nice try')         sys.exit()      haproxy_sock_port = sql.get_setting('haproxy_sock_port')     cmd = 'echo \"show acl #%s\"|nc %s %s' % (list_id, serv, haproxy_sock_port) if form.getvalue('list_id_for_delete') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     lists_path = sql.get_setting('lists_path')     lib_path = funct.get_config_var('main', 'lib_path')     ip_id = form.getvalue('list_ip_id_for_delete')     ip = form.getvalue('list_ip_for_delete')     list_id = form.getvalue('list_id_for_delete')     list_name = form.getvalue('list_name')     user_group = funct.get_user_group(id=1)      if any((funct.checkAjaxInput(ip_id), funct.checkAjaxInput(ip), funct.checkAjaxInput(list_id), funct.checkAjaxInput(list_name))):         print('error: Nice try')         sys.exit()      cmd = \"sed -i 's!%s$!!' %s/%s/%s/%s\" % (ip, lib_path, lists_path, user_group, list_name)     cmd1 = \"sed -i '/^$/d' %s/%s/%s/%s\" % (lib_path, lists_path, user_group, list_name)     output, stderr = funct.subprocess_execute(cmd)     ip = form.getvalue('list_ip_for_add')     ip = ip.strip()     ip = funct.is_ip_or_dns(ip)     list_id = form.getvalue('list_id_for_add')     list_name = form.getvalue('list_name')     user_group = funct.get_user_group(id=1)      if any((funct.checkAjaxInput(lists_path), funct.checkAjaxInput(list_id), funct.checkAjaxInput(list_name))):         print('error: Nice try')         sys.exit()      cmd = 'echo \"add acl #%s %s\" |nc %s %s' % (list_id, ip, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     if output[0]:      env = Environment(loader=FileSystemLoader('templates'), autoescape=True,                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)     serv = form.getvalue('sessions_select')      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      haproxy_sock_port = sql.get_setting('haproxy_sock_port')      print(template)  if form.getvalue('sessions_select_show') is not None:     serv = form.getvalue('sessions_select_show')     sess_id = form.getvalue('sessions_select_id')      if funct.checkAjaxInput(serv) or funct.checkAjaxInput(sess_id):         print('error: Nice try')         sys.exit()      haproxy_sock_port = sql.get_setting('haproxy_sock_port')      cmd = 'echo \"show sess %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)      if stderr:  if form.getvalue('session_delete_id') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     sess_id = form.getvalue('session_delete_id')      if funct.checkAjaxInput(sess_id):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(sess_id):         print('error: Nice try')         sys.exit()      cmd = 'echo \"shutdown session %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     if output[0] != '':     print(\"success: Apache has been %s\" % action)  if form.getvalue('action_service') is not None:     action = form.getvalue('action_service')      if funct.checkAjaxInput(action):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(action):         print('error: Nice try')         sys.exit()      if action not in ('start', 'stop', 'restart'):         print('error: wrong action') async def get_runner_overviewServers(**kwargs): if form.getvalue('servaction') is not None:     server_state_file = sql.get_setting('server_state_file')     haproxy_sock = sql.get_setting('haproxy_sock')     enable = form.getvalue('servaction')     backend = form.getvalue('servbackend')      if funct.checkAjaxInput(enable) or funct.checkAjaxInput(backend):         print('error: Nice try')         sys.exit()      cmd = 'echo \"{} {}\" |sudo socat stdio {}'.format(enable, backend, haproxy_sock)  async def get_runner_overviewServers(**kwargs): if serv is not None and form.getvalue('right') is not None:     from jinja2 import Environment, FileSystemLoader      left = form.getvalue('left')     right = form.getvalue('right')      if funct.checkAjaxInput(left) or funct.checkAjaxInput(right):         print('error: Nice try')         sys.exit()      if form.getvalue('service') == 'nginx':         configs_dir = funct.get_config_var('configs', 'nginx_save_configs_dir') async def get_runner_overviewServers(**kwargs):  if form.getvalue('sshdel') is not None:     lib_path = funct.get_config_var('main', 'lib_path')     sshdel = form.getvalue('sshdel')      if funct.checkAjaxInput(sshdel):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(sshdel):         print('error: Nice try')         sys.exit()      for sshs in sql.select_ssh(id=sshdel):         ssh_enable = sshs.enable async def get_runner_overviewServers(**kwargs):     import paramiko      user_group = funct.get_user_group()     name = form.getvalue('name')      if funct.checkAjaxInput(name):         print('error: Nice try')         sys.exit()      try:         key = paramiko.pkey.load_private_key(form.getvalue('ssh_cert')) async def get_runner_overviewServers(**kwargs):         funct.logging('SMON', ' Has been update the server ' + ip + ' to SMON ', haproxywi=1, login=1)  if form.getvalue('showBytes') is not None:     serv = form.getvalue('showBytes')      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      port = sql.get_setting('haproxy_sock_port')     bin_bout = [] async def get_runner_overviewServers(**kwargs):         print('error: cannot connect to Nginx stat page')  if form.getvalue('waf_rule_id'):     enable = form.getvalue('waf_en')     rule_id = form.getvalue('waf_rule_id')      if funct.checkAjaxInput(enable) or funct.checkAjaxInput(rule_id):         print('error: Nice try')         sys.exit()      haproxy_path = sql.get_setting('haproxy_dir')     rule_file = sql.select_waf_rule_by_id(rule_id) async def get_runner_overviewServers(**kwargs):     os.system(\"rm -f %s\" % script)  if form.getvalue('uploadovpn'):     name = form.getvalue('ovpnname')      if funct.checkAjaxInput(name):         print('error: Nice try')         sys.exit()      if funct.checkAjaxInput(name):         print('error: Nice try')         sys.exit()      ovpn_file = os.path.dirname('/tmp/') + \"/\" + name + '.ovpn'  async def get_runner_overviewServers(**kwargs):     funct.logging(\"localhost\", \" has been uploaded a new ovpn file %s\" % ovpn_file, haproxywi=1, login=1)  if form.getvalue('openvpndel') is not None:     openvpndel = form.getvalue('openvpndel')      if funct.checkAjaxInput(openvpndel):         print('error: Nice try')         sys.exit()      cmd = 'sudo openvpn3 config-remove --config /tmp/%s.ovpn --force' % openvpndel     try: async def get_runner_overviewServers(**kwargs):         funct.logging('localhost', e.args[0], haproxywi=1)  if form.getvalue('actionvpn') is not None:     openvpn = form.getvalue('openvpnprofile')     action = form.getvalue('actionvpn')      if funct.checkAjaxInput(openvpn) or funct.checkAjaxInput(action):         print('error: Nice try')         sys.exit()      if action == 'start':         cmd = 'sudo openvpn3 session-start --config /tmp/%s.ovpn' % openvpn async def get_runner_overviewServers(**kwargs):         funct.logging('localhost', e.args[0], haproxywi=1)  if form.getvalue('scan_ports') is not None:     serv_id = form.getvalue('scan_ports')      if funct.checkAjaxInput(serv_id):         print('error: Nice try')         sys.exit()      server = sql.select_servers(id=serv_id)     ip = ''  async def get_runner_overviewServers(**kwargs):         print(template)  if form.getvalue('viewFirewallRules') is not None:     serv = form.getvalue('viewFirewallRules')      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      cmd = [\"sudo iptables -L INPUT -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"]     cmd1 = [\"sudo iptables -L IN_public_allow -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"] async def get_runner_overviewServers(**kwargs):  if form.getvalue('geoipserv') is not None:     serv = form.getvalue('geoipserv')      if funct.checkAjaxInput(serv):         print('error: Nice try')         sys.exit()      haproxy_dir = sql.get_setting('haproxy_dir')      cmd = [\"ls \" + haproxy_dir + \"/geoip/\"] async def get_runner_overviewServers(**kwargs):     user_uuid = cookie.get('uuid')     user_id = sql.get_user_id_by_uuid(user_uuid.value)     user_services = sql.select_user_services(user_id)     server_id = form.getvalue('server_id')     service = form.getvalue('service')      if funct.checkAjaxInput(server_id) or funct.checkAjaxInput(service):         print('error: Nice try')         sys.exit()      if '1' in user_services:         if service == 'haproxy':", "after_version": "         print(e)  if form.getvalue('getcert') is not None and serv is not None:     cert_id = funct.checkAjaxInput(form.getvalue('getcert'))      cert_path = sql.get_setting('cert_path')     commands = [\"openssl x509 -in \" + cert_path + \"/\" + cert_id + \" -text\"]         print('error: Cannot connect to the server ' + e.args[0])  if form.getvalue('delcert') is not None and serv is not None:     cert_id = form.getvalue('delcert')     cert_id = funct.checkAjaxInput(cert_id)     cert_path = sql.get_setting('cert_path')     commands = [\"sudo rm -f \" + cert_path + \"/\" + cert_id]     try:     if form.getvalue('ssl_name') is None:         print('error: Please enter a desired name')     else:         name = funct.checkAjaxInput(form.getvalue('ssl_name'))      try:         with open(name, \"w\") as ssl_cert:  if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is None:     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))     backend = funct.checkAjaxInput(form.getvalue('ipbackend'))     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |awk \\'{print $4}\\'' % (serv, haproxy_sock_port, backend)     output, stderr = funct.subprocess_execute(cmd)     for i in output:  if form.getvalue('ipbackend') is not None and form.getvalue('backend_server') is not None:     haproxy_sock_port = int(sql.get_setting('haproxy_sock_port'))     backend = funct.checkAjaxInput(form.getvalue('ipbackend'))     backend_server = funct.checkAjaxInput(form.getvalue('backend_server'))     cmd = 'echo \"show servers state\"|nc %s %s |grep \"%s\" |grep \"%s\" |awk \\'{print $5\":\"$19}\\' |head -1' % (serv, haproxy_sock_port, backend, backend_server)     output, stderr = funct.subprocess_execute(cmd)     print(output[0])  if form.getvalue('backend_ip') is not None:     backend_backend = funct.checkAjaxInput(form.getvalue('backend_backend'))     backend_server = funct.checkAjaxInput(form.getvalue('backend_server'))     backend_ip = funct.checkAjaxInput(form.getvalue('backend_ip'))     backend_port = funct.checkAjaxInput(form.getvalue('backend_port'))      if form.getvalue('backend_ip') is None:         print('error: Backend IP must be IP and not 0')         sys.exit()         stderr = funct.master_slave_upload_and_restart(serv, cfg, just_save='save')  if form.getvalue('maxconn_select') is not None:     serv = funct.checkAjaxInput(form.getvalue('maxconn_select'))     funct.get_backends_from_config(serv, backends='frontend')  if form.getvalue('maxconn_frontend') is not None:     frontend = funct.checkAjaxInput(form.getvalue('maxconn_frontend'))     maxconn = funct.checkAjaxInput(form.getvalue('maxconn_int'))      if form.getvalue('maxconn_int') is None:         print('error: Maxconn must be integer and not 0')         sys.exit()  if form.getvalue('ip_for_delete') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     ip = funct.checkAjaxInput(form.getvalue('ip_for_delete'))     table = funct.checkAjaxInput(form.getvalue('table_for_delete'))      cmd = 'echo \"clear table %s key %s\" |nc %s %s' % (table, ip, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)  if form.getvalue('table_for_clear') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     table = funct.checkAjaxInput(form.getvalue('table_for_clear'))      cmd = 'echo \"clear table %s \" |nc %s %s' % (table, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     env = Environment(loader=FileSystemLoader('templates/'), autoescape=True,                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)     template = env.get_template('ajax/list.html')     list_id = funct.checkAjaxInput(form.getvalue('list_select_id'))     list_name = funct.checkAjaxInput(form.getvalue('list_select_name'))      haproxy_sock_port = sql.get_setting('haproxy_sock_port')     cmd = 'echo \"show acl #%s\"|nc %s %s' % (list_id, serv, haproxy_sock_port) if form.getvalue('list_id_for_delete') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     lists_path = sql.get_setting('lists_path')     lib_path = funct.checkAjaxInput(funct.get_config_var('main', 'lib_path'))     ip_id = funct.checkAjaxInput(form.getvalue('list_ip_id_for_delete'))     ip = funct.checkAjaxInput(form.getvalue('list_ip_for_delete'))     list_id = funct.checkAjaxInput(form.getvalue('list_id_for_delete'))     list_name = funct.checkAjaxInput(form.getvalue('list_name'))     user_group = funct.checkAjaxInput(funct.get_user_group(id=1))     cmd = \"sed -i 's!%s$!!' %s/%s/%s/%s\" % (ip, lib_path, lists_path, user_group, list_name)     cmd1 = \"sed -i '/^$/d' %s/%s/%s/%s\" % (lib_path, lists_path, user_group, list_name)     output, stderr = funct.subprocess_execute(cmd)     ip = form.getvalue('list_ip_for_add')     ip = ip.strip()     ip = funct.is_ip_or_dns(ip)     list_id = funct.checkAjaxInput(form.getvalue('list_id_for_add'))     list_name = funct.checkAjaxInput(form.getvalue('list_name'))     user_group = funct.checkAjaxInput(funct.get_user_group(id=1))     cmd = 'echo \"add acl #%s %s\" |nc %s %s' % (list_id, ip, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     if output[0]:      env = Environment(loader=FileSystemLoader('templates'), autoescape=True,                       extensions=['jinja2.ext.loopcontrols', 'jinja2.ext.do'], trim_blocks=True, lstrip_blocks=True)     serv = funct.checkAjaxInput(form.getvalue('sessions_select'))      haproxy_sock_port = sql.get_setting('haproxy_sock_port')      print(template)  if form.getvalue('sessions_select_show') is not None:     serv = funct.checkAjaxInput(form.getvalue('sessions_select_show'))     sess_id = funct.checkAjaxInput(form.getvalue('sessions_select_id'))     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     cmd = 'echo \"show sess %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)      output, stderr = funct.subprocess_execute(cmd)      if stderr:  if form.getvalue('session_delete_id') is not None:     haproxy_sock_port = sql.get_setting('haproxy_sock_port')     sess_id = funct.checkAjaxInput(form.getvalue('session_delete_id'))     cmd = 'echo \"shutdown session %s\" |nc %s %s' % (sess_id, serv, haproxy_sock_port)     output, stderr = funct.subprocess_execute(cmd)     if output[0] != '':     print(\"success: Apache has been %s\" % action)  if form.getvalue('action_service') is not None:     action = funct.checkAjaxInput(form.getvalue('action_service'))      if action not in ('start', 'stop', 'restart'):         print('error: wrong action') async def get_runner_overviewServers(**kwargs): if form.getvalue('servaction') is not None:     server_state_file = sql.get_setting('server_state_file')     haproxy_sock = sql.get_setting('haproxy_sock')     enable = funct.checkAjaxInput(form.getvalue('servaction'))     backend = funct.checkAjaxInput(form.getvalue('servbackend'))      cmd = 'echo \"{} {}\" |sudo socat stdio {}'.format(enable, backend, haproxy_sock)  async def get_runner_overviewServers(**kwargs): if serv is not None and form.getvalue('right') is not None:     from jinja2 import Environment, FileSystemLoader      left = funct.checkAjaxInput(form.getvalue('left'))     right = funct.checkAjaxInput(form.getvalue('right'))      if form.getvalue('service') == 'nginx':         configs_dir = funct.get_config_var('configs', 'nginx_save_configs_dir') async def get_runner_overviewServers(**kwargs):  if form.getvalue('sshdel') is not None:     lib_path = funct.get_config_var('main', 'lib_path')     sshdel = funct.checkAjaxInput(form.getvalue('sshdel'))      for sshs in sql.select_ssh(id=sshdel):         ssh_enable = sshs.enable async def get_runner_overviewServers(**kwargs):     import paramiko      user_group = funct.get_user_group()     name = funct.checkAjaxInput(form.getvalue('name'))      try:         key = paramiko.pkey.load_private_key(form.getvalue('ssh_cert')) async def get_runner_overviewServers(**kwargs):         funct.logging('SMON', ' Has been update the server ' + ip + ' to SMON ', haproxywi=1, login=1)  if form.getvalue('showBytes') is not None:     serv = funct.checkAjaxInput(form.getvalue('showBytes'))      port = sql.get_setting('haproxy_sock_port')     bin_bout = [] async def get_runner_overviewServers(**kwargs):         print('error: cannot connect to Nginx stat page')  if form.getvalue('waf_rule_id'):     enable = funct.checkAjaxInput(form.getvalue('waf_en'))     rule_id = funct.checkAjaxInput(form.getvalue('waf_rule_id'))      haproxy_path = sql.get_setting('haproxy_dir')     rule_file = sql.select_waf_rule_by_id(rule_id) async def get_runner_overviewServers(**kwargs):     os.system(\"rm -f %s\" % script)  if form.getvalue('uploadovpn'):     name = funct.checkAjaxInput(form.getvalue('ovpnname'))      ovpn_file = os.path.dirname('/tmp/') + \"/\" + name + '.ovpn'  async def get_runner_overviewServers(**kwargs):     funct.logging(\"localhost\", \" has been uploaded a new ovpn file %s\" % ovpn_file, haproxywi=1, login=1)  if form.getvalue('openvpndel') is not None:     openvpndel = funct.checkAjaxInput(form.getvalue('openvpndel'))      cmd = 'sudo openvpn3 config-remove --config /tmp/%s.ovpn --force' % openvpndel     try: async def get_runner_overviewServers(**kwargs):         funct.logging('localhost', e.args[0], haproxywi=1)  if form.getvalue('actionvpn') is not None:     openvpn = funct.checkAjaxInput(form.getvalue('openvpnprofile'))     action = funct.checkAjaxInput(form.getvalue('actionvpn'))      if action == 'start':         cmd = 'sudo openvpn3 session-start --config /tmp/%s.ovpn' % openvpn async def get_runner_overviewServers(**kwargs):         funct.logging('localhost', e.args[0], haproxywi=1)  if form.getvalue('scan_ports') is not None:     serv_id = funct.checkAjaxInput(form.getvalue('scan_ports'))     server = sql.select_servers(id=serv_id)     ip = ''  async def get_runner_overviewServers(**kwargs):         print(template)  if form.getvalue('viewFirewallRules') is not None:     serv = funct.checkAjaxInput(form.getvalue('viewFirewallRules'))      cmd = [\"sudo iptables -L INPUT -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"]     cmd1 = [\"sudo iptables -L IN_public_allow -n --line-numbers|sed 's/  */ /g'|grep -v -E 'Chain|target'\"] async def get_runner_overviewServers(**kwargs):  if form.getvalue('geoipserv') is not None:     serv = form.getvalue('geoipserv')     haproxy_dir = sql.get_setting('haproxy_dir')      cmd = [\"ls \" + haproxy_dir + \"/geoip/\"] async def get_runner_overviewServers(**kwargs):     user_uuid = cookie.get('uuid')     user_id = sql.get_user_id_by_uuid(user_uuid.value)     user_services = sql.select_user_services(user_id)     server_id = funct.checkAjaxInput(form.getvalue('server_id'))     service = funct.checkAjaxInput(form.getvalue('service'))      if '1' in user_services:         if service == 'haproxy':", "file_extension": "py", "cwe": "CWE-78"}
{"vuln_id": "CVE-2022-31501", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/ChaoticOnyx/OnyxForum/commit/f25543dfc62a9694d7e4f67eebfa45e3de916053'}", "dataset": "nvd", "summary": "The ChaoticOnyx/OnyxForum repository before 2022-05-04 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-11", "chain_len": 1, "project": "https://github.com/ChaoticOnyx/OnyxForum", "commit_href": "https://github.com/ChaoticOnyx/OnyxForum/commit/f25543dfc62a9694d7e4f67eebfa45e3de916053", "commit_sha": "f25543dfc62a9694d7e4f67eebfa45e3de916053", "patch": "SINGLE", "chain_ord": "['f25543dfc62a9694d7e4f67eebfa45e3de916053']", "before_first_fix_commit": "{'4077b499a1ca213f3eb55b8321a4733d83531750'}", "last_fix_commit": "f25543dfc62a9694d7e4f67eebfa45e3de916053", "chain_ord_pos": 1, "commit_datetime": "05/04/2022, 21:40:28", "message": "fix(hub): absolute Path Traversal due to incorrect use of `send_file` call\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\r\n\r\n## Root Cause Analysis\r\n\r\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\r\n```\r\n>>> import os.path\r\n>>> static = \"path/to/mySafeStaticDir\"\r\n>>> malicious = \"/../../../../../etc/passwd\"\r\n>>> os.path.join(t,malicious)\r\n'/../../../../../etc/passwd'\r\n```\r\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\r\n\r\nIn this case, the problems occurs due to the following code :\r\nhttps://github.com/ChaoticOnyx/OnyxForum/blob/4077b499a1ca213f3eb55b8321a4733d83531750/modules/hub/hub/views.py#L493\r\n\r\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\r\n\r\n## Remediation\r\n\r\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `flask.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\r\n\r\n## References\r\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\r\n* github/securitylab#669\r\n\r\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*\r\n\r\nCo-authored-by: Porcupiney Hairs <porucpiney.hairs@protonmail.com>\r\nPR #63", "author": "porcupineyhairs", "comments": null, "stats": "{'additions': 3, 'deletions': 1, 'total': 4}", "files": {"modules/hub/hub/views.py": {"additions": 3, "deletions": 1, "changes": 4, "status": "modified", "raw_url": "https://github.com/ChaoticOnyx/OnyxForum/raw/f25543dfc62a9694d7e4f67eebfa45e3de916053/modules%2Fhub%2Fhub%2Fviews.py", "patch": "@@ -19,6 +19,8 @@\n from flaskbb.extensions import allows, db, celery\n from flaskbb.user.models import User, Group\n from flaskbb.forum.models import Post\n+from werkzeug.utils import safe_join \n+\n \n from hub.forms import ConfigEditForm, BanSearchForm, ConnectionSearchForm\n from hub.permissions import CanAccessServerHub, CanAccessServerHubAdditional, CanAccessServerHubManagement\n@@ -489,7 +491,7 @@ def get(self):\n         if server is None:\n             abort(404)\n \n-        file_path = os.path.join(server.logs_path, path)\n+        file_path = safe_join(server.logs_path, path)\n         return send_file(file_path, as_attachment=True)"}}, "prior_version": " from flaskbb.extensions import allows, db, celery from flaskbb.user.models import User, Group from flaskbb.forum.models import Post  from hub.forms import ConfigEditForm, BanSearchForm, ConnectionSearchForm from hub.permissions import CanAccessServerHub, CanAccessServerHubAdditional, CanAccessServerHubManagement def get(self):         if server is None:             abort(404)          file_path = os.path.join(server.logs_path, path)         return send_file(file_path, as_attachment=True)  ", "after_version": " from flaskbb.extensions import allows, db, celery from flaskbb.user.models import User, Group from flaskbb.forum.models import Post from werkzeug.utils import safe_join    from hub.forms import ConfigEditForm, BanSearchForm, ConnectionSearchForm from hub.permissions import CanAccessServerHub, CanAccessServerHubAdditional, CanAccessServerHubManagement def get(self):         if server is None:             abort(404)          file_path = safe_join(server.logs_path, path)         return send_file(file_path, as_attachment=True)  ", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2022-31502", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/operatorequals/wormnest/commit/2dfe96fc2570586ac487b399ac20d41b3c114861'}", "dataset": "nvd", "summary": "The operatorequals/wormnest repository through 0.4.7 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-11", "chain_len": 1, "project": "https://github.com/operatorequals/wormnest", "commit_href": "https://github.com/operatorequals/wormnest/commit/2dfe96fc2570586ac487b399ac20d41b3c114861", "commit_sha": "2dfe96fc2570586ac487b399ac20d41b3c114861", "patch": "SINGLE", "chain_ord": "['2dfe96fc2570586ac487b399ac20d41b3c114861']", "before_first_fix_commit": "{'30ab2ba563a19040b07b7b8b06e97ad95c0b5793', 'dd981626b574a89939babd1246588580ecc323f9'}", "last_fix_commit": "2dfe96fc2570586ac487b399ac20d41b3c114861", "chain_ord_pos": 1, "commit_datetime": "04/29/2022, 08:37:58", "message": "Merge pull request #8 from porcupineyhairs/FixPathInjection\n\nFix Path Traversal Vulnerability", "author": "John Torakis", "comments": null, "stats": "{'additions': 2, 'deletions': 2, 'total': 4}", "files": {"app.py": {"additions": 2, "deletions": 2, "changes": 4, "status": "modified", "raw_url": "https://github.com/operatorequals/wormnest/raw/2dfe96fc2570586ac487b399ac20d41b3c114861/app.py", "patch": "@@ -1,6 +1,6 @@\n #!/bin/env python\n from flask import Flask\n-from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort\n+from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort, safe_join\n \n from werkzeug.utils import secure_filename\n from ipaddress import ip_address, ip_network\n@@ -116,7 +116,7 @@ def dir_listing(req_path):\n https://stackoverflow.com/questions/23718236/python-flask-browsing-through-directory-with-files\n   '''\n   # Joining the base and the requested path\n-  abs_path = os.path.join(CONFIG['SRV_DIR'], req_path)\n+  abs_path = safe_join(CONFIG['SRV_DIR'], req_path)\n \n   # Return 404 if path doesn't exist\n   if not os.path.exists(abs_path):"}}, "prior_version": " #!/bin/env python from flask import Flask from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort  from werkzeug.utils import secure_filename from ipaddress import ip_address, ip_network def dir_listing(req_path): https://stackoverflow.com/questions/23718236/python-flask-browsing-through-directory-with-files   '''   # Joining the base and the requested path   abs_path = os.path.join(CONFIG['SRV_DIR'], req_path)    # Return 404 if path doesn't exist   if not os.path.exists(abs_path):", "after_version": " #!/bin/env python from flask import Flask from flask import flash,request,send_file,send_from_directory,redirect,render_template, abort, safe_join  from werkzeug.utils import secure_filename from ipaddress import ip_address, ip_network def dir_listing(req_path): https://stackoverflow.com/questions/23718236/python-flask-browsing-through-directory-with-files   '''   # Joining the base and the requested path   abs_path = safe_join(CONFIG['SRV_DIR'], req_path)    # Return 404 if path doesn't exist   if not os.path.exists(abs_path):", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2022-31508", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/idayrus/evoting/commit/241d92a4d68f524365a6322b5bbcfaa7d9abc8a3'}", "dataset": "nvd", "summary": "The idayrus/evoting repository before 2022-05-08 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-11", "chain_len": 1, "project": "https://github.com/idayrus/evoting", "commit_href": "https://github.com/idayrus/evoting/commit/241d92a4d68f524365a6322b5bbcfaa7d9abc8a3", "commit_sha": "241d92a4d68f524365a6322b5bbcfaa7d9abc8a3", "patch": "SINGLE", "chain_ord": "['241d92a4d68f524365a6322b5bbcfaa7d9abc8a3']", "before_first_fix_commit": "{'d9ef8c7c0343c7986fe06ff976395775d5844732', 'fefef0d06816ac2d80ed3c80df20fa5deca43a48'}", "last_fix_commit": "241d92a4d68f524365a6322b5bbcfaa7d9abc8a3", "chain_ord_pos": 1, "commit_datetime": "05/08/2022, 18:26:01", "message": "Merge pull request #2 from porcupineyhairs/FixPathInjection\n\nFix Path Traversal Vulnerability", "author": "adierebel", "comments": null, "stats": "{'additions': 2, 'deletions': 1, 'total': 3}", "files": {"app/helper/middleware.py": {"additions": 2, "deletions": 1, "changes": 3, "status": "modified", "raw_url": "https://github.com/idayrus/evoting/raw/241d92a4d68f524365a6322b5bbcfaa7d9abc8a3/app%2Fhelper%2Fmiddleware.py", "patch": "@@ -5,6 +5,7 @@\n from app.module.user.model import UserModel, UserTokenModel\n from app.module.user import UserSession\n from werkzeug.routing import BaseConverter, ValidationError\n+from werkzeug.utils import safe_join\n from bson.objectid import ObjectId\n from bson.errors import InvalidId\n from os import path\n@@ -18,7 +19,7 @@\n @login_required\n def private_static(filename):\n     # Get path\n-    filepath = path.join(app.config.get(\"PRIVATE_DIR\"), filename)\n+    filepath = safe_join(app.config.get(\"PRIVATE_DIR\"), filename)\n     if path.isfile(filepath):\n         return send_file(filepath)\n     # End"}}, "prior_version": " from app.module.user.model import UserModel, UserTokenModel from app.module.user import UserSession from werkzeug.routing import BaseConverter, ValidationError from bson.objectid import ObjectId from bson.errors import InvalidId from os import path @login_required def private_static(filename):     # Get path     filepath = path.join(app.config.get(\"PRIVATE_DIR\"), filename)     if path.isfile(filepath):         return send_file(filepath)     # End", "after_version": " from app.module.user.model import UserModel, UserTokenModel from app.module.user import UserSession from werkzeug.routing import BaseConverter, ValidationError from werkzeug.utils import safe_join from bson.objectid import ObjectId from bson.errors import InvalidId from os import path @login_required def private_static(filename):     # Get path     filepath = safe_join(app.config.get(\"PRIVATE_DIR\"), filename)     if path.isfile(filepath):         return send_file(filepath)     # End", "file_extension": "py", "cwe": "CWE-22"}
{"vuln_id": "CVE-2022-31564", "cwe_id": "{'CWE-22'}", "score": 4.9, "chain": "{'https://github.com/woduq1414/munhak-moa/commit/e8f800373b20cb22de70c7a994325b8903877da0'}", "dataset": "nvd", "summary": "The woduq1414/munhak-moa repository before 2022-05-03 on GitHub allows absolute path traversal because the Flask send_file function is used unsafely.", "published_date": "2022-07-11", "chain_len": 1, "project": "https://github.com/woduq1414/munhak-moa", "commit_href": "https://github.com/woduq1414/munhak-moa/commit/e8f800373b20cb22de70c7a994325b8903877da0", "commit_sha": "e8f800373b20cb22de70c7a994325b8903877da0", "patch": "SINGLE", "chain_ord": "['e8f800373b20cb22de70c7a994325b8903877da0']", "before_first_fix_commit": "{'cdcc98959879c2e88a89eea164e806b3b0e09972'}", "last_fix_commit": "e8f800373b20cb22de70c7a994325b8903877da0", "chain_ord_pos": 1, "commit_datetime": "05/03/2022, 11:23:52", "message": "# Absolute Path Traversal due to incorrect use of `send_file` call\n\nA path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder. By manipulating variables that reference files with \u201cdot-dot-slash (../)\u201d sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file system including application source code or configuration and critical system files. This attack is also known as \u201cdot-dot-slash\u201d, \u201cdirectory traversal\u201d, \u201cdirectory climbing\u201d and \u201cbacktracking\u201d.\n\n## Common Weakness Enumeration category\nCWE - 36\n\n## Root Cause Analysis\n\nThe `os.path.join` call is unsafe for use with untrusted input. When the `os.path.join` call encounters an absolute path, it ignores all the parameters it has encountered till that point and starts working with the new absolute path.  Please see the example below.\n```\n>>> import os.path\n>>> static = \"path/to/mySafeStaticDir\"\n>>> malicious = \"/../../../../../etc/passwd\"\n>>> os.path.join(t,malicious)\n'/../../../../../etc/passwd'\n```\nSince the \"malicious\" parameter represents an absolute path, the result of `os.path.join` ignores the static directory completely. Hence, untrusted input is passed via the `os.path.join` call to `flask.send_file` can lead to path traversal attacks.\n\nIn this case, the problems occurs due to the following code :\nhttps://github.com/woduq1414/munhak-moa/blob/cdcc98959879c2e88a89eea164e806b3b0e09972/app.py#L273\n\nHere, the `path` parameter is attacker controlled. This parameter passes through the unsafe `os.path.join` call making the effective directory and filename passed to the `send_file` call attacker controlled. This leads to a path traversal attack.\n\n## Proof of Concept\n\nThe bug can be verified using a proof of concept similar to the one shown below.\n\n```\ncurl --path-as-is 'http://<domain>/images//../../../../etc/passwd\"'\n```\n## Remediation\n\nThis can be fixed by preventing flow of untrusted data to the vulnerable `send_file` function. In case the application logic necessiates this behaviour, one can either use the `werkzeug.utils.safe_join` to join untrusted paths or replace `flask.send_file` calls with `flask.send_from_directory` calls.\n\n## Common Vulnerability Scoring System Vector\n\nThe attack can be carried over the network. A complex non-standard configuration or a specialized condition is not required for the attack to be successfully conducted. There is no user interaction required for successful execution. The attack can affect components outside the scope of the target module. The attack can be used to gain access to confidential files like passwords, login credentials and other secrets. It cannot be directly used to affect a change on a system resource. Hence has limited to no impact on integrity. Using this attack vector a attacker may make multiple requests for accessing huge files such as a database. This can lead to a partial system denial service. However, the impact on availability is quite low in this case. Taking this account an appropriate CVSS v3.1 vector would be\n\n(AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L)[https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator?vector=AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:N/A:L&version=3.1]\n\nThis gives it a base score of 9.3/10 and a severity rating of critical.\n\n## References\n* [OWASP Path Traversal](https://owasp.org/www-community/attacks/Path_Traversal)\n* github/securitylab#669\n\n### This bug was found using *[CodeQL by Github](https://codeql.github.com/)*", "author": "Porcupiney Hairs", "comments": null, "stats": "{'additions': 2, 'deletions': 1, 'total': 3}", "files": {"app.py": {"additions": 2, "deletions": 1, "changes": 3, "status": "modified", "raw_url": "https://github.com/woduq1414/munhak-moa/raw/e8f800373b20cb22de70c7a994325b8903877da0/app.py", "patch": "@@ -1,6 +1,7 @@\n import configparser\n \n from flask import Flask, render_template, session, request, flash, redirect, url_for, Response, abort, jsonify, send_file\n+from werkzeug.utils import safe_join\n import socket\n import os\n import random\n@@ -267,7 +268,7 @@ def get_absolute_path(path):\n         import os\n         script_dir = os.path.dirname(__file__)  # <-- absolute dir the script is in\n         rel_path = path\n-        abs_file_path = os.path.join(script_dir, rel_path)\n+        abs_file_path = safe_join(script_dir, rel_path)\n         return abs_file_path\n \n     return send_file("}}, "prior_version": " import configparser  from flask import Flask, render_template, session, request, flash, redirect, url_for, Response, abort, jsonify, send_file import socket import os import random def get_absolute_path(path):         import os         script_dir = os.path.dirname(__file__)  # <-- absolute dir the script is in         rel_path = path         abs_file_path = os.path.join(script_dir, rel_path)         return abs_file_path      return send_file(", "after_version": " import configparser  from flask import Flask, render_template, session, request, flash, redirect, url_for, Response, abort, jsonify, send_file from werkzeug.utils import safe_join import socket import os import random def get_absolute_path(path):         import os         script_dir = os.path.dirname(__file__)  # <-- absolute dir the script is in         rel_path = path         abs_file_path = safe_join(script_dir, rel_path)         return abs_file_path      return send_file(", "file_extension": "py", "cwe": "CWE-22"}
